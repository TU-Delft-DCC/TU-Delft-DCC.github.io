[
  {
    "objectID": "docs/software/development_workflow/collaboration.html",
    "href": "docs/software/development_workflow/collaboration.html",
    "title": "Collaboration",
    "section": "",
    "text": "Effective collaboration is a fundamental aspect of any successful software development project.\nKey points:",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Collaboration"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/collaboration.html#collaborative-workflow",
    "href": "docs/software/development_workflow/collaboration.html#collaborative-workflow",
    "title": "Collaboration",
    "section": "Collaborative workflow",
    "text": "Collaborative workflow\nFollowing the GitHub Flow model, everything starts from the main branch. Developers can create feature branches from the main branch to isolate their work. Once ready, changes are merged back to main.\n\n\n\n\n\n\n Workflow variations\n\n\n\nWhile the GitHub Flow workflow focuses on main, some opt for a hybrid approach to include a develop branch either as a staging area for pre-release testing or ongoing integration (aggregating features before merging to main). This approach borrows elements from GitFlow (e.g., a long-lived develop branch) without adopting its full branching model.\n\n\nA common workflow in a collaborative development project.\n\nCreate a feature branch: Start by creating a new branch of the main branch (or develop if used). This branch should have a descriptive name to give an idea of the work that will be done, such as a new feature or a bug fix. This separation allows you to work independently without affecting the main codebase.\nMake changes and commit: Work on your branch, making the necessary changes to the code. Commit these changes with clear, descriptive messages.\nOpen a pull request: Once you have made your changes, open a pull request (PR). PRs allow for discussion, review, and additional changes if necessary.\nReview: Before merging, your changes might go through a review process where other team members can give feedback. Some projects may require a review before merging is allowed.\nMerge: Finally, once your changes are reviewed and tested, you can merge the pull request into main (or develop, if applicable). This incorporates your contributions into the project, making them part of the official codebase.\nDelete feature branch: Feature branches should be short-lived, thus avoiding potential conflicts due to the divergence of the code.\n\n\n\n\n\n\n\nSequence diagram of workflow\n\n\n\n\n\n\n\n\n\n\nsequenceDiagram\n    participant A as Author\n    participant R as Reviewer\n    A-&gt;&gt;A: Write some code in your branch or fork\n    A-&gt;&gt;R: Open a pull request\n    R-&gt;&gt;R: Add comments to a review\n    R-&gt;&gt;A: Submit a review\n    loop Until approved\n        A-&gt;&gt;R: Address or respond to review comments\n        R-&gt;&gt;A: Clarify or resolve comments\n    end\n    R-&gt;&gt;A: Approve pull request\n    A-&gt;&gt;A: Merge pull request\n    A-&gt;&gt;A: Delete branch\n\n\n\n\n\n\n\n\n\n\nForking\nExternal collaborators who do not have the same administrative rights to the repository can fork the project. They make their changes on their forked repository in a new feature branch. Steps 3-5 remain the same.\n\n\n\n\n\n\n Create ‚ÄúDraft‚Äù Pull Requests!\n\n\n\nWith Draft PR‚Äôs you:\n\nwant to signal that a pull request is just the start of the conversation and your code isn‚Äôt in any state to be judged.\nor have no intention of ever merging it, but you‚Äôd still like people to check it out locally and give you feedback.\nor opened a pull request without any code at all in order to get the discussion started.\n\n\n\n\n\nConflict resolution\nConflicts occur when two or more changes compete with each other, typically during a merge or rebase operation in Git. With pull requests, code reviews and testing you can catch potential conflicts before they are merged into the main codebase.\nConflicts usually come up and are resolved during a pull request:\n\nReview Conflicts: When a conflict is detected in a pull request, GitHub will alert you. Start by reviewing the conflicting files to understand the nature of the conflict.\nPull and Merge Locally: Fetch the latest changes from the main branch and attempt to merge them into your feature/develop branch locally. This will allow you to resolve conflicts on your local machine.\nResolve Conflicts: This might involve choosing one change over another or merging the changes manually.\nTest Changes: After resolving conflicts, thoroughly test your changes to ensure that the merged code works as expected.\nCommit and Push: Once conflicts are resolved and changes are tested, commit the resolved conflicts and push your changes back to the feature/develop branch on GitHub.\nComplete the Pull Request: After resolving conflicts and pushing your changes, review the pull request again to ensure everything is in order. If all checks pass and your team approves the changes, you can complete the merge into the main branch.\n\nEffective conflict resolution ensures that changes can be integrated smoothly and that the project remains on track. Conflicts cannot always be avoided, but they can be managed. Clear communication and adherence to established practices is the way to go.\n\n\n\n\n\n\n Learn more\n\n\n\n\nFor more information on Draft PRs - Introducing Draft Pull Requests.\nGitHub - Resolving a merge conflict\nCode Refinery - Lesson on conflict resolution",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Collaboration"
    ]
  },
  {
    "objectID": "docs/tud-support/index.html",
    "href": "docs/tud-support/index.html",
    "title": "Research Support Staff Guide",
    "section": "",
    "text": "üöß Under construction! üèóÔ∏è"
  },
  {
    "objectID": "docs/software/testing/strategies.html",
    "href": "docs/software/testing/strategies.html",
    "title": "Testing strategy",
    "section": "",
    "text": "In designing test cases for research software, it can be useful to conceptually differentiate between tests that verify the technical correctness of the code and tests that check the scientific validity of the results. With technical software tests, you check whether a function behaves as expected. With a scientific test, you compare the outcome of a function to known (experimental) scientific results.\nThe following questions can help you decide what to test in your software:\n\nHow can I ensure the algorithms and mathematical models implemented in the software are correct?\nHow can I verify that the input data types, formats, and ranges adhere to expected standards and constraints?\nHow does the software behave at boundary conditions and extreme values of input parameters?\nHow does the software perform under varying workloads and dataset sizes, and is it scalable for large-scale simulations or data processing tasks?\nHow do I compare the software‚Äôs results against existing literature, experimental data, or previous simulations to check their accuracy?\n\n\nRoadmap to testing\n\nNew to testingFamiliar with testing\n\n\n\n\n\n\n\n\n1. Familiarize yourself with the basics\n\n\n\n\n\nBegin by learning a testing framework that is well-suited for your programming language; for example, you might explore pytest if you are using Python. It is also important to understand the basic types of tests, focusing primarily on unit tests and simple integration tests.\n\n\n\n\n\n\n\n\n\n2. Identify critical components in your code\n\n\n\n\n\nTake the time to inspect your codebase and determine which parts are most important or particularly prone to error. These are the areas where you should focus your testing efforts.\n\n\n\n\n\n\n\n\n\n3. Start small\n\n\n\n\n\nBegin by writing minimal (unit) tests for individual functions or modules. Creating tests based on expected inputs and outputs will help confirm that your code behaves as intended. The primary goal at this stage is to understand the testing process rather than aiming for complete coverage from the start.\n\n\n\n\n\n\n\n\n\n4. Incrementally expand the number of tests\n\n\n\n\n\nAs you introduce new functionality, adopt an approach by writing tests alongside your new code. Over time, gradually add tests to your existing code ‚Äì especially when you make changes or improvements ‚Äì to steadily increase overall test coverage and improve the reliability of your software. Make sure to focus on testing the critical parts of your codebase first.\n\n\n\n\n\n\n\n\n\n5. Refactor your code for testability\n\n\n\n\n\nIf you find it difficult to write tests for your codebase, consider refactoring it into smaller, more testable units. Clear documentation and comments on your functions will further aid in writing tests by providing a well-defined understanding of each component‚Äôs intent.\n\n\n\n\n\n\n\n\n\n6. Automate and adopt\n\n\n\n\n\nFinally, add automated testing to your development workflow by using a continuous integration tool to run tests automatically with each code change. Establishing a regular habit of testing will, over time, lead to significant improvements in the quality and reliability of your research code.\n\n\n\n\n\n\n\n\n\n\n\n1. Develop a testing strategy\n\n\n\n\n\nFor researchers already experienced with testing, it is useful to develop a testing strategy. Start by adopting the test pyramid approach: ensure that all core functions and algorithms are covered by unit tests, verify that modules interact correctly with integration tests, and, when applicable, use end-to-end tests to simulate real-world user workflows. Regularly running regression tests is also important to catch any unintended side effects of code changes.\nAim for comprehensive test coverage to ensure that critical parts of your codebase are thoroughly tested. A good benchmark is to test at least 70% of your code base with unit tests.\n\n\n\n\n\n\n\n\n\n2. Adopt a practice of writing tests first\n\n\n\n\n\nConsider methodologies such as Test-Driven Development (TDD) into your workflow. With TDD, you write tests before you write the actual code to define the desired behavior, ensure clear specifications, and obtain immediate feedback.\n\n\n\n\n\n\n\n\n\n3. Research-specific testing\n\n\n\n\n\nIn a research context, certain quality measures become particularly important. Prioritize reproducibility by writing tests that verify experiments yield consistent outputs for a given dataset and configuration. If your code relies on statistical methods, use fixed random seeds to ensure reproducibility across different runs. Additionally, consider implementing validation tests that compare your results against known benchmarks or experimental data.\n\n\n\n\n\n\n\n\n\n4. Consider advanced testing practices\n\n\n\n\n\n\nCoverage Analysis:\nEmploy code coverage tools to identify untested paths and critical areas that require additional testing.\nParameterization:\nRun tests with a range of inputs to validate robustness across different scenarios.\nError Handling: Verify that your code behaves as expected when encountering errors.\nFixtures: Use fixtures to set up a consistent and reusable testing environment.\nMocking:\nUse mocks to simulate external systems or heavy computations, isolating tests for faster feedback.\nTagging and Filtering: Organize tests into categories and run specific subsets based on tags or filters.  Advanced testing practices\n\n\n\n\n\n\n\n\n\n\n5. Integrate with CI/CD\n\n\n\n\n\nFinally, integrate your testing processes into a continuous integration/deployment pipeline. Automate your test runs so that every code commit triggers a suite of tests to catch issues early in the development cycle. Monitor test performance and code coverage over time to continuously refine and enhance your testing strategy, ensuring a high level of quality and reliability in your research software.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Testing strategy"
    ]
  },
  {
    "objectID": "docs/software/testing/python.html",
    "href": "docs/software/testing/python.html",
    "title": "Testing in Python",
    "section": "",
    "text": "In Python, two widely used testing frameworks are pytest and unittest. This guide focuses on pytest, which is recommended for its simplicity and readability. If you are new to testing in Python, pytest is a great starting point.\n\n\n\n\n\n\n What is the difference between pytest and unittest?\n\n\n\n\n\n\npytest is a third-party testing framework that is more user-friendly, requires less boilerplate, and offers better readability.\nunittest is part of the Python standard library and follows a more traditional object-oriented style of writing tests.\n\n\n\n\n\nStep 1. Setup a testing framework\nInstall pytest\npip install pytest\nA good practice is to organize the codebase into a src directory for the source code and a tests directory for the test suite. For example:\nsrc/\n    mypkg/\n        __init__.py\n        add.py\n        draw_random_number.py\ntests/\n    test_add.py\n    test_draw_random_number.py\n    ...\n\n\nStep 2. Identify testable units\nIdentify functions, methods, or classes on your code that should be tested. Focus on critical computations and potential points of failure.\n\n\nStep 3. Write test cases\nWrite test functions using pytest. Here‚Äôs an example:\n# src/mypkg/add.py\ndef add(x,y):\n    return x + y\n\n# tests/test_add.py\nfrom mypkg.add import add\n\ndef test_add():\n    assert add(1, 2) == 3\n    assert add(0, 0) == 0\n    assert add(-1, -1) == -2\n\n\n\n\n\n\n Tip\n\n\n\nLimit the number of assert statements in a single test function. Otherwise, when a particular assert fails, the remaining assertions in the test function will not be executed.\n\n\n\n\nStep 4. Run tests locally\nRun all tests in the project by executing the following command:\npytest\nRun a specific test file:\npytest tests/test_add.py\n\n\nStep 5. Debug and fix failing tests\nThe test results displayed in the console will help you to identify any failures or errors. If errors occur, debug the failing tests by examining failure messages and stack traces.\n\n\nStep 6. Run coverage report locally\nGenerate a coverage report to gain insights into which parts of the codebase have been executed during testing (see Code Coverage).\npip install pytest-cov\npytest --cov=mypkg tests/\n\n\nStep 7. Automate testing with Continuous Integration\nIntegrate youre test suite with a Continuous Integration service (e.g., GitHub Actions) to run tests automatically on every code change.\n\n\n\n\n\n\n Learning materials for automated testing\n\n\n\n\nIntermediate Research Software Development - CI for Automated Testing\nCode Refinery - Automated testing\n\n\n\n\n\nExamples of repositories with tests\n\neScience Center - Project matchms\nPandas library - Repository tests\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nPytest - Getting Started\nCode Refinery - Pytest exercise\nRealPython - Effective testing with pytest",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Testing in Python"
    ]
  },
  {
    "objectID": "docs/software/testing/intermediate.html",
    "href": "docs/software/testing/intermediate.html",
    "title": "More testing concepts",
    "section": "",
    "text": "Code Coverage\nCode coverage measures how much of your code is executed during testing. It is a useful metric to ensure that your tests are comprehensive and indicate your code‚Äôs quality. If your software becomes a dependency for others, a code coverage of 70% or higher is recommended for unit tests.\n\nPythonMATLAB\n\n\n\npytest-cov plugin (for pytest)\nCoverage.py documentation\n\n\n\n\nCollect code coverage with Command Window execution (since R2023b)\nCode coverage with Test Browser (since R2023a)\nCollect code coverage metrics\n\n\n\n\n\n\nError handling\nTests should check if your code behaves as expected when it encounters errors. This includes testing if the code raises the correct exceptions when given invalid input or when an error occurs.\n\nPythonMATLAB\n\n\n\nAssert raised exceptions\n\nExample in Python:\ndef divide(x, y):\n    if y == 0:\n        raise ValueError(\"Cannot divide by zero\")\n    return x / y\n\ndef test_divide_by_zero():\n    with pytest.raises(ValueError):\n        divide(1, 0)\n\n\n\nVerify function throws specific exceptions\n\n\n\n\n\n\nFixtures\nFixtures are predefined states or sets of data used to set up the testing environment, ensuring consistent conditions for tests to run reliably. Fixtures can be used to set up databases, create temporary files, or initialize other resources, that then available to all tests in a test suite.\n\nPythonMATLAB\n\n\n\nHow to use fixtures\n\n\n\n\nCreate shared fixtures\n\n\n\n\n\n\nParameterization\nParameterization involves running the same test with different inputs or configurations to ensure broader coverage and identify potential edge cases.\n\nPythonMATLAB\n\n\n\nParameterizing unit tests\n\n\n\n\nCreate a basic parameterized test\n\n\n\n\n\n\nMocking\nMocking (or monkeypatching) is a technique used to simulate the behavior of dependencies or external systems during testing, allowing isolated testing of specific components. For example, if your software requires a connection to a database, you can mock this interaction during testing.\n\n\n\nMathWorks, MATLAB Mocking Diagram, MATLAB Documentation, link to image.\n\n\n\n\n\n\n\n\nüêí Monkeypatching?\n\n\n\n\n\nThe term monkey patch seems to have come from an earlier term, guerrilla patch, which referred to changing code sneakily ‚Äì and possibly incompatibly with other such patches ‚Äì at runtime. The word guerrilla, nearly homophonous with gorilla, became monkey, possibly to make the patch sound less intimidating.\n\n\n\n\nPythonMATLAB\n\n\n\nHow to monkeypatch/mock modules and environments\n\n\n\n\nCreate Mock Object\n\n\n\n\n\n\nMarks and tags\nYou can use test tags to group tests into categories and then run tests with specified tags. This is useful when you want to run only a subset of tests, such as regression tests, or when ignoring slow tests during development.\n\nPythonMATLAB\n\n\n\nWorking with custom markers\n\n\n\n\nTag unit tests",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Advanced concepts"
    ]
  },
  {
    "objectID": "docs/software/releases_archiving/releases.html",
    "href": "docs/software/releases_archiving/releases.html",
    "title": "Releases",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Publish and share",
      "Releases"
    ]
  },
  {
    "objectID": "docs/software/releases_archiving/index.html",
    "href": "docs/software/releases_archiving/index.html",
    "title": "Packaging, releases and archiving",
    "section": "",
    "text": "üèóÔ∏è Under construction!",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Publish and share"
    ]
  },
  {
    "objectID": "docs/software/getting_started.html",
    "href": "docs/software/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "üèóÔ∏è Under construction",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Getting started"
    ]
  },
  {
    "objectID": "docs/software/fair_software/fair.html",
    "href": "docs/software/fair_software/fair.html",
    "title": "FAIR Software",
    "section": "",
    "text": "While originally targetting data management, the FAIR for Research Software (FAIR4RS) extends the FAIR principles to research software, which, unlike data, is executable and evolves over time. Ensuring the findability of software involves metadata, identifiers, and version control systems, while accessibility includes guidelines for obtaining, installing, and running the software. Interoperability involves adherence to community-driven standards or protocols, and reusability requires detailed documentation and user guides to effectively apply the software in new research projects.\n\n\n\n FAIR Software Checklist\nSet of recommendations for FAIR software. Add FAIR cards to your repository to track progress.\n\nLearn more ¬ª\n\n\n\n Software Management Plan\n\nLearn more ¬ª\n\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nFAIR Guiding Principles for scientific data management and stewardship to research software\nFAIR4RS community in Zenodo\nFAIR Software Checklist - five recommendations for FAIR (scientific) software",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "FAIR Software"
    ]
  },
  {
    "objectID": "docs/software/documentation/write_a_readme.html",
    "href": "docs/software/documentation/write_a_readme.html",
    "title": "README",
    "section": "",
    "text": "A README file is essential for your software project as it helps users understand the purpose of your project, how to install and use it, and how to contribute. While the specific content of a README can vary from project to project, a good README should always include the following sections:\n\nThe purpose of the project.\nHow to cite the project.\nInstallation and usage instructions.\nThe terms under which the software is distributed (license).\n\n\nProject purpose\nClearly explain the purpose of your project, including its motivation and objectives. This section should serve as an introductory overview, helping users and contributors understand the essence of your project.\nConsider adding:\n\nBackground information\nComparison with alternatives, highlighting what sets your project apart\nLinks to related references or documentation\n\n\n\nHow to cite\nIf you want users to cite your project when they use it, provide a citation in this section, referring to a publication or DOI of the software.\nFor more information about citing the project, see the citation guide.\n\n\nInstallation and usage\nThis section should explain the steps needed to set up and use the software. Before installation, users must be aware of any prerequisites or dependencies that are required. This can include specific versions of programming languages, libraries, operating systems, data, and hardware.\n\nInstallation steps\nProvide a step-by-step guide for installation. This can involve downloading the software from a repository, compiling code, or using a package manager. Consider using package managers, such as pip or conda, to simplify the installation.\nExample: The scikit-learn GitHub repository provides a good example of the Installation section of a README.\n\n\nUsage\nYou can include the simplest possible usage example directly in the README and provide more complex examples in additional files or links.\nExample: The TensorFlow GitHub repository gives a small usage sample after installation instructions and provides a link with additional examples and tutorials.\n\n\n\nLicense\nYour README should specify the licensing terms. For more information, see the License guide.\n\n\n\n\n\n\n Tip\n\n\n\nIt is recommended to write README‚Äôs in markdown (README.md) formatting and placed in the project‚Äôs top-level directory. If you find your README is becoming too long, consider incorporating additional documentation files instead of omitting important details.\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nMake a README - README 101\nMaking READMEs readable",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "README"
    ]
  },
  {
    "objectID": "docs/software/documentation/license.html",
    "href": "docs/software/documentation/license.html",
    "title": "Software licenses",
    "section": "",
    "text": "Important\n\n\n\nFor questions about data and software licenses, please consult your Faculty Data Steward.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Software licenses"
    ]
  },
  {
    "objectID": "docs/software/documentation/license.html#tu-delft-licensing-policy",
    "href": "docs/software/documentation/license.html#tu-delft-licensing-policy",
    "title": "Software licenses",
    "section": "TU Delft licensing policy",
    "text": "TU Delft licensing policy\nTU Delft, by default, holds the rights to the software created by its employees. In order to apply a pre-approved open source license, you have to follow the guidelines in TU Delft Guidelines on Research Software: Licensing, Registration and Commercialisation. It states:\n\n\n\n\n\n\nIt is important to remember that in principle TU Delft holds the rights to the software created by its employees (i.e.¬†software developers, researchers and/or staff). So, some formal (legal) steps are needed to arrange matters properly.\nWhen these guidelines are followed and when the software is published, TU Delft disclaims its copyright, allowing software developers, researchers and staff to hold the copyright to their software and thereby having the right to apply one of the pre-approved licences when sharing software. The pre-approved open source software licences at TU Delft are Apache, MIT, BSD, EUPL, AGPL, LGPL, GPL, and CC0.\n\n\n\n\nSteps to apply a pre-approved open-source license\n\nDetermine if it is possible to apply an Open Source Software licence to your project (see diagram below).\nThe waiver of TU Delft should be added to the repository, either as a separate file or within the LICENSE file. The waiver text should be as follows:\nTechnische Universiteit Delft hereby disclaims all copyright interest in the program ‚ÄúName program‚Äù (one line description of the content or function) written by the Author(s). \n\n[Name Dean], Dean of [Name Faculty]\nAssert your own, personal copyright (¬© YEAR, [NAME], [REFERENCE project, grant or study if desired]. Waiving the copyright and having TU Delft staff assert the copyright in their own name facilitates the use of copyleft licences.\nApply one of the TU Delft pre-approved Open Source Software licences in the format and form described in the licence text after stating, ‚ÄúThis work is licensed under a [NAME and VERSION] OSS licence‚Äù.\nMake the software openly available (for instance in an online repository such as GitHub).\nPlease consider acknowledging support from TU Delft and/or your funding provider.\nRegister the software either in 4TU.ResearchData or in PURE. Registries in 4TU.ResearchData are automatically registered in PURE.\n\n\n\n\n\n\n\nThe steps above are mandatory, the TU Delft guidelines state:\nPlease note that if the software is not published, and/or if the guidelines have not been followed correctly and/or if the software is not registered in PURE, then this ‚Äòagreement‚Äô is invalid and the software automatically falls under the legal copyright of TU Delft. This instantly nullifies the right of the software developer or researcher to apply for a licence and thus the open source software licence applied never came into existence. This works retroactively.\n\n\n\n\n\nDecision tree for applying for a license\nTU Delft staff members can apply for an open-source license according to the decision tree found in TU Delft Guidelines on Research Software: Licensing, Registration and Commercialisation.\n\n\n\n\n\n\n\nDecision tree to guide software developers, researchers and staff on when they can apply an open source licence to their software (OSS: Open Source Software, IDF: Invention Disclosure Form). From: Bazuine, M. (2021). TU Delft Guidelines on Research Software: Licensing, Registration and Commercialisation. Zenodo. https://doi.org/10.5281/zenodo.4629635",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Software licenses"
    ]
  },
  {
    "objectID": "docs/software/documentation/license.html#types-of-open-source-licenses",
    "href": "docs/software/documentation/license.html#types-of-open-source-licenses",
    "title": "Software licenses",
    "section": "Types of open source licenses",
    "text": "Types of open source licenses\n\nPermissive licenses aka copyright (e.g., MIT, BSD, Apache): These licenses allow users to do almost anything with the code, including using it in proprietary software.\nRestrictive licenses aka copyleft (e.g., GPL, AGPL, LGPL, EUPL): These licenses require any derivative works to be open source and distributed under the same license.\n\n\nCopyright licenses\n\nMIT: Very simple and permissive, allowing almost unrestricted reuse. The software can be freely used, modified, distributed, and sublicensed.\nBSD: Similar to the MIT license, but it may include additional attribution requirements.\n\n\n\n\n\n\n\n BSD license details\n\n\n\n\n\n\nAttribution: Requires that the copyright notice and list of conditions be included in all copies or substantial portions of the software (except for the BSD 0-Clause License, which does not require any attribution). There are different clause variants of the license. For example, a BSD 3-Clause license adds a clause preventing the use of the names of the project or its contributors to endorse or promote derived products without written permission.\nPatent Protection: Does not include explicit provisions for patent protection.\n\n\n\n\n\nApache: Allows for the use, modification, distribution, and sublicensing of the software under certain conditions. It is often used in open-source projects and is often the choice for its balance between permissiveness and the protection of patents. The Innovation and Impact Center recommends this license for industry collaborations.\n\n\n\n\n\n\n\n Apache license details\n\n\n\n\n\n\nAttribution: Requires preservation of the original copyright notice and a notice of any modifications made.\nPatent Protection: Includes a patent retaliation clause, which provides an additional layer of protection. This clause terminates the license if the user initiates patent litigation against any entity regarding the licensed software.\nNotice Requirement: Modifications to the original code must be documented, and a NOTICE file must be included with any substantial portions of the software.\n\n\n\n\n\n\n\n\n\n\n Key differences between a BSD and Apache license\n\n\n\n\nThe Apache license includes a patent retaliation clause to protect against patent litigation, but the BSD license does not explicitly address patent rights.\nThe BSD license does not require a specific notice file for modifications, but the Apache License requires a NOTICE file that documents any modifications made to the original code.\n\n\n\n\n\nCopyleft licenses\n\nGPL (GNU General Public License): One of the most widespread copyleft licenses. With the GPL license, any derivative work under this license automatically becomes subject to the same GPL terms, regardless of the size of the contribution. All future modifications and adaptions of code under this license is only compatible with this license and cannot be used in proprietary software.\nDerivatives from GPL (AGPL, LGPL, EUPL): From these, the EUPL license is somewhat more flexible compared to others as it can coexist with other open-source software licenses such as MIT, BSD, and Apache. For instance, if you integrate a portion of software that is licensed under Apache into a project governed by EUPL, that portion can retain its Apache license. In contrast, under the GPL, the entire codebase would need to be licensed under GPL.\n\n\n\n\n\n\n\n There are even instances when GPL licenses are incompatible with each other. For example, GPL-2.0 is incompatible with GPL-3.0. If a project uses GPL-2.0 you are essentially forced to use that license.\n\n\n\n\n\nLicense compatibility\n\n\n\n\n\n\n\nCompatibility of licenses. From: Bazuine, M. (2021). TU Delft Guidelines on Research Software: Licensing, Registration and Commercialisation. Zenodo. https://doi.org/10.5281/zenodo.4629635\n\n\n\n\n\n\n\n\n Tip\n\n\n\nDon‚Äôt forget to check whether your software‚Äôs dependencies have restrictions on re-use.\n\n\nIt is advisable to contact your faculty‚Äôs data steward regarding licensing questions. If your project involves complex legal considerations, particularly regarding intellectual property rights or compliance with licensing agreements, the Innovation and Impact Center should also be involved.\n\n\n\n\n\n\n Further reading\n\n\n\n\nTU Delft Research Software Policy\nTU Delft Guidelines on Research Software - the TU Delft Research Software Policy approved by the Executive Board\nChoose a license - a simplified guide on choosing an open-source license\ntl;drLegal - Plain English summaries of software licenses\nThe Turing Way - Licensing\nGitHub - Adding a license to a repository",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Software licenses"
    ]
  },
  {
    "objectID": "docs/software/documentation/hosting.html",
    "href": "docs/software/documentation/hosting.html",
    "title": "Hosting",
    "section": "",
    "text": "Once you have created your documentation either in Sphinx, Jupyter Book, MkDocs or Quarto, you can host it online.\n\nGitHub Pages\nGitHub Pages provides a simple way to host your documentation, especially if your project is already on GitHub.\nIt is straightforward to set up GitHub Pages:\n\nWithin your repository, go to the repository settings and find the GitHub Pages section.\nChoose your publishing source (you should have a docs folder or a dedicated branch).\n\nGitHub Pages also supports custom domains, which might be relevant to you. You can configure this by adding a CNAME file to your directory.\n\n\n\n\n\n\n Learn more\n\n\n\n\nGitHub Pages\nConfiguring a custom domain for your GitHub Pages site\nCoderefinery - Deploying Sphinx documentation to GitHub Pages\nCoderefinery - Hosting websites/homepages on GitHub Pages\n\n\n\n\n\nRead the Docs\nRead the Docs is a platform that simplifies the hosting of documentation. It integrates particularly well with Sphinx, allowing for the automatic building and hosting of your project documentation. Read the Docs supports automatic builds and version control, enabling users to switch between different versions of the documentation to match the version of the software they are using. Additionally, it offers support for custom domains.\nIt offers a free service for open-source projects, which includes features like version control and automatic builds. However, for private or commercial projects, Read the Docs requires a paid subscription.\nThe setup is also straightforward:\n\nSign up and import your documentation repository.\nConnect to your GitHub account.\nConfigure your project settings within their dashboard.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nRead the Docs: documentation simplified\nRead the Docs tutorial",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Hosting"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_of_conduct.html",
    "href": "docs/software/documentation/code_of_conduct.html",
    "title": "Code of conduct",
    "section": "",
    "text": "A code of conduct establishes expectations for behavior within your project‚Äôs community, creating an inclusive space that minimizes conflicts and promotes constructive collaboration.\nWhat to include:\n\nPurpose: State the reason for having a code of conduct and its importance for a positive community.\nExpected behavior: Clearly outline the standards of behavior expected from all participants.\nUnacceptable behavior: Specify actions and language that are not tolerated.\nEnforcement: Explain the consequences of violating the code of conduct and how incidents will be handled.\nContact information: Provide contact details for reporting concerns or issues.\n\nYou can add a CODE_OF_CONDUCT.md file at your repository‚Äôs root level. GitHub will automatically detect and display it in your community profile.\n\n\n\n\n\n\n Learn more\n\n\n\n\nContributor Covenant - A widely adopted template for open source communities.\nGitHub‚Äôs guide to adding a code of conduct",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code of conduct"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/python_documentation.html",
    "href": "docs/software/documentation/code_documentation/python_documentation.html",
    "title": "Python code documentation",
    "section": "",
    "text": "Code readability is detailed in a coding style guide.\nCode comments are useful for clarifying complex parts of code, noting why certain decisions were made in specific blocks or lines.\nDocstrings provide a description of the function, class, or module that follows immediately after it is defined, and should contain all the relevant information needed for using them, rather than explaining how the code works. Ideally, every module should have a docstring, and so should every function and class that a module makes available.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation",
      "Python projects"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/python_documentation.html#code-comments",
    "href": "docs/software/documentation/code_documentation/python_documentation.html#code-comments",
    "title": "Python code documentation",
    "section": "Code comments",
    "text": "Code comments\nCode comments are inline annotations meant for developers who read or maintain the source code. They should:\n\nexplain parts that are not intuitive from the code itself\nexplain the purpose of a piece of code (why over how)\nneed to be kept up-to-date as wrong comments are not caught through testing\ndo not replace readable and structured code\ndo not turn old code into commented zombie code (see code smells)\ndo not repeat in natural language what is written in your code, e.g.\n\n# Now we check if the age of a patient is greater than 18\nif age_patient &gt; 18:",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation",
      "Python projects"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/python_documentation.html#docstrings",
    "href": "docs/software/documentation/code_documentation/python_documentation.html#docstrings",
    "title": "Python code documentation",
    "section": "Docstrings",
    "text": "Docstrings\nDocstrings are structured comments, associated with segments (rather than lines) of code which can be used to generate documentation for users (and yourself!) of your project. They allow you to provide documentation to a segment (function, class, method) that is relevant for the user. Docstrings are placed in triple quotes \"\"\" and enable automated generation of API documentation.\nTwo docstring styles are commonly used for their readability:\n\nNumPy styleGoogle style\n\n\ndef func(arg1, arg2):\n    \"\"\"Summary line.\n\n    Extended description of function.\n\n    Parameters\n    ----------\n    arg1 : int\n        Description of arg1\n    arg2 : str\n        Description of arg2\n\n    Returns\n    -------\n    bool\n        Description of return value\n\n    \"\"\"\n    return True\n‚Æï Check out the NumPy style guide or a full example.\n\n\ndef func(arg1, arg2):\n    \"\"\"Summary line.\n\n    Extended description of function.\n\n    Args:\n        arg1 (int): Description of arg1\n        arg2 (str): Description of arg2\n\n    Returns:\n        bool: Description of return value\n\n    \"\"\"\n    return True\n‚Æï Check out the Google style guide or a full example.\n\n\n\n\nDocstring formatting\nPython‚Äôs PEP 257 provides guidelines on how to effectively write docstrings to ensure they are clear, concise, and useful. Some pointers:\n\nThe summary sentence of the docstring should appear on the same line as the opening triple quotes.\nThe closing triple quotes should be placed on a separate line, except for one-line docstrings.\nDocstrings for methods and functions should not have blank lines before or after them.\n\n\n\n\n\n\n\n Example\n\n\n\n\n\ndef find_max(numbers):\n    \"\"\"Find the maximum value in a list of numbers.\n\n    Parameters\n    ----------\n    numbers : iterable\n        A collection of numerical values from which the maximum will be determined.\n\n    Returns\n    -------\n    max_value : `float`\n        The highest number in the given list of numbers.\n    \"\"\"\n    pass\n\n\n\n\nDocstrings for classes should immediately follow the class definition without any preceding blank lines. However, a single blank line should follow the docstring, separating it from subsequent code such as class variables or the init method.\n\n\n\n\n\n\n\n Example\n\n\n\n\n\nclass Circle(object):\n    \"\"\"A circle defined by its radius.\n\n    Parameters\n    ----------\n    radius : `float`\n        The radius of the circle.\n    \"\"\"\n\n    def __init__(self, radius):\n        self.radius = radius\n\n\n\n\nThe content of a docstring must align with the indentation level of the code it documents.\n\n\n\n\n\n\n\n Correct and incorrect examples\n\n\n\n\n\n\n\n\n\ndef get_length(items):\n    \"\"\"Calculate the number of items in the list.\n\n    Parameters\n    ----------\n    items : list\n        A list whose length is to be determined.\n\n    Returns\n    -------\n    length : int\n        The number of items in the list.\n    \"\"\"\n    return len(items)\n\n\ndef get_length(items):\n    \"\"\"Calculate the number of items in the list.\n\nParameters\n----------\nitems : list\n    A list whose length is to be determined.\n\nReturns\n-------\nlength : int\n    The number of items in the list.\n\"\"\"\n    return len(items)\n\n\n\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nBuild API reference from docstrings\nNumpydoc style guide - best practices for docstrings\n\n\n\n\n\nDocstring contents\nFormatting conventions are important for clarity and readability across different APIs or libraries. Here we adhere to the numpydoc convention.\n\nSummaries\nDocstrings should start with a one-sentence summary and if additional clarification is needed, you could add an extended summary. For functions and methods, use imperative voice, framing its summary as a command or instruction that the user can execute through the API. For classes, the summary should clearly describe what the class represents or its primary responsibility.\n\n\nParameters and arguments\nThe Parameters section lists the input parameters of a class, function, or method. It should include the parameter name, type, and a brief description of what the parameter represents. Parameters are listed in the same order as they appear in the function definition.\n\n\n\n\n\n\n Full description and example\n\n\n\n\n\nDescribing parameters\nBasic example:\ndef calcDistance(x, y, x0=0., y0=0., **kwargs):\n    \"\"\"Calculate the distance between two points.\n\n    Parameters\n    ----------\n    x : `float`\n        X-axis coordinate.\n    y : `float`\n        Y-axis coordinate.\n    x0 : `float`, optional\n        X-axis coordinate for the second point (the origin,\n        by default).\n\n        Descriptions can have multiple paragraphs, and lists:\n\n        - First list item.\n        - Second list item.\n    y0 : `float`, optional\n        Y-axis coordinate for the second point (the origin,\n        by default).\n    **kwargs\n        Additional keyword arguments passed to\n        `calcExternalApi`.\n    \"\"\"\n\n\n\n\n\nReturns and Yields\nReturns is an explanation about the returned values and their types, following the same format as Parameters. This is applicable to functions and methods. Use Yields for generators.\n\n\n\n\n\n\n Returns and Yields examples\n\n\n\n\n\n\nDocumenting Returns\nDocumenting Yields\n\n\nBasic example for Returns:Basic example for Yields:\n\n\ndef getCoord(self):\n    \"\"\"Get the point's pixel coordinate.\n\n    Returns\n    -------\n    x : `int`\n        X-axis pixel coordinate.\n    y : `int`\n        Y-axis pixel coordinate.\n    \"\"\"\n    return self._x, self._y\n\n\ndef items(self):\n    \"\"\"Iterate over items in the container.\n\n    Yields\n    ------\n    key : `str`\n        An item's key.\n    value : obj\n        An item's value.\n    \"\"\"\n    for key, value in self._data.items():\n        yield key, value\n\n\n\n\n\n\n\n\nRaises\nFor classes, methods, and functions the Raises section is used to describe exceptions that are explicitly raised.\n\n\n\n\n\n\n Example\n\n\n\n\n\n\nDocumenting Raises\n\nRaises\n------\nIOError\n    Raised if the input file cannot be read.\nTypeError\n    Raised if parameter ``example`` is an invalid type.\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nDocumenting modules\nDocumenting classes\nDocumenting methods and functions\nDocumenting constants and class attributes\nDocumenting class properties\nComplete example module\nnumpydoc example",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation",
      "Python projects"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/code_documentation.html",
    "href": "docs/software/documentation/code_documentation/code_documentation.html",
    "title": "Code documentation",
    "section": "",
    "text": "Good code documentation acts as the bridge between developers and users by clearly explaining the functionality and rationale behind your code. Whether you‚Äôre writing inline comments or structured documentation, the key is to make your code readable, maintainable, and accessible to both current and future contributors.\n\n\n\n Python projects\nCode comments, docstrings, API reference.\n\nLearn more ¬ª\n\n\n\n MATLAB projects\nDocumenting MATLAB projects.\n\nLearn more ¬ª\n\n\n\n R projects\nDocumenting R projects with roxygen2.\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/reusing_projects.html",
    "href": "docs/software/development_workflow/reusing_projects.html",
    "title": "Project templates and reusability",
    "section": "",
    "text": "Templates can help you to standardize your software development process.\n\n\nYou can turn an existing repository into a template, so you and others can generate new repositories with the same directory structure, branches, and files. Note, the template repository cannot include files stored using Git LFS.\n\n\n\n\n\n\n Repository templates\n\n\n\n\nCreating a template repository\nRepository template example to make your code more compliant with FAIR principles\n\n\n\n\n\n\nCookiecutter creates Python projects from project templates. The advantage of using Cookiecutter is that new projects are set up quickly from a standardized template structure and can include everything needed to get started on a project, such as directory layouts, sample code, and even integrations with tools and services.\n\n\n\n\n\n\n Tutorials\n\n\n\n\nTutorial for Cookiecutter\nFor installation instructions, have a look at Cookiecutter installation instructions.\n\n\n\n\n\n\n\n\n\n Cookiecutter templates\n\n\n\n\nCookiecutter templates on GitHub\nCookiecutter PyPackage: template for distributing Python libraries.\n\nGitHub - cookiecutter-pypackage\nGitHub - Netherlands eScience Center template\n\nCookiecutter Machine Learning: template for machine learning projects.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project templates and reusability"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/reusing_projects.html#project-templates",
    "href": "docs/software/development_workflow/reusing_projects.html#project-templates",
    "title": "Project templates and reusability",
    "section": "",
    "text": "Templates can help you to standardize your software development process.\n\n\nYou can turn an existing repository into a template, so you and others can generate new repositories with the same directory structure, branches, and files. Note, the template repository cannot include files stored using Git LFS.\n\n\n\n\n\n\n Repository templates\n\n\n\n\nCreating a template repository\nRepository template example to make your code more compliant with FAIR principles\n\n\n\n\n\n\nCookiecutter creates Python projects from project templates. The advantage of using Cookiecutter is that new projects are set up quickly from a standardized template structure and can include everything needed to get started on a project, such as directory layouts, sample code, and even integrations with tools and services.\n\n\n\n\n\n\n Tutorials\n\n\n\n\nTutorial for Cookiecutter\nFor installation instructions, have a look at Cookiecutter installation instructions.\n\n\n\n\n\n\n\n\n\n Cookiecutter templates\n\n\n\n\nCookiecutter templates on GitHub\nCookiecutter PyPackage: template for distributing Python libraries.\n\nGitHub - cookiecutter-pypackage\nGitHub - Netherlands eScience Center template\n\nCookiecutter Machine Learning: template for machine learning projects.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project templates and reusability"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/reusing_projects.html#reusing-projects-and-repositories",
    "href": "docs/software/development_workflow/reusing_projects.html#reusing-projects-and-repositories",
    "title": "Project templates and reusability",
    "section": "Reusing projects and repositories",
    "text": "Reusing projects and repositories\nOne of the easiest ways to reuse code across projects is by packaging it into an installable library that can be used as a dependency. Alternatively, you can integrate external code into your project using Git submodules or Git subtree.\n\n\n\n\n\n\nPractices to avoid\n\n\n\n\nStoring commonly-used folders in a separate folder on your system and adding the folder to the PATH. Other users/developers will not have access to these folders.\nDirect copy-and-pasting of code as you lose any upstream changes to the external repository.\n\n\n\n\nWhat‚Äôs the Difference?\n\n\n\n\n\n\n\n\nFeature\nGit Submodules\nGit Subtree\n\n\n\n\nHow it works\nAdds an external repository inside your project as a separate Git reference.\nMerges an external repository‚Äôs contents into your project‚Äôs directory structure.\n\n\nVersion Control\nTracks a specific commit of the external repository (not automatically updated).\nThe external repository‚Äôs commits are fully merged into your project‚Äôs commit history.\n\n\nUpdating\nRequires running git submodule update --remote to pull new changes.\nUpdates by merging changes from the external repository into your project.\n\n\nIdeal For\nKeeping external code separate while still using it in your project.\nFully integrating external code while keeping its history.\n\n\n\nIn short:\n\nUse Git submodules when you want to include an external repository but keep it separate, track its exact version, and update it manually.\nUse Git subtree if you want to fully integrate an external repository‚Äôs code into your project while keeping its commit history.\n\n\n\nGit submodules\nA Git submodule allows you to add a separate Git repository inside another repository as a subdirectory. It is a record that points to a specific commit in another external repository. Submodules are useful for incorporating external code or libraries into your project while keeping them separate and easily updatable.\n\n\n\n\n\n\nGit submodule commands\n\n\n\n\n\n\nAdding a submodule\nTo add an external repository as a submodule inside your project, use:\ngit submodule add &lt;repo-url&gt;\n\n\nCloning a repository with submodules\nWhen cloning a repository that contains submodules, follow these steps: 1. Clone the repository:\ngit clone &lt;repo-url&gt;\n\nInitialize the submodules:\n\ngit submodule init\n\nFetch the submodule content:\n\ngit submodule update\nAlternatively, you can use the shorthand command to clone and initialize submodules:\ngit clone --recurse-submodules &lt;repo-url&gt;\n\n\nUpdating submodules\nTo update the submodules to the latest commit, use:\ngit submodule update --remote\n\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nSimplified Git submodules tutorial\nGuide on Git submodules - comprehensive guide that covers everything from the basics to advanced workflows\n\n\n\n\n\n\n\n\n\nIf you are using GitHub Desktop\n\n\n\n\n\nIf you are using GitHub Desktop, be aware that there can be limitations when working with submodules. While GitHub Desktop supports basic submodule functionality, some operations may require using the command line. Known issues include\n\ndifficulties in initializing submodules\nswitching branches with submodules\nvisualizing submodule changes.\n\nFor more details, check out this discussion or visit the GitHub Desktop issue tracker.\n\n\n\n\n\nGit subtree\nUnlike Git submodules, Git subtree merges the history of one repository into another as a subdirectory. This makes the external repository‚Äôs files appear as if they are part of your project while still allowing updates.\nFor more details, check out this Git subtree guide.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project templates and reusability"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_management.html",
    "href": "docs/software/development_workflow/project_management.html",
    "title": "Project management",
    "section": "",
    "text": "Git is a distributed version control system that enables you to track changes in your code over time. Platforms like GitHub, GitLab and Bitbucket extend the features of git by providing a centralized location for storing repositories, collaborating, and providing powerful tools to plan, organize, and track your work efficiently.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_management.html#version-control-platforms",
    "href": "docs/software/development_workflow/project_management.html#version-control-platforms",
    "title": "Project management",
    "section": "Version control platforms",
    "text": "Version control platforms\nThe choice between GitHub, GitLab and Bitbucket depends on your required features, privacy and other preferences, but all are Git-based platforms for version control. While numerous detailed comparisons exist online, here we will focus on GitHub.\n\n\n\n\n\n\nTU Delft GitLab\n\n\n\nTU Delft has its own GitLab instance hosted on campus. For more information, please visit the documentation and our TU Delft GitLab guides in the Computing Infrastracture section.\n Choosing a Repository Manager - for TU Delft Researchers\n\n\nSimilarly, whether you are using a version control system through your terminal or Integrated Development Environment (IDE), or using a GUI like GitHub Desktop, the core functionality remains the same.\n\n\n\n\n\n\n Learn more about GitHub Desktop\n\n\n\n\n\nGitHub Desktop is a great choice if you are just starting out with version control, providing a user-friendly graphical interface that simplifies Git operations. It makes it easy to visualize changes, create branches, and manage pull requests without needing to use command-line Git commands.\n Getting started with GitHub Desktop",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_management.html#github-issues",
    "href": "docs/software/development_workflow/project_management.html#github-issues",
    "title": "Project management",
    "section": "GitHub issues",
    "text": "GitHub issues\nGitHub issues help you keep track of tasks, bugs, feature ideas in your project. They are like a to-do list items that everyone on your team can see and update.\nHow to use issues effectively:\n\nUse descriptive titles: Write short, specific titles that make it easy to understand what the issue is about.\nProvide detailed descriptions: Include all relevant information, steps to reproduce (if reporting a bug), and expected outcomes in the issue description. This ensures that anyone working on the issue has all the necessary context.\nUse labels: Labels act like tags to help you organize and prioritize tasks.\nAssign people: By assigning someone (or yourself) you let others know that you are picking up and working on this issue.\nLink related issues: Connect related work by linking issues to provide context (add #issue_number to reference an issue).\n\nGitHub Issues make it easier to manage your project, collaborate with others, and keep track of progress. As your project grows, you can use additional tools like milestones and project boards while still benefiting from well-organized issues.\n\n\n\n\n\n\n Learn more\n\n\n\n\nQuickstart for GitHub Issues\nMastering GitHub Issues",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_management.html#project-boards",
    "href": "docs/software/development_workflow/project_management.html#project-boards",
    "title": "Project management",
    "section": "Project boards",
    "text": "Project boards\nProject boards on GitHub are designed for planning, organizing, and tracking work within a project. They serve as visual management interfaces that integrate directly with GitHub issues and pull requests. Project boards can be configured as Kanban boards, tables, or roadmaps, offering various layouts to suit different project management needs. Project boards can be particularly useful for visualizing the overall progress of your project and identifying bottlenecks in your workflow. They provide a high-level view that complements the detailed tracking offered by issues.\n\nMilestones\nUsing milestones you can break down large projects into smaller, more manageable parts. While project boards offer a visual, dynamic interface to manage and track your tasks, milestones serve as structured markers that help you monitor progress toward key project phases/goals.\n\n\n\n\n\n\n Learn more\n\n\n\n\nExample project board - TU Delft Astrodynamics Toolkit (Tudat)\nDefine a milestone\nGitHub Guides for Issues and Projects",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_management.html#managing-projects-on-github",
    "href": "docs/software/development_workflow/project_management.html#managing-projects-on-github",
    "title": "Project management",
    "section": "Managing projects on GitHub",
    "text": "Managing projects on GitHub\nWhen managing your project on GitHub, we recommend two approaches:\n\na simplified approach using only issues, or\na more structured approach using milestones and project boards.\n\nBoth methods have advantages, and the choice depends on the size of the project, its complexity, and your preferences.\n\nSimplified approachStructured approach\n\n\nYou can use a simplified approach and just track your progress in the form of issues and work without defining milestones or using a project board. This can be particularly useful for smaller projects or when you are just starting out with GitHub.\nIn this approach, you would:\n\nCreate issues for each task or feature you need to work on.\nOptionally, use labels to categorize and prioritize your issues.\nAssign issues to yourself or team members/collaborators.\nUse comments to update progress and discuss any challenges.\nClose issues as you complete them.\n\nThis method allows for a flexible workflow while still maintaining a good level of organization and transparency in your project. If your project grows or becomes more complex, you can always adopt milestones and project boards for more structured project management.\n\n\nWhen working on a big project, it‚Äôs helpful to create a roadmap - a simple plan that outlines what needs to be done and when. A roadmap gives you and your team a clear view of what‚Äôs happening now and what‚Äôs coming next.\nTo create a roadmap, it is useful to map out the key milestones and the tasks needed to accomplish the milestones. You can then use GitHub milestones and project boards to track progress and manage your project:\n\nDefine key milestones.\nCreate a milestone in GitHub\nAdd related issues to your milestone.\nSet up a project board.\nAdd issues to your project board.\nUse task lists in your issues to break down the work.\nAssign tasks to team members.\nLinking milestones, issues and pull requests to track progress.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_management.html#github-benefits-for-researchers-and-organisations",
    "href": "docs/software/development_workflow/project_management.html#github-benefits-for-researchers-and-organisations",
    "title": "Project management",
    "section": "GitHub benefits for researchers and organisations",
    "text": "GitHub benefits for researchers and organisations\nResearchers at TU Delft are eligible to receive GitHub Educational benefits, which includes\n\nGitHub Team plan at no cost (check out the benefits)\nGitHub codespaces\nGitHub pages for private repositories\nAnd more!\n\nTo qualify for the benefits, you must:\n\nHave a GitHub account\nBe an educator, faculty member, or researcher at a recognized educational institution\nBe able to provide documentation from your institute demonstrating your employment\n\n\n\n\n\n\n\n Apply for Educational benefits",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/envs_dependencies/r_envs_dependencies.html",
    "href": "docs/software/development_workflow/envs_dependencies/r_envs_dependencies.html",
    "title": "Environment and dependency management in R",
    "section": "",
    "text": "R users often rely on RStudio Projects and renv to manage their development environments. RStudio Projects organize your workspace by managing file paths and configurations, while renv tracks and restores package dependencies to ensure reproducibility. Together, they provide a structured and reliable workflow for managing R projects.\nAlthough Conda can be used to create isolated R environments, it is less common in R workflows. Conda is most useful when managing multiple R versions, working in a Python + R setup, or handling system dependencies that are difficult to install through CRAN.\n\nProjects\nRStudio Projects provide an organized workspace for your analyses and scripts, ensuring that file paths and working directories remain consistent across sessions. When you open an RStudio Project, it automatically sets the project‚Äôs root directory as your working directory and loads project-specific settings stored in the .Rproj file. Using RStudio Projects helps you to keep your code, data, and output bundled together, and avoid issues with file paths.\nCreating a new RStudio Project:\n\nIn RStudio, go to File ‚Üí New Project.\nChoose whether to create a new directory, use an existing directory, or clone a project.\nFollow the prompts to configure your project settings.\n\n\n\nrenv\nThe renv package manages R package dependencies within a project. It creates a reproducible snapshot of your package environment, ensuring that collaborators (or your future self) can recreate the exact setup. Some key renv commands:\nInitialize renv in your project:\n# From your R console within the project directory:\nrenv::init()\nThis creates a dedicated library and a renv.lock file that tracks all installed packages. If a renv.lock file exists, renv::init() will automatically install the recorded dependencies. Otherwise, it sets up a new environment.\nCreate a snapshot of your dependencies:\nrenv::snapshot()\nThis updates the renv.lock file to reflect the current package versions in your project.\nTo restore an environment from a lockfile:\nrenv::restore()\nThis reinstalls packages according to the renv.lock file and reconstructs the environment.\n\n\n\n\n\n\n Learn more\n\n\n\n\nUsing RStudio Projects\nrenv for R",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Environments and dependencies",
      "R"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/envs_dependencies/matlab_envs_dependencies.html",
    "href": "docs/software/development_workflow/envs_dependencies/matlab_envs_dependencies.html",
    "title": "Environment and dependency management in MATLAB",
    "section": "",
    "text": "MATLAB does not use virtual environments like Python, where isolated environments manage dependencies. Instead, MATLAB handles project-specific dependencies using:\n\nToolboxes - Pre-packaged libraries that must be licensed and available\nMATLAB projects - A feature that manages paths and environments for a project\nPath management - Manually adding paths to the MATLAB search path with addpath and rmpath\n\nTo check dependencies in a project:\n\nUse requiredfilesandproducts to identify required MathWorks toolboxes for a script of function.\nUse the the Dependency Analyzer to detect file dependencies.\n\n\nCustom MATLAB Dependency Manager\nTo offer a solution for managing dependencies in MATLAB through a dependency file, we have created a Dependency Manager:\n DependencyManager",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Environments and dependencies",
      "MATLAB"
    ]
  },
  {
    "objectID": "docs/software/containers/intro.html",
    "href": "docs/software/containers/intro.html",
    "title": "Introduction to containers",
    "section": "",
    "text": "Just as you document your software dependencies, it may be useful to record and manage your development environments. This may involve documenting the specific configurations, tools, and versions used during development to ensure that everything runs consistently across different setups.\nBy recording your environments, you create a reproducible framework that significantly reduces the infamous ‚Äúit works on my machine‚Äù syndrome, where code runs on one machine but fails on others.\nEnvironment management includes specifying your operating system, programming language (and their versions), system libraries, and any other software or tools required. This practice not only helps in maintaining consistency across development, testing, and production stages but also streamlines onboarding for new team members, as they can quickly set up their environment to match the recorded specifications."
  },
  {
    "objectID": "docs/software/containers/intro.html#introduction-to-containers",
    "href": "docs/software/containers/intro.html#introduction-to-containers",
    "title": "Introduction to containers",
    "section": "",
    "text": "Just as you document your software dependencies, it may be useful to record and manage your development environments. This may involve documenting the specific configurations, tools, and versions used during development to ensure that everything runs consistently across different setups.\nBy recording your environments, you create a reproducible framework that significantly reduces the infamous ‚Äúit works on my machine‚Äù syndrome, where code runs on one machine but fails on others.\nEnvironment management includes specifying your operating system, programming language (and their versions), system libraries, and any other software or tools required. This practice not only helps in maintaining consistency across development, testing, and production stages but also streamlines onboarding for new team members, as they can quickly set up their environment to match the recorded specifications."
  },
  {
    "objectID": "docs/software/containers/intro.html#why-use-containers",
    "href": "docs/software/containers/intro.html#why-use-containers",
    "title": "Introduction to containers",
    "section": "Why use containers?",
    "text": "Why use containers?\nContainers remove the need for manual installation or troubleshooting, ensuring that software runs consistently across different machines. Containers act as a self-contained unit that bundle everything needed to run software, including dependencies and system libraries, into a single package known as an image.\nThe definition files, like Dockerfiles or Singularity definition files, are essentially instruction manuals to build a container image.\n\n\n\n\n\n\nAn analogy for a container image\n\n\n\n\n\nConsider a container image like a detailed movie script that outlines every scene. When the movie is shot (i.e., the container is executed), a temporary set is built where all filming occurs in a controlled environment. Once filming ends, the set is dismantled, but the script remains unchanged, allowing the software to be re-executed with the same consistent results every time, just as each scene is reproduced faithfully with the same script.\n\n\n\nContainers can be useful for various purposes:\n\nIf installing certain software is complex or incompatible with your operating system, you can use a pre-built container image to run the software seamlessly.\nLikewise, if you want to make sure that the people you are working with use the exact same environment, you could provide them with an image of your container.\nIf you are facing issues due to different system architectures you can distribute a definition file to build an image that tailors to different machines. While it might not replicate your environment exactly, it often provides a sufficiently close alternative.\n\nPopular containerisation solutions:\n\nDocker and Podman are great for general software development.\nSingularity is tailored for high-performance computing (HPC) environments.\nFor managing and scaling containers across multiple machines, tools like Kubernetes are commonly used.\n\nDocker‚Äôs official samples and examples\n\n\n\n\n\n\nFurther reading\n\n\n\n\nRecording environments lesson on CodeRefinery\nCarpentries incubator lesson on Docker\nGuides and manuals for Docker\nSingularity documentation"
  },
  {
    "objectID": "docs/software/containers/intro.html#advantages-and-disadvantages-of-using-containers",
    "href": "docs/software/containers/intro.html#advantages-and-disadvantages-of-using-containers",
    "title": "Introduction to containers",
    "section": "Advantages and disadvantages of using containers",
    "text": "Advantages and disadvantages of using containers\nContainers have gained widespread popularity due to their significant benefits in solving various challenges:\n\nThey enable a smooth transition of workflows across different operating systems and configurations.\nThey address the common issue of software behaving differently on different machines by providing a consistent runtime environment.\nFor software with nested dependencies, containers can be a vital tool for ensuring long-term reproducibility.\nContainers package software in isolated files, simplifying management, installation, and removal compared to traditional methods.\n\nBut it is important to consider the downsides:\n\nThe convenience of containers might lead to overlooking underlying software installation issues and not adhering to good software development practices.\nThere‚Äôs a risk of creating a new form of dependency - software that ‚Äúonly works in a specific container‚Äù, which could limit flexibility and interoperability.\nContainer images can grow in size substantially, especially if not carefully managed.\nModifying existing containers can sometimes be challenging, requiring a good understanding of the container‚Äôs configuration.\nEnsuring container security is vital, as misconfigurations can expose vulnerabilities.\n\n\n\n\n\n\n\nCaution\n\n\n\nIt‚Äôs crucial to source your container images from reputable and official channels. There have been instances where images were found to be malicious, so it is very important to apply the same caution as when installing software packages from untrusted sources.\nAlways download images from trusted sources like Docker Hub. Utilize container scanning tools, such as Docker scanning tools to mitigate risks from malicious images."
  },
  {
    "objectID": "docs/software/code_quality/refactoring.html",
    "href": "docs/software/code_quality/refactoring.html",
    "title": "Refactoring",
    "section": "",
    "text": "‚ÄúAlways leave the code you‚Äôre editing a little better than you found it.‚Äù\nRobert C. Martin (Uncle Bob)\n\n\nWhat is refactoring?\nRefactoring is the process of restructuring existing code without changing its external behavior. It improves maintainability and readability, making future developments smoother and reducing the likelihood of bugs. Key benefits include:\n\nImproving readability - Writing code that‚Äôs easier to understand, benefits both yourself and future developers.\nReducing complexity - Simplifying complex structures by breaking down large functions or removing unnecessary dependencies.\nOptimizing design - Creating a more robust and adaptable codebase for long-term growth.\nEliminating redundancies - Removing duplicate or unnecessary code.\nEnsuring consistency - Following a consistent coding style for a cleaner, more maintanable codebase.\n\n\n\nWhen should you refactor?\n\n\n\nCC-BY-4.0 ¬© 2021 Balaban et al.\n\n\n\nRule of three: If you find yourself writing the same or similiar code for the third time, it‚Äôs time to refactor.\nBefore adding a feature: Cleaning up existing code makes it easier to integrate a new functionality.\nWhen fixing a bug: Cleaning up surrounding code can help uncover and fix the issue faster.\nDuring code reviews: Refactoring during code reviews can prevent issues from becoming part of the public codebase and streamline the development process.\nWhen you spot a code smell: Addressing code smells early prevents them from evolving into more serious bugs.\n\n\n Learn more: When to refactor?\n\n\n\nHow to refactor code effectively?\nRefactoring should be done gradually, improving code in small controlled steps without introducing new functionalities. Keep these principles in mind:\n Maintain clean code - Aim for clarity, simplicity, and readability.\n Avoid adding new features - Focus on improving structure, not functionality.\n Ensure tests pass - Verify that all existing tests still succeed to prevent new bugs.\n\n Learn more: How to refactor?\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nRefactoring techniques from Refactoring.Guru\neScience Center - Lesson on refactoring\nThe Alan Turing Institute - Refactoring",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Refactoring"
    ]
  },
  {
    "objectID": "docs/software/code_quality/index.html",
    "href": "docs/software/code_quality/index.html",
    "title": "Code quality",
    "section": "",
    "text": "‚ÄúEveryone knows that debugging is twice as hard as writing a program in the first place. So if you‚Äôre as clever as you can be when you write it, how will you ever debug it?‚Äù\nBrian W. Kernighan\n\nThe quality of your research software plays a crucial role in its reliability, maintainability, and scalability. Writing clean code means developing code that is easy to read, understand - not for just you, but for others as well. Well-structured code simplifies debugging and allows for future modifications and extensions, ensuring your software remains useful and adaptable over time.\n\n\n\n Code Style\nConventions and guidelines used to write and format code.\n\nLearn more ¬ª\n\n\n\n Refactoring\nRestructuring existing code without changing its external behavior.\n\nLearn more ¬ª\n\n\n\n Code Smells\nSymptoms of poor code quality that can indicate deeper problems.\n\nLearn more ¬ª\n\n\n\n Online services\nServices that provide code quality analysis.\n\nLearn more ¬ª\n\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nThe Turing Way - Writing Robust Code\nUtrecht University - Workshop on Writing Reproducible Code",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/side_effects.html",
    "href": "docs/software/code_quality/code_smells/side_effects.html",
    "title": "Side effects and external state",
    "section": "",
    "text": "Side effects occur when a function modifies external state or interacts with the outside world beyond simply returning a value. This makes code less predictable, harder to test, and more difficult to debug.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Side effects"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/side_effects.html#symptoms",
    "href": "docs/software/code_quality/code_smells/side_effects.html#symptoms",
    "title": "Side effects and external state",
    "section": "Symptoms",
    "text": "Symptoms\n\nUnexpected changes to the global state\nNon-deterministic behavior\nHidden dependencies\n\n\n\n\n\n\n\nTip\n\n\n\nPure functions are deterministic (always return the same output for the same input) and have no side-effects.\nInstead, non-pure functions often:\n\nModify global variables or shared state, leading to unintended behavior.\nChange input parameters (mutating function arguments).\nPerform I/O operations like reading from or writing to files, databases, or APIs.\nGenerate random numbers, making them non-deterministic.\nDepend on external state, meaning results may change due to external factors.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Side effects"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/side_effects.html#example---function-with-side-effects",
    "href": "docs/software/code_quality/code_smells/side_effects.html#example---function-with-side-effects",
    "title": "Side effects and external state",
    "section": "Example - Function with side effects",
    "text": "Example - Function with side effects\n# Modifies global state (side effect)\ndata = []\n\ndef add_item(item):\n    data.append(item)  # Changes an external variable\n\nadd_item(\"A\")\nprint(data)  # ['A'] - Output depends on previous calls\n\nSolutions\n\n1. Separate pure and non-pure functions\nKeep your computational logic (pure) separate from side-effect operations (non-pure).\ndef process_data(data):  # Pure function: no external state modification\n    return [x**2 for x in data]\n\ndef save_to_file(filename, data):  # Non-pure: writes to a file\n    with open(filename, \"w\") as f:\n        f.write(\"\\n\".join(map(str, data)))\n\n# Usage\nnumbers = [1, 2, 3]\nprocessed = process_data(numbers)\nsave_to_file(\"output.txt\", processed)\n\n\n2. Avoid mutating global variables\nUse function parameters and return values instead of modifying external variables.\ndef add_item(data, item):\n    return data + [item]  # Returns a new list instead of modifying global state\n\ndata = []\ndata = add_item(data, \"A\")  # Safe: no side effects",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Side effects"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/side_effects.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/side_effects.html#key-takeaways",
    "title": "Side effects and external state",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nEnsure that each function or module has a single responsibility.\nBreak down complex functions into smaller, focused functions that perform specific tasks.\nIsolate non-pure functions with side effects from pure functions.\n\n\n\n\nCC-BY-4.0 CodeRefinery",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Side effects"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/long_method.html",
    "href": "docs/software/code_quality/code_smells/long_method.html",
    "title": "Long Method",
    "section": "",
    "text": "‚ÄúFunctions should do one thing. They should do it well. They should do it only.‚Äù\nRobert C. Martin (Uncle Bob)\nA ‚Äúlong method‚Äù is a common code where a method or function becomes overly long and handles multiple responsibilities at once. This makes the code hard to read, understand, test, and maintain. Long methods often indicate that a function is doing too much and may benefit from being broken into smaller, more focussed helper functions.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Long method"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/long_method.html#symptoms",
    "href": "docs/software/code_quality/code_smells/long_method.html#symptoms",
    "title": "Long Method",
    "section": "Symptoms",
    "text": "Symptoms\nA long method often:\n\nPerforms multiple tasks rather than a single, well-defined responsibility.\nHas deeply nested control structures, making it harder to follow.\nIncludes multiple sections of logic that could be extracted into separate functions.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Long method"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/long_method.html#example---long-method",
    "href": "docs/software/code_quality/code_smells/long_method.html#example---long-method",
    "title": "Long Method",
    "section": "Example - Long method",
    "text": "Example - Long method\nBelow is an example of a function that is doing too much:\ndef load_data(filepath: str):\n    # Check if data file exists\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(\"File not found\")\n    \n    _, extension = os.path.splitext(filepath)\n\n    # Load data based on file extension    \n    if extension == \".json\":\n        with open(filepath, \"r\") as file:\n            # If file extension is .json: load json data\n            data = json.load(file)\n    elif extension == \".pickle\":\n        with open(filepath, \"rb\") as file:\n            # If file extionsion is .pickle: load pickled data\n            data = pickle.load(file)\n    elif extension == \".csv\":\n        # If file extionsion is .csv: load cvs data\n        data = read_csv(filepath)\n    else:\n        raise ValueError(f\"Unsupported file format: {extension}\")\n    \n    # Verify content of data set\n    if not isinstance(data, (list, dict, pd.DataFrame)):\n        raise ValueError(\"Invalid data format\")\n\n    return data\n\nIssues\n\nThe function is handling file validation, data loading, and data verification, which are separate concerns.\nIt is now difficult to test individual parts in isolation.\nAdding support for new file types requires modifying a large function.\n\n\n\nSolution\nIdentify logical blocks of code within the long method/function and extract them into separate methods with descriptive names. We should aim to make each method responsible for a singular task and compose more complex functionalities from modular components.\n\nExample solution long method\ndef load_data(filepath: str) -&gt; Data:\n    verify_filepath(filepath: str)  \n    data = read_data(filepath: str)\n    verify_data(data)\n    return data\n\n# Helper function to verify file path\ndef verify_filepath(filepath: str):\n    if not os.path.exists(filepath):\n        raise FileNotFoundError(\"File not found\")\n\n# Helper function to read data from file based on its extension\ndef read_data(filepath: str) -&gt; Data:\n    # Extract file extension\n    _, extension = os.path.splitext(filepath)\n    \n    # Create dictionary mapping file extensions to read functions\n    data_types = {\n        \".json\": read_from_json,\n        \".pickle\": read_from_pickle,\n        \".csv\": read_from_csv,\n    }\n\n    # Select read function based on file extension\n    try:\n        read_function = data_types[extension]\n    except KeyError:\n        raise ValueError(f\"Unsupported file format: {extension}\")\n    return data_types[extension](filepath)\n\n# Placeholder for helper functions to read data from different file formats\ndef read_from_json(filepath: str): pass\ndef read_from_pickle(filepath: str): pass\ndef read_from_csv(filepath: str): pass",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Long method"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/long_method.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/long_method.html#key-takeaways",
    "title": "Long Method",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nBreaking a long method into smaller, well-named helper functions makes the code easier to read and understand. ‚Äì Each function now has a single responsibility, reducing complexity and making future modifications more manageable. ‚Äì With isolated functions, individual components can be tested independently, leading to more reliable and maintainable code.\n\n By breaking the long method into smaller helper functions, we improve the overall structure and maintainability of the code.\n\n\n\n\n\n\n Learn more\n\n\n\n\neScience Center - Slides on writing modular code\nCarpentries Incubator - Modular Code Development",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Long method"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/inappropriate_intimacy.html",
    "href": "docs/software/code_quality/code_smells/inappropriate_intimacy.html",
    "title": "Inappropriate Intimacy",
    "section": "",
    "text": "This code smell occurs when one part of the system knows too much about the internal details of another, leading to tight coupling. When components are too dependent on each other, it becomes difficult to modify or extend the system without breaking other parts.\nA good design principle to follow is the Law of Demeter, also known as the ‚ÄúDon‚Äôt talk to strangers‚Äù rule. It suggests that a module should only interact with its direct dependencies rather than deeply nested objects.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Inappropriate intimacy"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/inappropriate_intimacy.html#symptoms",
    "href": "docs/software/code_quality/code_smells/inappropriate_intimacy.html#symptoms",
    "title": "Inappropriate Intimacy",
    "section": "Symptoms",
    "text": "Symptoms\n\nA class accesses properties of another object‚Äôs properties, exposing too much detail.\nChanges in one part of the code require changes in multiple other places.\nBecause multiple classes depend on each other‚Äôs internal structures, small changes can cause unintended issues.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Inappropriate intimacy"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/inappropriate_intimacy.html#example---violating-law-of-demeter",
    "href": "docs/software/code_quality/code_smells/inappropriate_intimacy.html#example---violating-law-of-demeter",
    "title": "Inappropriate Intimacy",
    "section": "Example - Violating Law of Demeter",
    "text": "Example - Violating Law of Demeter\nIn this example, a SensorSystem directly accesses the TemperatureSensor internal attributes, creating tight coupling.\nclass TemperatureSensor:\n    def __init__(self, temperature):\n        self.temperature = temperature  # Internal detail exposed\n\nclass SensorSystem:\n    def __init__(self, sensor):\n        self.sensor = sensor\n\n    def get_temperature(self):\n        # Law of Demeter violation: Directly accessing sensor's attribute\n        return self.sensor.temperature\n\n# Usage\nsensor = TemperatureSensor(25)\nsystem = SensorSystem(sensor) \ntemperature = system.get_temperature()\nprint(temperature)  # 25\nProblem: The SensorSystem class depends on the internal structure of TemperatureSensor. If the way temperature is stored changes (e.g., a new sensor model), SensorSystem must also change.\n\nSolutions\n\nExample solution - Using getter methods\nInstead of directly accessing attributes, define getter methods in TemperatureSensor to limit exposure.\nclass TemperatureSensor:\n    def __init__(self, temperature):\n        self._temperature = temperature  # Use a private variable\n\n    def get_temperature(self):\n        return self._temperature  # Encapsulated access\n\nclass SensorSystem:\n    def __init__(self, sensor):\n        self.sensor = sensor\n\n    def get_temperature(self):\n        return self.sensor.get_temperature()  # Indirect access through method\n\n# Usage\nsensor = TemperatureSensor(25)\nsystem = SensorSystem(sensor)\nprint(system.get_temperature())  # 25\nWhy is this better?\n\nThe SensorSystem no longer needs to know the internal structure of TemperatureSensor.\nIf TemperatureSensor changes, only get_temperature() needs to be updated, not every place it‚Äôs used.\n\n\n\nExample solution - Removing the dependency\nA better design is to pass only the needed data instead of an entire object.\nclass SensorSystem:\n    def __init__(self, temperature):\n        self.temperature = temperature\n\n    def get_temperature(self):\n        return self.temperature  # Works directly with the value\n\n# Usage\ntemperature = 25\nsystem = SensorSystem(temperature)\nprint(system.get_temperature())  # 25\nWhy is this better?\n\nSensorSystem no longer depends on TemperatureSensor, making it more modular and reusable.\nWorks even if the source of temperature data changes (e.g., from a file, API, or another sensor).\n\n\n\n\n\n\n\nBalance between dependecy injection and encapsulation. If the data is simple and does not require complex operations, pass it directly. If the data is complex or requires additional logic, encapsulate it in a class.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Inappropriate intimacy"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/inappropriate_intimacy.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/inappropriate_intimacy.html#key-takeaways",
    "title": "Inappropriate Intimacy",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nFollow the Law of Demeter - Only interact with direct dependencies.\nEncapsulate data - Use getters and setters to access and modify data.\nReduce dependencies - pass only the necessary information to other components.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nRealPython - Python Classes\nRealPython - Getters and Setters",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Inappropriate intimacy"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/duplication.html",
    "href": "docs/software/code_quality/code_smells/duplication.html",
    "title": "Duplicated code",
    "section": "",
    "text": "‚ÄúPerfection is achieved, not when there is nothing more to add, but when there is nothing left to take away.‚Äù\nAntoine de Saint-Exup√©ry\nDuplicated code occurs when similar or identical blocks of code appear multiple times within a codebase. This can increase maintenance efforts, as changes in one place might require corresponding changes elsewhere, leading to inconsistencies and higher changes or errors.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Code duplication"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/duplication.html#symptoms",
    "href": "docs/software/code_quality/code_smells/duplication.html#symptoms",
    "title": "Duplicated code",
    "section": "Symptoms",
    "text": "Symptoms\n\nThe same logic appears in multiple places, sometimes with minor variations.\nFixing a bug required modifying the same code in multiple places.\nAdding a new feature results in copy-pasting existing code rather than reusing it.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Code duplication"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/duplication.html#example---duplicate-code-in-functions",
    "href": "docs/software/code_quality/code_smells/duplication.html#example---duplicate-code-in-functions",
    "title": "Duplicated code",
    "section": "Example - Duplicate code in functions",
    "text": "Example - Duplicate code in functions\ndef time_of_flight_ball(initial_velocity, launch_angle):\n    g = 9.81  # Earth's gravity (m/s¬≤)\n    return (2 * initial_velocity * np.sin(launch_angle)) / g\n\ndef time_of_flight_rocket(initial_velocity, launch_angle):\n    g = 9.81\n    return (2 * initial_velocity * np.sin(launch_angle)) / g\n\ndef time_of_flight_satellite(initial_velocity, launch_angle):\n    g = 9.81\n    return (2 * initial_velocity * np.sin(launch_angle)) / g\n\nSolution\n\nRefactor the code to accept parameters as arguments, instead of hard-coding them.\nExtract common functionality into functions or methods.\nRefactor duplicated code into higher-level abstractions.\nMake use of utility functions to centralize common code and avoid duplication.\n\ndef time_of_flight(initial_velocity, launch_angle, gravity=9.81):\n    \"\"\"Compute time of flight for any projectile.\"\"\"\n    return (2 * initial_velocity * np.sin(launch_angle)) / gravity\n\n# Usage\ntof_ball = time_of_flight(30, np.pi/4)       # Time of flight for a ball\ntof_rocket = time_of_flight(100, np.pi/3)    # Time of flight for a rocket\ntof_mars_probe = time_of_flight(300, np.pi/6, gravity=3.71)  # Gravity adjusted for Mars",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Code duplication"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/duplication.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/duplication.html#key-takeaways",
    "title": "Duplicated code",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nExtracting common functionality into functions or methods can help reduce duplication and improve code reuse.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Code duplication"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/dead_code.html",
    "href": "docs/software/code_quality/code_smells/dead_code.html",
    "title": "Commented-out code",
    "section": "",
    "text": "Dead code refers to unused or unreachable code that remains in the codebase but serves no functional purpose. Commented-out code consists of inactive code blocks that developers have disabled rather than deleting. Both contribute to clutter and reduce maintainability.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Commented out code"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/dead_code.html#symptoms",
    "href": "docs/software/code_quality/code_smells/dead_code.html#symptoms",
    "title": "Commented-out code",
    "section": "Symptoms",
    "text": "Symptoms\n\nUnused variables or functions.\nConditional blocks that never execute.\nLarge blocks of commented-out code.\nUsing comments to disable code to change the behavior of the code.\n\n\n\n\n\n\n\nTip\n\n\n\nDo not use comments to change the behavior of the code. Instead, make use of input parameters or configuration settings to control the behavior of the code.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Commented out code"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/dead_code.html#solution",
    "href": "docs/software/code_quality/code_smells/dead_code.html#solution",
    "title": "Commented-out code",
    "section": "Solution",
    "text": "Solution\n\nIf code is not needed, delete it. Use version control (e.g., Git) to restore it if necessary. Commit the removal of the commented-out code with a meaningful commit message explaining why it was removed. This allows you to track the change and easily revert it if necessary.\nTo change the executation of your code, use input parameters or configuration settings to control the behavior of the code. This makes the code more readable and maintainable.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Commented out code"
    ]
  },
  {
    "objectID": "docs/resources/tools.html",
    "href": "docs/resources/tools.html",
    "title": "Tools",
    "section": "",
    "text": "üèóÔ∏è Under construction!",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üìñ</span> **Resources**",
      "AI tooling"
    ]
  },
  {
    "objectID": "docs/resources/courses.html",
    "href": "docs/resources/courses.html",
    "title": "Courses and workshops",
    "section": "",
    "text": "The TU Delft organises training for researchers on data management, research software development, and open science. For an overview of available courses, please visit the TU Delft Library website.\n\n\n\nThe Carpentries teaches foundational coding and data science skills to researchers worldwide.\n Software Carpentry Lesson  Data Carpentry Lesson\n\nCourses overview\n\n\n\n\nThe Delft Institute for Computational Science and Engineering offers courses on supercomputing through the Delft High Performance Computing Center.\n\nCourses overview\n\n\n\n\nCodeRefinery teaches good practices for writing and maintaining research software, focussed on open source software. Their lessons cover version control, testing, continuous integration, documentation, and more.\n\nUpcoming workshops\n\n\n\n\nThe Research Engineering and Infrastructure Team offers support on software engineering, data science, and high-performance computing. They offer courses on Rust for Research, Python best practices, and Working with a cluster.\n\nCourses overview",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üìñ</span> **Resources**",
      "Courses and workshops"
    ]
  },
  {
    "objectID": "docs/resources/courses.html#training-for-researchers-at-the-tu-delft",
    "href": "docs/resources/courses.html#training-for-researchers-at-the-tu-delft",
    "title": "Courses and workshops",
    "section": "",
    "text": "The TU Delft organises training for researchers on data management, research software development, and open science. For an overview of available courses, please visit the TU Delft Library website.\n\n\n\nThe Carpentries teaches foundational coding and data science skills to researchers worldwide.\n Software Carpentry Lesson  Data Carpentry Lesson\n\nCourses overview\n\n\n\n\nThe Delft Institute for Computational Science and Engineering offers courses on supercomputing through the Delft High Performance Computing Center.\n\nCourses overview\n\n\n\n\nCodeRefinery teaches good practices for writing and maintaining research software, focussed on open source software. Their lessons cover version control, testing, continuous integration, documentation, and more.\n\nUpcoming workshops\n\n\n\n\nThe Research Engineering and Infrastructure Team offers support on software engineering, data science, and high-performance computing. They offer courses on Rust for Research, Python best practices, and Working with a cluster.\n\nCourses overview",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üìñ</span> **Resources**",
      "Courses and workshops"
    ]
  },
  {
    "objectID": "docs/resources/courses.html#external-training-opportunities",
    "href": "docs/resources/courses.html#external-training-opportunities",
    "title": "Courses and workshops",
    "section": "External training opportunities",
    "text": "External training opportunities\n\n\n\nThe eScience Center offers regular workshops on good practices for research software development and on intermediate-level topics such as GPU programming, Deep Learning, and Image Processing. Check out the overview of the training materials.\n\nUpcoming workshops\n\n\n\n\nSURF is the IT cooperative of Dutch education and research institutions and offers various workshops on using the supercomputers and storage solutions.\n\nUpcoming events\n\n\n\n\nThe Software Sustainability Institute in the UK provides training and resources to improve the quality of research software.\n\nTraining Hub\n\n\n\n\nTaxila provides an overview of training, learning, and teaching materials for trainers and trainees in the Netherlands.\n\nUpcoming workshops",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üìñ</span> **Resources**",
      "Courses and workshops"
    ]
  },
  {
    "objectID": "docs/resources/courses.html#community-training-opportunities",
    "href": "docs/resources/courses.html#community-training-opportunities",
    "title": "Courses and workshops",
    "section": "Community training opportunities",
    "text": "Community training opportunities\n\n\n\nAre you learning R or looking for a friendly community to practice with? The R Caf√© is a welcoming space for R users of all levels - from absolute beginners to experienced programmers.\n\nUpcoming events\n\n\n\n\n4TU.ResearchData offers training resources and community engagement to research and research-support professionals working to make their research data FAIR.\n\nUpcoming events",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üìñ</span> **Resources**",
      "Courses and workshops"
    ]
  },
  {
    "objectID": "docs/infrastructure/moving_data.html",
    "href": "docs/infrastructure/moving_data.html",
    "title": "Moving data to your server",
    "section": "",
    "text": "$ scp -o \"ProxyCommand ssh -W %h:%p &lt;bastion-username&gt;@linux-bastion-ex.tudelft.nl\" &lt;my-local-file&gt;  &lt;target-username&gt;@&lt;target-host&gt;:/&lt;remote-directory&gt;/",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Moving data to your server"
    ]
  },
  {
    "objectID": "docs/infrastructure/moving_data.html#copy-data-from-client-to-host-using-proxycommand",
    "href": "docs/infrastructure/moving_data.html#copy-data-from-client-to-host-using-proxycommand",
    "title": "Moving data to your server",
    "section": "",
    "text": "$ scp -o \"ProxyCommand ssh -W %h:%p &lt;bastion-username&gt;@linux-bastion-ex.tudelft.nl\" &lt;my-local-file&gt;  &lt;target-username&gt;@&lt;target-host&gt;:/&lt;remote-directory&gt;/",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Moving data to your server"
    ]
  },
  {
    "objectID": "docs/infrastructure/moving_data.html#copy-data-from-host-to-client-using-proxycommand",
    "href": "docs/infrastructure/moving_data.html#copy-data-from-host-to-client-using-proxycommand",
    "title": "Moving data to your server",
    "section": "Copy Data from Host to Client using ProxyCommand",
    "text": "Copy Data from Host to Client using ProxyCommand\n$ scp -o \"ProxyCommand ssh -W %h:%p &lt;bastion-username&gt;@linux-bastion-ex.tudelft.nl\" &lt;target-username&gt;@&lt;target-host&gt;:/tmp/&lt;my-remote-file&gt; /&lt;my-local-directory&gt;/",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Moving data to your server"
    ]
  },
  {
    "objectID": "docs/infrastructure/moving_data.html#copy-data-using-ssh-tunneling",
    "href": "docs/infrastructure/moving_data.html#copy-data-using-ssh-tunneling",
    "title": "Moving data to your server",
    "section": "Copy Data using SSH Tunneling",
    "text": "Copy Data using SSH Tunneling\nIf a default ssh tunneling was configured correctly. Data can be copied to and from a remote host as follows:\n# Copy TO Remote Host\n$ scp &lt;my-local-file&gt; &lt;host-nickname&gt;:/&lt;remote-directory&gt;/\n# Copy FROM Remote Host\n$ scp &lt;host-nickname&gt;:/&lt;my-remote-file&gt; /&lt;my-local-directory&gt;/",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Moving data to your server"
    ]
  },
  {
    "objectID": "docs/infrastructure/moving_data.html#scp-with-sudo-files-from-a-remote-host-to-another-remote-host",
    "href": "docs/infrastructure/moving_data.html#scp-with-sudo-files-from-a-remote-host-to-another-remote-host",
    "title": "Moving data to your server",
    "section": "scp with sudo files from a remote host to another remote host",
    "text": "scp with sudo files from a remote host to another remote host\n‚Äú-C /tmp/a‚Äù can be used when you wanted to ‚Äúcd /tmp/a‚Äù\nssh source.tudelft.nl sudo tar cf - -C /tmp/a . | ssh target.tudelft.nl  sudo tar xvf - -C /tmp/b/",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Moving data to your server"
    ]
  },
  {
    "objectID": "docs/infrastructure/giving_sudo_privilege.html",
    "href": "docs/infrastructure/giving_sudo_privilege.html",
    "title": "Giving sudo privilege to a user",
    "section": "",
    "text": "There are some tasks in Linux that requires superuser (sudo) permission. For instance editing the /etc/fstab file, rebooting the system, mounting a drive, viewing /etc/passwd file and many other tasks cannot be done without sudo privilege."
  },
  {
    "objectID": "docs/infrastructure/giving_sudo_privilege.html#background",
    "href": "docs/infrastructure/giving_sudo_privilege.html#background",
    "title": "Giving sudo privilege to a user",
    "section": "",
    "text": "There are some tasks in Linux that requires superuser (sudo) permission. For instance editing the /etc/fstab file, rebooting the system, mounting a drive, viewing /etc/passwd file and many other tasks cannot be done without sudo privilege."
  },
  {
    "objectID": "docs/infrastructure/giving_sudo_privilege.html#what-this-documentation-will-help-achieve",
    "href": "docs/infrastructure/giving_sudo_privilege.html#what-this-documentation-will-help-achieve",
    "title": "Giving sudo privilege to a user",
    "section": "What this documentation will help achieve",
    "text": "What this documentation will help achieve\nThis documentation helps you to give sudo privilege to a user."
  },
  {
    "objectID": "docs/infrastructure/giving_sudo_privilege.html#prerequisites",
    "href": "docs/infrastructure/giving_sudo_privilege.html#prerequisites",
    "title": "Giving sudo privilege to a user",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nTU Delft netID\nBasic knowledge of Linux\nThose who grant sudo permission need to have sudo permission themselves."
  },
  {
    "objectID": "docs/infrastructure/giving_sudo_privilege.html#toolssoftware",
    "href": "docs/infrastructure/giving_sudo_privilege.html#toolssoftware",
    "title": "Giving sudo privilege to a user",
    "section": "Tools/Software",
    "text": "Tools/Software\n\nFor Windows users, you will need a programming and runtime environment like Cygwin or SSH client like PuTTY in order to access the VPS running Linux."
  },
  {
    "objectID": "docs/infrastructure/giving_sudo_privilege.html#steps",
    "href": "docs/infrastructure/giving_sudo_privilege.html#steps",
    "title": "Giving sudo privilege to a user",
    "section": "Steps",
    "text": "Steps\n\nGetting the username(s) of sudo access candidates\nNavigating to the sudoers directory\nCreate an access file for each of the candidates\nEditing the access files\n\n\nStep 1. Getting the username(s) of sudo access candidates\nYou can get the usernames by checking the /etc/passwd file. This file contains all the usernames and their login information.\n\n\nStep 2. Navigating to the sudoers directory\nThe list of users who posses the sudo permission is in the /etc/sudoers.d/ folder, so navigate to that folder.\n\n\nStep 3. Create an access file for each of the candidates\nIf you use ls command to check the available files in this folder, you can see there are some files that their name start with a number and then a dash and then a user name (&lt;number&gt;-&lt;username&gt;). In Linux for every user with a sudo permission, there is a file like that, so we duplicate one of the existing files and rename them for each of the sudo candidates (in fact, name of those file doesn‚Äôt matter; however, it helps us to understand which users have sudo privilege without opening them).\n\n\nStep 4. Editing the access files\nIn this step you need to open each of the newly duplicated files and replace the old username in the second line with the sudo candidate username. After the edit, you just save the changes and exit the file."
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html",
    "href": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html",
    "title": "Transfer ownership of a GitLab repository",
    "section": "",
    "text": "GitLab repositories belonging to employees leaving the TU Delft might be deleted in future.\nFrom the TU Delft GitLab help documentation, we read the following:\nCurrent situation\nFirst, if you use Git on your computer, you will have the entire history also locally on your machine. Without a valid TU Delft account, your GitLab access will become inactive. There are currently no plans to delete any content when an account becomes inactive.\nFuture situation\nAt some point in the future, repositories of former TU Delft employees may be deleted. To avoid losing information, it is recommended to transfer ownership of your repositories to a current TU Delft employee when you leave.\n\n\n\nThis guide provides the steps required to secure access to repositories of employees who will leave the TU Delft.\nIf they have access to your projects, they will still have access after you leave, as long as the projects still exist. You can control who has access to your projects by going to Project Information &gt; Members in the sidebar of your repository. To be safe, transfer the ownership of the projects to a current TU Delft employee when you leave.\nYou can transfer a project to another user‚Äôs GitLab namespace. Read what a namespace is here.\n\n\n\n\n\n\nNote\n\n\n\nProviding a more straightforward way to transfer ownership in GitLab was raised as an issue in 2016 but the issue is still open; you can follow the progress here if interested.\n\n\n\n\n\nThe steps will guide you through transferring repository ownership between TU Delft employees through an intermediary GitLab group:\n\n\n\n\n\n\n\nNote\n\n\n\nSummary (based on this Stack Overflow post): ‚Äã‚ÄãMove your project from your namespace to a group where both you and the other user are owners, then the other user can transfer it to their own namespace\n\n\n\n\nCreate a new group if you don‚Äôt have one that you want to use (Menu &gt; Groups &gt; Create group)\n\n\n\nMake sure that both the maintainer of the project repository, and the person who it will be transferred to, are members of the group and have the Owner role (to add a new owner: go to the group namespace, then from the sidebar choose Group information &gt; Members &gt; Invite members.\n\n\nEnter the username or email of the person you want to invite and change the role to ‚ÄòOwner‚Äô. Click ‚ÄòInvite‚Äô.)\n\n\n\n\nHave a maintainer of the project repository transfer it to the group namespace (go to the project namespace, then from the sidebar go to Settings &gt; General &gt; Advanced &gt; Transfer Project)\n\n\n\n\nAfter doing this, the maintainer(s) of the project will get an email:\n\n\n\n\nNow the person who the project is being transferred to can move it to their own namespace (go to the project namespace, then from the sidebar, go to Settings &gt; General &gt; Advanced &gt; Transfer Project like before).\n\n\n\nIf desired, the group can be deleted after the transfer is complete (go to the group namespace, then from the sidebar go to Settings &gt; General &gt; Advanced &gt; Remove Group)",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Transfer ownership of a GitLab repository"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html#background",
    "href": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html#background",
    "title": "Transfer ownership of a GitLab repository",
    "section": "",
    "text": "GitLab repositories belonging to employees leaving the TU Delft might be deleted in future.\nFrom the TU Delft GitLab help documentation, we read the following:\nCurrent situation\nFirst, if you use Git on your computer, you will have the entire history also locally on your machine. Without a valid TU Delft account, your GitLab access will become inactive. There are currently no plans to delete any content when an account becomes inactive.\nFuture situation\nAt some point in the future, repositories of former TU Delft employees may be deleted. To avoid losing information, it is recommended to transfer ownership of your repositories to a current TU Delft employee when you leave.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Transfer ownership of a GitLab repository"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html#purpose-of-this-guide",
    "href": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html#purpose-of-this-guide",
    "title": "Transfer ownership of a GitLab repository",
    "section": "",
    "text": "This guide provides the steps required to secure access to repositories of employees who will leave the TU Delft.\nIf they have access to your projects, they will still have access after you leave, as long as the projects still exist. You can control who has access to your projects by going to Project Information &gt; Members in the sidebar of your repository. To be safe, transfer the ownership of the projects to a current TU Delft employee when you leave.\nYou can transfer a project to another user‚Äôs GitLab namespace. Read what a namespace is here.\n\n\n\n\n\n\nNote\n\n\n\nProviding a more straightforward way to transfer ownership in GitLab was raised as an issue in 2016 but the issue is still open; you can follow the progress here if interested.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Transfer ownership of a GitLab repository"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html#steps",
    "href": "docs/infrastructure/gitlab/gitlab_transfer_ownership.html#steps",
    "title": "Transfer ownership of a GitLab repository",
    "section": "",
    "text": "The steps will guide you through transferring repository ownership between TU Delft employees through an intermediary GitLab group:\n\n\n\n\n\n\n\nNote\n\n\n\nSummary (based on this Stack Overflow post): ‚Äã‚ÄãMove your project from your namespace to a group where both you and the other user are owners, then the other user can transfer it to their own namespace\n\n\n\n\nCreate a new group if you don‚Äôt have one that you want to use (Menu &gt; Groups &gt; Create group)\n\n\n\nMake sure that both the maintainer of the project repository, and the person who it will be transferred to, are members of the group and have the Owner role (to add a new owner: go to the group namespace, then from the sidebar choose Group information &gt; Members &gt; Invite members.\n\n\nEnter the username or email of the person you want to invite and change the role to ‚ÄòOwner‚Äô. Click ‚ÄòInvite‚Äô.)\n\n\n\n\nHave a maintainer of the project repository transfer it to the group namespace (go to the project namespace, then from the sidebar go to Settings &gt; General &gt; Advanced &gt; Transfer Project)\n\n\n\n\nAfter doing this, the maintainer(s) of the project will get an email:\n\n\n\n\nNow the person who the project is being transferred to can move it to their own namespace (go to the project namespace, then from the sidebar, go to Settings &gt; General &gt; Advanced &gt; Transfer Project like before).\n\n\n\nIf desired, the group can be deleted after the transfer is complete (go to the group namespace, then from the sidebar go to Settings &gt; General &gt; Advanced &gt; Remove Group)",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Transfer ownership of a GitLab repository"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_groups.html",
    "href": "docs/infrastructure/gitlab/gitlab_groups.html",
    "title": "Creating GitLab groups",
    "section": "",
    "text": "Groups and subgroups are similar to directories in the operating systems. In windows or Mac, we create directories to organise files or other directories. For example, imagine a scenario where you want to keep your photos in an organised manner. To this end, you may organise your photos on multiple levels. In the first level, perhaps you broadly classify them and then in the next levels you narrow it down to more specific subjects. Similarly, in the GitLab, a group is used as a binder to put together projects or even other groups. For example, if three themes are researched in a lab, each of those themes could be a group, and all the research in a certain theme fall into its corresponding group. Sometimes there are also sub-themes. For every sub-theme you can create a subgroup (within the group corresponding to the broader theme) and assign the research close to the sub-theme there.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Creating GitLab groups"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_groups.html#background",
    "href": "docs/infrastructure/gitlab/gitlab_groups.html#background",
    "title": "Creating GitLab groups",
    "section": "",
    "text": "Groups and subgroups are similar to directories in the operating systems. In windows or Mac, we create directories to organise files or other directories. For example, imagine a scenario where you want to keep your photos in an organised manner. To this end, you may organise your photos on multiple levels. In the first level, perhaps you broadly classify them and then in the next levels you narrow it down to more specific subjects. Similarly, in the GitLab, a group is used as a binder to put together projects or even other groups. For example, if three themes are researched in a lab, each of those themes could be a group, and all the research in a certain theme fall into its corresponding group. Sometimes there are also sub-themes. For every sub-theme you can create a subgroup (within the group corresponding to the broader theme) and assign the research close to the sub-theme there.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Creating GitLab groups"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_groups.html#what-this-documentation-will-help-achieve",
    "href": "docs/infrastructure/gitlab/gitlab_groups.html#what-this-documentation-will-help-achieve",
    "title": "Creating GitLab groups",
    "section": "What this documentation will help achieve",
    "text": "What this documentation will help achieve\nThis documentation helps researchers to set up a group and assign contributors to the projects within the GitLab.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Creating GitLab groups"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_groups.html#prerequisites",
    "href": "docs/infrastructure/gitlab/gitlab_groups.html#prerequisites",
    "title": "Creating GitLab groups",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nTU Delft netID",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Creating GitLab groups"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_groups.html#steps",
    "href": "docs/infrastructure/gitlab/gitlab_groups.html#steps",
    "title": "Creating GitLab groups",
    "section": "Steps",
    "text": "Steps\n\nLog-in to the GitLab with your netid and password.\nEnter to the Groups section.\nCreate a group.\nAssign contributors to the group.\n\n\nStep 1. Log-in to the GitLab with your netid and password\nTo create a group in GitLab, first you need to log in to the TU Delft‚Äôs instance of GitLab.\n Figure 1: The login page of TU Delft‚Äôs GitLab.\n\n\nStep 2. Enter to the Groups section\nAfter the log-in, from the top bar click on groups and then Your groups. I\n Figure 2: The Group section of the GitLab.\n\n\nStep 3. Create a group\nIn the new web page, click on the New group and then fill in the form by choosing a suitable group name and then selecting the visibility level. You can later on change both group name and visibility level.\n Figure 3: Creation of a new Group in the GitLab.\n\n\nStep 4. Assign contributors to the group.\nAfter creating a group, it appears in the Groups tab. The group owner can add different people to the projects. This can be done by entering a project and then clicking on the Members on the left panel and filling in the form (Figure 4). A very important part of this form is permissions which are explained here in detail.\n Figure 4: Assigning members to a project.\nYou can also create subgroups within a group. To create a subgroup, you need to enter an existing group and press the New subgroup button. Then, similar to creating a group, you fill in the subgroup name and select the degree of visibility for the subgroup. The subgroup visibility level is always a subset of its (parent) group visibility, hence if the parent visibility is private, there is no choice except private for the subgroup visibility but if the parent visibility is public, subgroup visibility could be either public, internal, or private. The same logic applies when you create a subgroup within another subgroup.\n Figure 5: Creating a subgroup.\nAfter setting up the group, (sub groups,) projects, and assigning the collaborators to the projects, they can start working with the remote repository and transfer their scripts there.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Creating GitLab groups"
    ]
  },
  {
    "objectID": "docs/infrastructure/getting_started.html",
    "href": "docs/infrastructure/getting_started.html",
    "title": "Overview",
    "section": "",
    "text": "Under construction! üèóÔ∏è",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Getting started"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html",
    "href": "docs/infrastructure/VPS_request.html",
    "title": "Request a VPS",
    "section": "",
    "text": "This guide describes the essentials for requesting and setting up a TU Delft managed server. A server is a computer that can handle requests. Servers are often a critical component of architectural solutions for data management. There are many reasons why you as a researcher may need to request a server, for example:\n\nAutomation of a process in your data collection\nSet up runners for the TU Delft Gitlab\nA part of your analysis should be running continuously, and you cannot do it with your own machine\nSpecific functionality (web server)\nYou need a machine to handle large amounts of requests\nYou want to outsource the maintenance of a server to TU Delft ICT\nRely on safety and security administrated by the University, including backups\nSecuring/controlling access\nMounting storage drive",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html#background",
    "href": "docs/infrastructure/VPS_request.html#background",
    "title": "Request a VPS",
    "section": "",
    "text": "This guide describes the essentials for requesting and setting up a TU Delft managed server. A server is a computer that can handle requests. Servers are often a critical component of architectural solutions for data management. There are many reasons why you as a researcher may need to request a server, for example:\n\nAutomation of a process in your data collection\nSet up runners for the TU Delft Gitlab\nA part of your analysis should be running continuously, and you cannot do it with your own machine\nSpecific functionality (web server)\nYou need a machine to handle large amounts of requests\nYou want to outsource the maintenance of a server to TU Delft ICT\nRely on safety and security administrated by the University, including backups\nSecuring/controlling access\nMounting storage drive",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html#what-this-documentation-will-help-you-achieve",
    "href": "docs/infrastructure/VPS_request.html#what-this-documentation-will-help-you-achieve",
    "title": "Request a VPS",
    "section": "What this documentation will help you achieve",
    "text": "What this documentation will help you achieve\nThis documentation helps researchers to request a VPS and data storage on the Project Drive. There are other forms of storage available, but Project Drive storage is often recommended for expandable and secure data preservation.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html#prerequisites",
    "href": "docs/infrastructure/VPS_request.html#prerequisites",
    "title": "Request a VPS",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nTU Delft netID\nBasic knowledge of Linux (if requesting Linux server, recommended)",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html#toolssoftware",
    "href": "docs/infrastructure/VPS_request.html#toolssoftware",
    "title": "Request a VPS",
    "section": "Tools/Software",
    "text": "Tools/Software\n\nFor Windows users, you will need a programming and runtime environment like Cygwin or SSH client like PuTTY in order to access the VPS running Linux",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html#steps",
    "href": "docs/infrastructure/VPS_request.html#steps",
    "title": "Request a VPS",
    "section": "Steps",
    "text": "Steps\n\nNavigate to the TU Delft server request form\nFill and send the form according to your preferences and needs\nReceive confirmation of server deployment from TU Delft ICT\nLogin to your server for the first time\n\n\nStep 1: Navigate to the TU Delft server request form\nYou can make a request for a server via the TopDesk self service portal.\n\n\nStep 2: Fill and send the form according to your preferences and needs\nThe form is divided into three sections: Caller Details, General Questions, and Technical Questions.\nCaller Details should contain the contact information of the main administrator of this server. If you select your name, the fields below should be auto-populated with your building, phone number, email, department/program, organizational unit, and (sometimes) room.\n\nThe last question in the Caller Details section access to the server by external users. Generally speaking, granting access to TU Delft-managed servers is not recommended, but if it is necessary you can add the contact details of the external party and the reason(s) for which they should have access. You will need to provide a company-affiliated email address for the external user, and the request may or may not be granted by ICT.\n\n\n\n\n\n\nNote\n\n\n\nKeep in mind that a server provides access to the backend of your application. If for example you want to deploy a web server to share your data widely, users do not need direct access to the server in order to access the data itself.\n\n\nThe next section contains General Questions about the name and purpose of your server. If you plan to use this server ongoing into the future, you can either leave the field ‚ÄúExpiration Date‚Äù blank or add a date in 10+ years. TU Delft ICT will alert you when the expiration date you select is nearing.\n\n\n\n436ab820-8194-4212-8622-93758ba56f56\n\n\nYou can add the netIDs of your collaborators who should have read/write access to the server, and optionally the netID of your faculty Data Steward or of a DCC Team member if you would like their help. You can find your faculty Data Steward contact information here.\nThe Technical Questions section asks you to specify an operating system and some other technical details about your server configuration. You can choose between four basic configuration options - you can of course consider which one best fits your needs. If you are new to working with servers, generally the best choice is Basic configuration 4.\nThe next question deals with opening ports to the server through the TU Delft firewall. Ports are essentially gateways to the server that are specific to different purposes. For example, port 80 is opened to handle HTTP requests, port 20 is opened to handle SSH requests, port 3306 is opened to allow access to a MySQL database, and port 443 is opened to handle HTTPS requests. If you are planning to use your VPS as a webserver, ports 80 and 443 should be open. You can use this space to ask ICT to do so.\nThe next section, FQDN, is the way you can refer to your server on the internet. The recommendation is a format like &lt;servername&gt;.&lt;facultyabbreviation&gt;.tudelt.nl. In general, it‚Äôs best to keep names relatively short and informative to make it easy to reference and remember.\nYou should also be sure to check the instructions in the form and contact your faculty Data Steward or Faculty IT Manager if you need further explanation.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html#initial-configuration-of-your-vps",
    "href": "docs/infrastructure/VPS_request.html#initial-configuration-of-your-vps",
    "title": "Request a VPS",
    "section": "Initial Configuration of your VPS",
    "text": "Initial Configuration of your VPS\nA few days after submitting the request, you will receive an email from ICT with login details. You can connect to your VPS via ssh. If you are in the windows environment, it is recommended to install Cygwin and its packages to be able to use the ssh command in a non-unix environment. The unix based systems (e.g., mac) contain ssh by default. In order to login to your VPS, you need to first ssh to the bastion server with ssh &lt;username&gt;@linux-bastion-ex.tudelft.nl and then from there login to your server ssh &lt;servername&gt;. The first thing we recommend to do after logging into the server is to update the pre-installed packages:\n\nDebian (Ubuntu)RedHat\n\n\nsudo apt-get update && sudo apt-get upgrade\n\n\nsudo yum update\n\n\n\nIt would be also useful to set a password for the VPS when you log in. You can do that by passwd command.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_request.html#next-steps",
    "href": "docs/infrastructure/VPS_request.html#next-steps",
    "title": "Request a VPS",
    "section": "Next Steps",
    "text": "Next Steps\nCommon next steps after obtaining a VPS and storage include initial configuration steps such as establishing a connection via SSH and mounting Project Drive storage; and also software installation steps for tools like Docker, and setting up Apache Web Server. We will add more documentation when common installations come to our attention, so please reach out to us with your questions or suggestions.\n\nInstall Docker\nConfigure Docker for use as non-root\nConfigure a runner for the TU Delft Gitlab\nApache Web Server",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Request a VPS"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSH.html",
    "href": "docs/infrastructure/VPS_SSH.html",
    "title": "Configure SSH Tunneling",
    "section": "",
    "text": "To connect to a remote host, TU Delft uses a proxy server, know as bastion. To reach a remote host, a user has to connect first to the bastion and from there to the remote host. However, a user can connect directly to the remote host using ssh tunneling.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSH Tunneling"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSH.html#set-a-default-ssh-tunneling-for-a-host-linux-terminal",
    "href": "docs/infrastructure/VPS_SSH.html#set-a-default-ssh-tunneling-for-a-host-linux-terminal",
    "title": "Configure SSH Tunneling",
    "section": "Set a Default SSH Tunneling for a Host (Linux Terminal)",
    "text": "Set a Default SSH Tunneling for a Host (Linux Terminal)\n\nOn your local machine, edit the ~/.ssh/config file and add the following confuration:\n\nHost &lt;host-nickname&gt;\n    HostName &lt;target-host&gt;\n    User &lt;target-username&gt;\n    ProxyCommand ssh &lt;bastion-username&gt;@linux-bastion-ex.tudelft.nl -W %h:%p \nReplace: : a name for you choice for the targe host, e.g., my-server : the actual name of the target host (FQDM), e.g, server.tudelft.nl : the username used to login to the target host : the username used to login to the bastion server\n\nCreate a key-pair on the local machine.\n\n$ ssh-keygen -f ~/.ssh/&lt;my-keyname&gt; -t rsa -b 4096\nYou will be promted to crate a passphrase, we recommend you to add one to make the connection more secure. The passphrase will be asked every time you connect to the target host.\nA private and public keys will be added to ~/.ssh. The public key is in the &lt;my-keyname&gt;.pub\n\nCopy the content of the public key to the ~/.ssh/authorized_keys file in the target host.\nConnect to the target host using ssh tunneling. Use your bastion-password when asked.\n\n$ ssh &lt;host-nickname&gt;\nIf you encounter problems with the connection. Use the debug mode ssh -vvv &lt;host-nickname&gt; to find out what might have gone wrong.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSH Tunneling"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSH.html#tunneling-with-winscp",
    "href": "docs/infrastructure/VPS_SSH.html#tunneling-with-winscp",
    "title": "Configure SSH Tunneling",
    "section": "Tunneling with WinSCP",
    "text": "Tunneling with WinSCP\nWinSCP is a GUI that makes it very easy to inspect, edit and transfer files on the webserver. Instructions for setting this up on a hypothetical server from the CiTG faculty are provided below. General documentation on tunneling with WinSCP are here: https://winscp.net/eng/docs/ui_login_tunnel\nThese instructions were tested with an existing id_ed25519 key, assume you already have WinSCP installed and can modify a text file on the server in your user directory using the terminal.\nDo the following:\n\nAs explained above, log in to the server and add your public key to the file /home/&lt;username&gt;/.ssh/authorized_keys (this only needs to be done once).\n\nIt should look like this with your own keys XXXXXXX and NetID filled between the &lt;...&gt; (note the &lt;XXXXXXX&gt; is much longer in reality):\nssh-rsa &lt;XXXXXXX&gt; ICT-SYSTEMS-&lt;NETID&gt;\nssh-rsa &lt;XXXXXXX&gt; ICT-SYSTEMS-&lt;NETID&gt;\nssh-ed25519 &lt;XXXXXXX&gt; &lt;NETID&gt;@tudelft.nl\n\nUsing WinSCP, the following fields should be entered:\n\nOn the main login settings page: - File protocol: SFTP - Host name: &lt;server&gt;.citg.tudelft.nl - User name: your NetID\n\nOpen the ‚ÄúAdvanced‚Ä¶‚Äù window\nOn the page ‚ÄúTunnel‚Äù (under heading ‚ÄúConnection,‚Äù still in the Advanced window):\n\n\nHost name: linux-bastion-ex.tudelft.nl\nUser name: your NetID\n\n\nOn the page ‚ÄúAuthentication‚Äù (under heading ‚ÄúSSH,‚Äù still in the Advanced window):\n\n\nPrivate key file: select your private key file, for example C:..../&lt;username&gt;/.ssh/id_ed25519\nNote that the app may ask you to convert your existing key to a Putty format (for example ‚ÄúDo you want to convert OpenSSH private key to PuTTY format?‚Äù). Click ‚ÄúOK‚Äù then make sure you select the new PuTTY file (e.g., C:..../&lt;username&gt;/.ssh/id_ed25519.ppk)\n\n\nSave the setting and click ‚ÄúLogin‚Äù, using your NetID password to authenticate.\n\n\nUsing WinSCP with sudo rights\nIf you have sudo rights on the webserver you can use this via WinSCP as follows:\n\nOnce agin go to the ‚ÄúAdvanced‚Ä¶‚Äù window to the ‚ÄúSFTP‚Äù page under heading ‚ÄúEnvironment‚Äù\nIn field ‚ÄúSFTP server‚Äù enter the following: sudo /usr/lib/openssh/sftp-server\nSave the changes\nUse with caution!\n\nNote that the path to sftp-server may be different but can be easily checked and arranged. This will not work if you change the setting and continue to use an open session.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSH Tunneling"
    ]
  },
  {
    "objectID": "docs/guides.html",
    "href": "docs/guides.html",
    "title": "How-to Guides",
    "section": "",
    "text": "The guides are split into a few major sections:\n\nComputing Infrastructure contains information and guides on TU Delft ICT infrastructure.\nData Management contains information and guides on using TU Delft data storage options and best-practices for FAIR data.\nResearch Software contains information for creating FAIR research software.\nResources contains a collection of courses, workshops, and references."
  },
  {
    "objectID": "docs/data/planning/planning.html",
    "href": "docs/data/planning/planning.html",
    "title": "Planning",
    "section": "",
    "text": "üöß Under construction! üèóÔ∏è\n\n\n\n\n Privacy and security\nComing soon! ‚è∞\n\nLearn more ¬ª\n\n\n\n Ethics\nComing soon! ‚è∞\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Planning"
    ]
  },
  {
    "objectID": "docs/data/getting_started.html",
    "href": "docs/data/getting_started.html",
    "title": "Getting started",
    "section": "",
    "text": "The aim of this section is to guide data owners and users through each stage of the data lifecycle - such as data collection, storage, sharing, publication, and archiving - in a responsible and effective manner. By following the Findable, Accessible, Interoperable, and Reproducible (FAIR) principles, users will learn the core concepts and practices of good data management at TU Delft.\nResearch data includes any information observed, generated or created for use in research projects. Though often tied to specific research projects, research data follows its own lifecycle, which is distinct from the project itself. After initial data collection, data may be processed, analyzed, published, shared, archived, reused or destroyed.\nEffective research data management by following FAIR principles ensures efficiency and reproducibility at every step of the data lifecycle. At TU Delft, various tools and resources are available to meet diverse data management needs at any stage in its lifecycle.\nThis guide intends to walk you through the following steps of the data lifecycle at TU Delft, following FAIR principles:\n\nData Collection\nData Processing\nData Storage\nData Publishing",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Getting started"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sync_unison.html",
    "href": "docs/data/data_storage/sync_unison.html",
    "title": "Sync Project Drive and SURFDrive with Unison",
    "section": "",
    "text": "From Unison website: ‚ÄúUnison is a file-synchronization tool for OSX, Unix, and Windows. It allows two replicas of a collection of files and directories to be stored on different hosts (or different disks on the same host), modified separately, and then brought up to date by propagating the changes in each replica to the other.‚Äù",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Sync Project Drive and SURFDrive with Unison"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sync_unison.html#background",
    "href": "docs/data/data_storage/sync_unison.html#background",
    "title": "Sync Project Drive and SURFDrive with Unison",
    "section": "",
    "text": "From Unison website: ‚ÄúUnison is a file-synchronization tool for OSX, Unix, and Windows. It allows two replicas of a collection of files and directories to be stored on different hosts (or different disks on the same host), modified separately, and then brought up to date by propagating the changes in each replica to the other.‚Äù",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Sync Project Drive and SURFDrive with Unison"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sync_unison.html#what-this-documentation-will-help-achieve",
    "href": "docs/data/data_storage/sync_unison.html#what-this-documentation-will-help-achieve",
    "title": "Sync Project Drive and SURFDrive with Unison",
    "section": "What this documentation will help achieve",
    "text": "What this documentation will help achieve\nThis documentation will help you create bi-directional backups between your local machine and a server (such as TU Delft project drive). Sync profiles can be customized so that, for example, shared folders on SurfDrive can be automatically synced with directories in the WebDAV links for TU Delft Staff and Students.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Sync Project Drive and SURFDrive with Unison"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sync_unison.html#prerequisites",
    "href": "docs/data/data_storage/sync_unison.html#prerequisites",
    "title": "Sync Project Drive and SURFDrive with Unison",
    "section": "Prerequisites",
    "text": "Prerequisites",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Sync Project Drive and SURFDrive with Unison"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sync_unison.html#toolssoftware",
    "href": "docs/data/data_storage/sync_unison.html#toolssoftware",
    "title": "Sync Project Drive and SURFDrive with Unison",
    "section": "Tools/Software",
    "text": "Tools/Software\n\nUnison\nGTK+ for Windows\nDesktop client for SURFDrive",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Sync Project Drive and SURFDrive with Unison"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sync_unison.html#steps-for-windows",
    "href": "docs/data/data_storage/sync_unison.html#steps-for-windows",
    "title": "Sync Project Drive and SURFDrive with Unison",
    "section": "Steps for Windows",
    "text": "Steps for Windows\n\nUnison requires .dll‚Äôs from GTK+ for Windows Runtime Environment. Download it and install it (to C:Files (x86)-Runtime).\nInstall Unison 2.48.4 and extract it in a folder.\nDownload desktop client for SurfDrive\nIf not already there, mount H: Drive or Project Drive folder in your local machine from WebDAV link https://webdata.tudelft.nl/\nNavigate to Unison folder via command prompt and then enter ‚Äúunison 2.48.4 GTK.exe‚Äù to run the Unison GUI.\nThe GUI starts & asks you to set a Profile for your file syncing. The Profile Creation Wizard guides you through this. For the Synchronization kind choose Local. Set the First directory to your local SurfDrive and Second directory, to WebDAV folder.\nBy pressing the Go button on the top menu, Unison start synchronizing both specified directories.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Sync Project Drive and SURFDrive with Unison"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sync_unison.html#steps-for-mac-beta",
    "href": "docs/data/data_storage/sync_unison.html#steps-for-mac-beta",
    "title": "Sync Project Drive and SURFDrive with Unison",
    "section": "Steps for Mac (beta)",
    "text": "Steps for Mac (beta)\nThese steps should theoretically be feasible, but there is an issue with the configuration of mounted TU Delft drives and them disconnecting which interrupts automated backup and read/write access. We are working on this with TU Delft ICT.\n\nInstall Unison\nDownload desktop client for SurfDrive\nMount H: drive or Project Drive folder in your local machine using these directions\nChoose folders for sync from local machine or Surfdrive to WebDAV folder",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Sync Project Drive and SURFDrive with Unison"
    ]
  },
  {
    "objectID": "docs/data/data_storage/storage.html",
    "href": "docs/data/data_storage/storage.html",
    "title": "Data storage",
    "section": "",
    "text": "Under construction! üèóÔ∏è\n\n\n\n\n Storage options\nComing soon! ‚è≥\n\nLearn more ¬ª\n\n\n\n Data security\nComing soon! ‚è≥\n\nLearn more ¬ª\n\n\n\n Data sharing\nComing soon! ‚è≥\n\nLearn more ¬ª\n\n\n\n Data backup\nComing soon! ‚è≥\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage"
    ]
  },
  {
    "objectID": "docs/data/data_storage/security.html",
    "href": "docs/data/data_storage/security.html",
    "title": "Data security",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Data security"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_mounting.html",
    "href": "docs/data/data_storage/project_drive_mounting.html",
    "title": "Mount Project Drive on server",
    "section": "",
    "text": "Project drive storage from TU Delft ICT can be mounted and made accessible in your (TU Delft) Virtual Private Server.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Mount Project Drive on server"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_mounting.html#what-this-documentation-will-help-achieve",
    "href": "docs/data/data_storage/project_drive_mounting.html#what-this-documentation-will-help-achieve",
    "title": "Mount Project Drive on server",
    "section": "",
    "text": "Project drive storage from TU Delft ICT can be mounted and made accessible in your (TU Delft) Virtual Private Server.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Mount Project Drive on server"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_mounting.html#prerequisites",
    "href": "docs/data/data_storage/project_drive_mounting.html#prerequisites",
    "title": "Mount Project Drive on server",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nA (TU Delft) Virtual Private Server\nA (TU Delft) Project Drive",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Mount Project Drive on server"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_mounting.html#steps",
    "href": "docs/data/data_storage/project_drive_mounting.html#steps",
    "title": "Mount Project Drive on server",
    "section": "Steps",
    "text": "Steps\n\nLocate the URL of your project storage\nConnect to your TU Delft VPS via SSH\nCreate a new directory as a mounting point\nRetrieve your Linux user and group details\nEdit the fstab file to include project storage technical details\nMount the project drive\n\n\nStep 1. Locate the URL of your project storage\nThe URL for your project drive can be obtained from either - the email from TU Delft ICT with the confirmation of your project drive request, or - by using a web browser to navigate into https://webdata.tudelft.nl/\n\n\n\n\n\n\nNote\n\n\n\nhttps://webdata.tudelft.nl/ can only be accessed in campus or using eduVPN\n\n\n\nchromeedge\n\n\n\nNavigate into https://webdata.tudelft.nl/staff-umbrella/\n\nA pop-up should appear asking for Username and Password.\n\nProvide your netID in the Username field, provide your password accordingly.\n\nYou should now see a list of your project drives.\n\nClick on the project drive of your choice.\n\nCopy everything after ‚Äúhttps://webdata.tudelft.nl/‚Äù\n\n\n\nContent within webdata is under password protection. Typing your username and password in only possible with a pop-up message which is disabled in systems managed by TU Delft, please try the instructions provided for chrome\n\n\n\n\n\nStep 2. Connect to your TU Delft VPS via SSH\nFollow instructions in TU Delft ICT email from initial server setup or configure a 1-step connection via SSH.\n\n\nStep 3. Create a new directory as the mounting point\nThe convention is to create mounting points in the folder /media. Navigate to the folder and create a new folder with\ncd /media\nmkdir &lt;server_mount_point&gt;\nReplace &lt;server_mount_point&gt; with the name of your choice. This will be the name of the folder where your project drive will be mounted.\n\n\nStep 4. Find and save your user and group details\nIn the terminal, you can retrieve your local user and group details with:\nid -u &lt;your_netID&gt; # User ID\nid -g &lt;your_netID&gt; # Group ID\nYou may need the values for uid and gid for step 5.\n\n\n\n\n\n\nNote\n\n\n\nThese commands are server-specific, so make sure to execute them on the server where the project drives will be mounted.\n\n\n\n\nStep 5. Edit the fstab file to include project storage technical details\nThe fstab file containes a list of the addresses of external file systems. In this file, the details of your project drive will need to be added in a single line. This line consists of four parts: 1. filesystem - the address of the project drive 2. mount point - the location in the VPS where you want to mount the project drive 3. type - the type of the filesystem 4. options - additional option such as user privileges\nThe fstab file must be in the /etc/ directory and can be opened with the vi or nano editor:\n\nvinano\n\n\nIn the terminal, enter the following command to open the fstab file in the vi editor:\nsudo vi /etc/fstab\nThen, switch to the insert mode (hit ‚Äúi‚Äù to switch to insert mode and be able to type)\n\n\nIn the terminal, enter the following command to open the fstab file in the nano editor:\nsudo nano /etc/fstab\n\n\n\nAdd the following line to the file:\n&lt;your_netID&gt;@sftp.tudelft.nl:/staff-umbrella/&lt;project_drive_name&gt;  /media/&lt;server_mount_point&gt; fuse.sshfs  rw,noauto,users,_netdev  0  0\nreplacing the values between &lt; and &gt; with your NetID, the name of your project drive, and the name of the folder you created in step 3.\n\n\n\n\n\n\nNote\n\n\n\nIf this configuration throws a permission error during mounting, try:\n//tudelft.net/staff-umbrella/&lt;project_drive_name&gt;/ /media/&lt;server_mount_point&gt; cifs username=&lt;your_netID&gt;,noauto,uid=&lt;your_uid&gt;,gid=&lt;your_gid&gt;,forcegid,rw,_netdev\nUse the values for uid and gid from step 4.\n\n\nClose the file editor and save the changes:\n\nvinano\n\n\nUse Control+C followed by :wq to save the file and close it to get back to your terminal.\n\n\nAs indicated by the nano interface, use Control+O to write the file. Then, confirm your choice of filename by hitting enter. Finally, exit the file with Control+X\n\n\n\n\n\nStep 6. Mount the project drive\nTo mount the project drive execute the command\nsudo mount /media/&lt;server_mount_point&gt;\nYou can also unmount the drive with\nfusermount -u /media/&lt;server_mount_point&gt;\nThe project drive will not mount automatically, so you will need to remount it manually each time you restart the server.\n\n\n\n\n\n\nNote\n\n\n\nIf the step above does not work, it probably means that the packages for mounting cifs-type filesystems haven‚Äôt been installed. Depending on your linux flavour you will need to install them using:\n\nUbuntu/DebianRedhat/Centos/Fedora\n\n\nsudo apt install cifs-utils\n\n\nsudo yum install cifs-utils",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Mount Project Drive on server"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_mounting.html#notes-and-next-steps",
    "href": "docs/data/data_storage/project_drive_mounting.html#notes-and-next-steps",
    "title": "Mount Project Drive on server",
    "section": "Notes and next steps",
    "text": "Notes and next steps\nThe steps above can also be used to mount any storage offered by TU Delft with a WebDav link (staff-homes, staff-groups, staff-bulk, student-homes, student-groups and apps). Simply use the latter half of the URL from the WebDav web link of your storage drive, which will change from staff-umbrella (project drive) to something else depending on the storage drive you would like to mount.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Mount Project Drive on server"
    ]
  },
  {
    "objectID": "docs/data/data_publishing/publishing.html",
    "href": "docs/data/data_publishing/publishing.html",
    "title": "Publishing data",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Archive and publish",
      "Publishing data"
    ]
  },
  {
    "objectID": "docs/data/data_publishing/licensing_data.html",
    "href": "docs/data/data_publishing/licensing_data.html",
    "title": "Data licensing",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Archive and publish",
      "Licensing"
    ]
  },
  {
    "objectID": "docs/data/data_processing.html",
    "href": "docs/data/data_processing.html",
    "title": "Data processing",
    "section": "",
    "text": "üèóÔ∏è Under construction! üöß",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Data processing"
    ]
  },
  {
    "objectID": "docs/data/data_collection/data_conventions.html",
    "href": "docs/data/data_collection/data_conventions.html",
    "title": "Data conventions",
    "section": "",
    "text": "Coming soon! ‚öôÔ∏è",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Collection",
      "Data conventions"
    ]
  },
  {
    "objectID": "docs/data/data_collection/access_reuse.html",
    "href": "docs/data/data_collection/access_reuse.html",
    "title": "Access and reuse",
    "section": "",
    "text": "Coming soon! üèóÔ∏è",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Collection",
      "Access and reuse"
    ]
  },
  {
    "objectID": "docs/community/dcc.html",
    "href": "docs/community/dcc.html",
    "title": "About the DCC",
    "section": "",
    "text": "About the DCC\nThe TU Delft Digital Competence Centre (DCC) is an on-campus initiative to help researchers make research data FAIR, improve research software, and apply computing practices to increase the efficiency of the research process. The DCC is an initiative of the Open Science Programme at TU Delft designed to benefit researchers at all levels.\nFor more information, please visit our website at dcc.tudelft.nl or email us at dcc@tudelft.nl."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others‚Äô private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at dcc@tudelft.nl. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla‚Äôs code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others‚Äô private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Code of Conduct",
    "section": "",
    "text": "Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at dcc@tudelft.nl. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla‚Äôs code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the DCC Guides!",
    "section": "",
    "text": "These guides are an initiative from TU Delft Digital Competence Centre and aim to provide a comprehensive entrypoint to get you started with Research Computing, Research Data, and Research Software at TU Delft.\n\n\n\n\n\n\nDisclaimer\n\n\n\nThe guides are under active development and mainly in use as a useful resource for the support provided by the DCC. The content is a compilation of developed solutions, relevant links and resources, and documents produced by colleagues inside and outside TU Delft. This is not an official TU Delft website, but rather a place where we keep note of things we find important and useful to share.\n\n\nThe guides are split into a few major sections:\n\nComputing Infrastructure contains information and guides on TU Delft ICT infrastructure.\nData Management contains information and guides on using TU Delft data storage options and best-practices for FAIR data.\nResearch Software contains information for creating FAIR research software.\nResources contains a collection of courses, workshops, and references.\n\n\n\n\n\n\n\nLearn more and get involved\n\n\n\nüôå Join the community\nWe welcome anyone to join us in improving our guides. To join, check out our contributing guide.\nüí¨ Join the discussion\nWe have community discussions, talk about ideas, share general questions and develop solutions and feedback in our community forum.\nüí° Open an issue\nWe track topic requests and bug-reports via GitHub issues.",
    "crumbs": [
      "Guides",
      "Getting started"
    ]
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing guidelines",
    "section": "",
    "text": "Do you have issues, tips, ideas, events, or questions related to Research Computing, Research Data, and Research Software at TU Delft?\nAre you a researcher interested in these topics?\nDo you work and collaborate with researchers on these topics?\n\nWe‚Äôre using GitHub Discussions as a place to connect with other members of our community. We hope that you:\n\nAsk questions about challenges you encounter\nShare ideas and solutions\nEngage with other community members\nBe welcoming and open-minded. Remember that this is a community we build together. See our Code of Conduct for more information.\n\n\n\n\nDo you have questions, ideas or ongoing developments on FAIR related aspects, Open Science, training, etc? Would you like to point to specific resources and potential solutions or ideas?\n\nUse the Q&A to ask a question on a specific topic, such as\n\nHow do I generate a reproducible software development environment?\nWhere can I find information on creating a Python package?\nHow should I archive my software?\nHow do I get started with git?\n\nUse Ideas to make proposals, for instance\n\nUsing jupyter hub for a workshop\nUsing jupyter books to create educational resources\nRunning monthly webinars for the community to transfer FAIR practices\n\nUse Solutions to point people to existing solutions or share your own. These solutions might end up on our Guides website to share with our community.\nShow and tell things you have done that you are proud of and like other to be aware of.\n\n\n\n\n\n\n\nFork the repository to your own GitHub profile.\nClone the repository.\nNavigate to the root of this repository in your terminal.\nInstall Quarto if you don‚Äôt already have it installed on your machine. You can find the installation instructions here.\n\nAlternative: Install Quarto within a virtual environment using the environment.yml file by following the below steps:\n\nRun conda env create -f environment.yml in the terminal to create a conda environment with Quarto pre-installed.\nActivate the environment by running conda activate dcc_guides.\n\n\n\nRun quarto preview.\nYou will see the rendered version in a browser window.\n\n\n\n\n\nFork the repository to your own GitHub profile.\nEither commit a new change to the repository to trigger the build action or manually trigger the action. To manually trigger the action, go to Actions -&gt; Quarto Publish Guides and press Run workflow and Run workflow.\nIn your forked repository, under Settings -&gt; Pages set Source to gh-pages and /(root) and press Save.\n\n\n\n\n\n(important) announce your plan to the rest of the community before you start working. This announcement should be in the form of a (new) issue;\n(important) wait until some kind of consensus is reached about your idea being a good idea;\nif needed, fork the repository to your own GitHub profile and create your own feature branch off of the latest main commit. While working on your feature branch, make sure to stay up to date with the main branch by pulling in changes, possibly from the ‚Äòupstream‚Äô repository (follow the instructions here and here);\npush your feature branch to (your fork of) the DCC guides repository on GitHub;\ncreate the pull request, e.g.¬†following the instructions here. If needed, provide a link to the gh-pages in your forked repository: https://&lt;your-username&gt;.github.io/TU-Delft-DCC.github.io/."
  },
  {
    "objectID": "CONTRIBUTING.html#welcome",
    "href": "CONTRIBUTING.html#welcome",
    "title": "Contributing guidelines",
    "section": "",
    "text": "Do you have issues, tips, ideas, events, or questions related to Research Computing, Research Data, and Research Software at TU Delft?\nAre you a researcher interested in these topics?\nDo you work and collaborate with researchers on these topics?\n\nWe‚Äôre using GitHub Discussions as a place to connect with other members of our community. We hope that you:\n\nAsk questions about challenges you encounter\nShare ideas and solutions\nEngage with other community members\nBe welcoming and open-minded. Remember that this is a community we build together. See our Code of Conduct for more information."
  },
  {
    "objectID": "CONTRIBUTING.html#how-to-participate",
    "href": "CONTRIBUTING.html#how-to-participate",
    "title": "Contributing guidelines",
    "section": "",
    "text": "Do you have questions, ideas or ongoing developments on FAIR related aspects, Open Science, training, etc? Would you like to point to specific resources and potential solutions or ideas?\n\nUse the Q&A to ask a question on a specific topic, such as\n\nHow do I generate a reproducible software development environment?\nWhere can I find information on creating a Python package?\nHow should I archive my software?\nHow do I get started with git?\n\nUse Ideas to make proposals, for instance\n\nUsing jupyter hub for a workshop\nUsing jupyter books to create educational resources\nRunning monthly webinars for the community to transfer FAIR practices\n\nUse Solutions to point people to existing solutions or share your own. These solutions might end up on our Guides website to share with our community.\nShow and tell things you have done that you are proud of and like other to be aware of."
  },
  {
    "objectID": "CONTRIBUTING.html#for-developers",
    "href": "CONTRIBUTING.html#for-developers",
    "title": "Contributing guidelines",
    "section": "",
    "text": "Fork the repository to your own GitHub profile.\nClone the repository.\nNavigate to the root of this repository in your terminal.\nInstall Quarto if you don‚Äôt already have it installed on your machine. You can find the installation instructions here.\n\nAlternative: Install Quarto within a virtual environment using the environment.yml file by following the below steps:\n\nRun conda env create -f environment.yml in the terminal to create a conda environment with Quarto pre-installed.\nActivate the environment by running conda activate dcc_guides.\n\n\n\nRun quarto preview.\nYou will see the rendered version in a browser window.\n\n\n\n\n\nFork the repository to your own GitHub profile.\nEither commit a new change to the repository to trigger the build action or manually trigger the action. To manually trigger the action, go to Actions -&gt; Quarto Publish Guides and press Run workflow and Run workflow.\nIn your forked repository, under Settings -&gt; Pages set Source to gh-pages and /(root) and press Save.\n\n\n\n\n\n(important) announce your plan to the rest of the community before you start working. This announcement should be in the form of a (new) issue;\n(important) wait until some kind of consensus is reached about your idea being a good idea;\nif needed, fork the repository to your own GitHub profile and create your own feature branch off of the latest main commit. While working on your feature branch, make sure to stay up to date with the main branch by pulling in changes, possibly from the ‚Äòupstream‚Äô repository (follow the instructions here and here);\npush your feature branch to (your fork of) the DCC guides repository on GitHub;\ncreate the pull request, e.g.¬†following the instructions here. If needed, provide a link to the gh-pages in your forked repository: https://&lt;your-username&gt;.github.io/TU-Delft-DCC.github.io/."
  },
  {
    "objectID": "docs/community/community.html",
    "href": "docs/community/community.html",
    "title": "Community",
    "section": "",
    "text": "Teams channel - DCC Community\nData Stewards\nOpen Science Program\nOpen Science Community\nDelft HPC\nData Champions\nICT Innovation\nStatistical Helpdesk\n\n\n\n\n4TU.ResearchData is an international data repository for science, engineering and design. Its services include curation, sharing, long-term access and preservation of research datasets. These services are available to anyone around the world. In addition, 4TU.ResearchData also offers training and resources to researchers to support them in making research data findable, accessible, interoperable and reproducible (FAIR).\n\n\n\nFounded in 2012 as an independent foundation by NWO and SURF, the Netherlands eScience Center is the national centre with the digital skills to create innovative software solutions in academic research. They award research projects based on calls for proposals, and train researchers in the use of research software. They offer our expertise in the form of research software engineers (RSEs), the technology specialists with expert digital skills who work with us at the Center.\n\n\n\nNL-RSE brings together the community of people writing and contributing to research software from Dutch universities, knowledge institutes, companies and other organizations to share knowledge, to organize meetings, and raise awareness for the scientific recognition of research software."
  },
  {
    "objectID": "docs/community/community.html#partners-within-the-tu-delft",
    "href": "docs/community/community.html#partners-within-the-tu-delft",
    "title": "Community",
    "section": "",
    "text": "Teams channel - DCC Community\nData Stewards\nOpen Science Program\nOpen Science Community\nDelft HPC\nData Champions\nICT Innovation\nStatistical Helpdesk"
  },
  {
    "objectID": "docs/community/community.html#tu.researchdata",
    "href": "docs/community/community.html#tu.researchdata",
    "title": "Community",
    "section": "",
    "text": "4TU.ResearchData is an international data repository for science, engineering and design. Its services include curation, sharing, long-term access and preservation of research datasets. These services are available to anyone around the world. In addition, 4TU.ResearchData also offers training and resources to researchers to support them in making research data findable, accessible, interoperable and reproducible (FAIR)."
  },
  {
    "objectID": "docs/community/community.html#escience-center",
    "href": "docs/community/community.html#escience-center",
    "title": "Community",
    "section": "",
    "text": "Founded in 2012 as an independent foundation by NWO and SURF, the Netherlands eScience Center is the national centre with the digital skills to create innovative software solutions in academic research. They award research projects based on calls for proposals, and train researchers in the use of research software. They offer our expertise in the form of research software engineers (RSEs), the technology specialists with expert digital skills who work with us at the Center."
  },
  {
    "objectID": "docs/community/community.html#nl-rse",
    "href": "docs/community/community.html#nl-rse",
    "title": "Community",
    "section": "",
    "text": "NL-RSE brings together the community of people writing and contributing to research software from Dutch universities, knowledge institutes, companies and other organizations to share knowledge, to organize meetings, and raise awareness for the scientific recognition of research software."
  },
  {
    "objectID": "docs/community/maintainers.html",
    "href": "docs/community/maintainers.html",
    "title": "Guide maintainers",
    "section": "",
    "text": "Guide maintainers\nThis content is automatically generated, all changes made will be lost.\n\n\n\n\n\n\n\n\n\nSection\nTitle\nLead maintainer\nBackup maintainer\n\n\n\n\ncontainers\nDocker users\nMaurits Kok\n\n\n\ndata\nRequestProject Drive\nAshley Cryan\n\n\n\ndata\nSync with Unison\nAshley Cryan\n\n\n\ndata\nMount Project Drive\nRa√∫l Ortiz Merino\nMaurits Kok\n\n\ndata\nData publishing\nAleksandra Wilczynska\n\n\n\ngitlab\nTransfer ownership of a GitLab repository\nLora Armstrong\nMaurits Kok\n\n\ngitlab\nCI with Gitlab\nAshley Cryan\nMaurits Kok\n\n\ngitlab\nGitLab runner for MATLAB\nMaurits Kok\n\n\n\ninfrastructure\nOverview\nMaurits Kok\nJose Urra\n\n\ninfrastructure\nRequest SSL Certificate\nAshley Cryan\n\n\n\ninfrastructure\nRequest VPS\nAshley Cryan\n\n\n\ninfrastructure\nSet up an Apache web server\nAshley Cryan\n\n\n\nresources\nCurriculum\nAshley Cryan\nMaurits Kok\n\n\nsoftware\nFAIR4RS checklist\nMaurits Kok\nElviss Dvinskis\n\n\nsoftware\nSoftware Management Plan\nMaurits Kok\n\n\n\nsoftware\nBranch management\nMaurits Kok\n\n\n\ntesting\nTesting with MATLAB\nMaurits Kok"
  },
  {
    "objectID": "docs/data/data_collection/collection.html",
    "href": "docs/data/data_collection/collection.html",
    "title": "Data collection",
    "section": "",
    "text": "Under construction! üèóÔ∏è\n\n\n\n\n Data conventions\n\nüöß Coming soon! ‚è≥\n\nLearn more ¬ª\n\n\n\n Data access and reuse\nüöß Coming soon! ‚è≥\n\nLearn more ¬ª\n\n\n\n eLabJournal and RSpace\nüöß Coming soon! ‚è≥\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Collection"
    ]
  },
  {
    "objectID": "docs/data/data_collection/elab_rspace.html",
    "href": "docs/data/data_collection/elab_rspace.html",
    "title": "eLabJournal and RSpace",
    "section": "",
    "text": "Coming soon! ‚öôÔ∏è",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Collection",
      "eLabJournal and RSpace"
    ]
  },
  {
    "objectID": "docs/data/data_publishing/archival_publishing_index.html",
    "href": "docs/data/data_publishing/archival_publishing_index.html",
    "title": "Archive and publish",
    "section": "",
    "text": "üöß Under construction! üèóÔ∏è\n\n\n\n\n Licensing\n\n‚è∞ Coming soon!\n\nLearn more ¬ª\n\n\n\n Publishing data\n\n‚è∞ Coming soon!\n\nLearn more ¬ª\n\n\n\n Offboarding and ownership\n‚è∞ Coming soon!\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Archive and publish"
    ]
  },
  {
    "objectID": "docs/data/data_publishing/offboarding.html",
    "href": "docs/data/data_publishing/offboarding.html",
    "title": "Offboarding and ownership",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Archive and publish",
      "Offboarding and ownership"
    ]
  },
  {
    "objectID": "docs/data/data_storage/backup.html",
    "href": "docs/data/data_storage/backup.html",
    "title": "Data backup",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Data backup"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_request.html",
    "href": "docs/data/data_storage/project_drive_request.html",
    "title": "Request Project Drive space",
    "section": "",
    "text": "TU Delft offers several options for researchers to store their data. One of the most commonly recommended options is the Project Drive (Project Data, U:) for its large storage capacity and secure backups from the University.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Request Project Drive space"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_request.html#background",
    "href": "docs/data/data_storage/project_drive_request.html#background",
    "title": "Request Project Drive space",
    "section": "",
    "text": "TU Delft offers several options for researchers to store their data. One of the most commonly recommended options is the Project Drive (Project Data, U:) for its large storage capacity and secure backups from the University.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Request Project Drive space"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_request.html#what-this-documentation-will-help-achieve",
    "href": "docs/data/data_storage/project_drive_request.html#what-this-documentation-will-help-achieve",
    "title": "Request Project Drive space",
    "section": "What this documentation will help achieve",
    "text": "What this documentation will help achieve\nThis documentation will walk through the steps needed to request Project Drive storage from TU Delft ICT. This storage can then be accessed directly through webdata.tudelft.nl (uses WebDAV protocol), through a client like WebDrive on your local machine (click on the link and then the WebDrive heading to download and install this software for your operating system), or mounted to a TU Delft Virtual Private Server following the instructions here.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Request Project Drive space"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_request.html#prerequisites",
    "href": "docs/data/data_storage/project_drive_request.html#prerequisites",
    "title": "Request Project Drive space",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nTU Delft netID\nAn Excel file with the netIDs of TU Delft collaborators who should have read/write access to the Project Drive storage space you are requesting (optional)",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Request Project Drive space"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_request.html#toolssoftware",
    "href": "docs/data/data_storage/project_drive_request.html#toolssoftware",
    "title": "Request Project Drive space",
    "section": "Tools/Software",
    "text": "Tools/Software\n\nWebDrive (optional GUI to access data on Project Drive)",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Request Project Drive space"
    ]
  },
  {
    "objectID": "docs/data/data_storage/project_drive_request.html#steps",
    "href": "docs/data/data_storage/project_drive_request.html#steps",
    "title": "Request Project Drive space",
    "section": "Steps",
    "text": "Steps\n\nRequest Project Drive storage via the TU Delft ICT form on TopDesk\nFill and send the form according to your data storage preferences and requirements\nAccess your data storage on Project Drive\n\n\nStep 1. Request Project Drive storage via the TU Delft ICT form on TopDesk\nYou can make a request for data storage via the TopDesk self service portal. Navigate to this form (requires netID sign in) and see below for guidance on how to fill in each of the sections.\n\n\nStep 2. Fill and send the form according to your data storage preferences and requirements\nThe form is divided into three sections: ‚ÄúCaller‚Äù, ‚ÄúInformation about Requester and Data‚Äù, and ‚ÄúData for a Research Project‚Äù.\nThe Caller section should contain the contact information of the main administrator of this server. If you select your name, the fields below should be auto-populated with your building, phone number, email, department/program, organizational unit, and (sometimes) room.\n\n\nIn the next part you choose your preferences about data preservation. The first question asks whether you are setting up new storage on the Project Drive, or want to change existing storage. The next question is about the availability - see below for more information. The usual choice here is ‚ÄúStandard‚Äù.\n\nFor the next question, you need to determine if your data is critical, sensitive, or standard, using these criteria:\n\nThere are two options for backup retention: standard and high. Data are backed up by ICT on a daily basis, so the retention time refers to the period for which these backups are stored. The standard option refers to 14 days of retention while in the other one the retention period is one year. In other words, if the retention time is set to 14 days (Standard) and you delete a file, you can restore it within those two weeks. If retention time is 1 year (High), you can restore it anytime within the year. For most situations, a Standard backup retention time is suitable.\n\nIn the final section, you need to provide some information about your research project. Depending on your research needs, you should specify how much space you will need on the Project Drive to hold all your data, initially and into the planned future. It is important to know that the Project Drive storage is able to expand as your data grows, but you should make your best guess when requesting the space.\nAt the bottom of this section you can attach an Excel file that contains the netIDs of TU Delft affiliated employees that should have read/write access to the storage you are requesting on the Project Drive. If access to the storage is required for TU Delft external researchers, this information can be added as well. Note that it is unusual that non-TU Delft personnel are added to Project Drive storage, and if you would like to do so you should provide a company-affiliated email address for each person you want to add.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options",
      "Request Project Drive space"
    ]
  },
  {
    "objectID": "docs/data/data_storage/sharing.html",
    "href": "docs/data/data_storage/sharing.html",
    "title": "Data sharing",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Data sharing"
    ]
  },
  {
    "objectID": "docs/data/data_storage/storage_options.html",
    "href": "docs/data/data_storage/storage_options.html",
    "title": "Storage options",
    "section": "",
    "text": "Under construction! üèóÔ∏è\n\n\n\n\n Request Project Drive space\nUpdate coming soon! üõ†Ô∏è\n\nLearn more ¬ª\n\n\n\n Mount Project Drive on server\nUpdate coming soon! üõ†Ô∏è\n\nLearn more ¬ª\n\n\n\n Sync Project Drive and SURFDrive with Unison\nUpdate coming soon! üõ†Ô∏è\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Storage",
      "Storage options"
    ]
  },
  {
    "objectID": "docs/data/fair_data/fair.html",
    "href": "docs/data/fair_data/fair.html",
    "title": "FAIR data",
    "section": "",
    "text": "The goal of the FAIR principles is to improve research transparency, reproducibility and reusability. FAIR data enhances research reliability, impact, and visibility, creating new collaboration opportunities for researchers. The acronym FAIR stands for:\n\nFindable: Data should be findable by users. A straightforward and reliable way to achieve this is by depositing data in a repository with appropriate metadata, tags, and identifiers to improve searchability.\nAccessible: Data should be accessible to authorized users. This does not mean all data must be publicly available; rather, it should be ‚Äúas open as possible, as closed as necessary‚Äù. If data cannot be made publicly available due to sensitive information or commercial restrictions, the metadata should still be made public to indicate where and how the data can be accessed if needed.\nInteroperable: Data should be in standardized formats with a clear structure to allow it to be interoperable across different systems, enabling data to be used in various applications by both the data owners and other users.\nReusable: For data to be reusable, users must understand what the data represents, the information it contains, and how to interpret its structure and format. Good documentation and an appropriate license are key in reusability, as these enable others to understand and work with your dataset, especially upon publication.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "FAIR Data"
    ]
  },
  {
    "objectID": "docs/data/planning/ethics.html",
    "href": "docs/data/planning/ethics.html",
    "title": "Ethics",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Planning",
      "Ethics"
    ]
  },
  {
    "objectID": "docs/data/planning/privacy_and_security.html",
    "href": "docs/data/planning/privacy_and_security.html",
    "title": "Privacy and security",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üóÉÔ∏è</span> **Data Management**",
      "Planning",
      "Privacy and security"
    ]
  },
  {
    "objectID": "docs/img/licences.html",
    "href": "docs/img/licences.html",
    "title": "",
    "section": "",
    "text": "testing-pyramid.jpg\n\n\n\n\ntesting-pyramid.jpg\n\n\nPermission: ‚ÄúAll I ask is that you provide attribution to me (e.g., credit @SketchingDev and link back to the original source).‚Äù See https://github.com/SketchingDev/sketchingdev.github.io/issues/20#issuecomment-2690689502"
  },
  {
    "objectID": "docs/infrastructure/VPS_SSL_Certs.html",
    "href": "docs/infrastructure/VPS_SSL_Certs.html",
    "title": "Configure SSL certificates",
    "section": "",
    "text": "It is common practice to have web servers serving content over HTTPS, which is the secure version of HTTP. In order to do this and make the connection secure, you need an SSL certificate from a certificate signing authority.\nThe role of the SSL certificate is to indicate the encryption of user data from a server exposed on the web. SSL is a key for encrypting information. When a website‚Äôs certificate is expired or invalid, or if it using a self-signed (unofficial) certificate, as a user you either get a warning saying, ‚Äúgo back to safety,‚Äù or can‚Äôt access the website over https - instead you see a message that says ‚ÄúNot Secure‚Äù in your web browser. This means that the certificate is not signed by an authority, so it‚Äôs not trusted.\nIn theory, if your web server is universally accessible and doesn‚Äôt contain forms for users with personal or confidential information, there is no strict need for HTTPS connection. But, HTTPS is the modern standard and without it, visitors will have impression that the website is not safe. Therefore it is good practice to always have HTTPS on your web server.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSL certificates"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSL_Certs.html#background",
    "href": "docs/infrastructure/VPS_SSL_Certs.html#background",
    "title": "Configure SSL certificates",
    "section": "",
    "text": "It is common practice to have web servers serving content over HTTPS, which is the secure version of HTTP. In order to do this and make the connection secure, you need an SSL certificate from a certificate signing authority.\nThe role of the SSL certificate is to indicate the encryption of user data from a server exposed on the web. SSL is a key for encrypting information. When a website‚Äôs certificate is expired or invalid, or if it using a self-signed (unofficial) certificate, as a user you either get a warning saying, ‚Äúgo back to safety,‚Äù or can‚Äôt access the website over https - instead you see a message that says ‚ÄúNot Secure‚Äù in your web browser. This means that the certificate is not signed by an authority, so it‚Äôs not trusted.\nIn theory, if your web server is universally accessible and doesn‚Äôt contain forms for users with personal or confidential information, there is no strict need for HTTPS connection. But, HTTPS is the modern standard and without it, visitors will have impression that the website is not safe. Therefore it is good practice to always have HTTPS on your web server.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSL certificates"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSL_Certs.html#what-this-documentation-will-help-achieve",
    "href": "docs/infrastructure/VPS_SSL_Certs.html#what-this-documentation-will-help-achieve",
    "title": "Configure SSL certificates",
    "section": "What this documentation will help achieve",
    "text": "What this documentation will help achieve\nSSL certificates for TU Delft researchers and staff may be requested by contacting the ICT service desk. TU Delft ICT will order SSL certificates on your behalf from a trusted certificate signing authority.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSL certificates"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSL_Certs.html#prerequisites",
    "href": "docs/infrastructure/VPS_SSL_Certs.html#prerequisites",
    "title": "Configure SSL certificates",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nTU Delft netID\nLinux-based VPS provided by TU Delft ICT\n(optional) 1-step SSH connection established (see instructions ___)",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSL certificates"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSL_Certs.html#toolssoftware",
    "href": "docs/infrastructure/VPS_SSL_Certs.html#toolssoftware",
    "title": "Configure SSL certificates",
    "section": "Tools/Software",
    "text": "Tools/Software\n\nNone",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSL certificates"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSL_Certs.html#steps",
    "href": "docs/infrastructure/VPS_SSL_Certs.html#steps",
    "title": "Configure SSL certificates",
    "section": "Steps",
    "text": "Steps\n\nGenerate .csr file\nSecure-copy .csr file from server to local machine\nSubmit Certificate Server Request to TU Delft ICT via TopDesk form\n\n\nStep 1. Generate .csr file\nThe Certificate Signing Request (.csr) file is a file generated by you in a standard format that contains all the information the signing authority needs to create a signed certificate. You will need to include this .csr file in submitting your SSL certificate request form to TU Delft ICT, and you should generate it on your VPS directly. The instructions for generating a .csr file come from here.\nSSH to your VPS (____ link if you have followed the process to connect directly, you can use: username@localmachine ~ % ssh externalserveralias)\nEnter following command in the terminal: Note: replace mydomain with your actual domain name:\nusername@externalserver ~ % openssl req -new -newkey rsa:2048 -nodes -keyout mydomain.key -out mydomain.csr\nYou will be prompted to answer a series of questions:\n\nCountry name: 2 letter abbreviation for your country. Netherlands is NL.\nState or Province Name: this is where your org operates from. Zuid-Holland.\nLocality Name - name of the city your org operates from. Don‚Äôt use abbreviations in this field.\nOrganisation Name - use your (organisation‚Äôs) full name.\nOrganisational Unit Name - Use a department name ex. ‚ÄúIT Department‚Äù or ‚ÄúLibrary‚Äù\nCommon Name - the FQDN that you are requesting an SSL certificate for.\nEmail address\nOptional password (can skip step)\nOptional company name\n\nYour CSR file has now been generated. To find your CSR, take a look at the contents of your current working directory with the ls command. You should notice two new files ending with ‚Äú.key‚Äù and ‚Äú.csr‚Äù respectively. For example:\nusername@externalserver ~ % ls\n-rw-r--r--. 1 root root 1082 Jan 31 12:10 mydomain.csr\n-rw-------. 1 root root 1704 Jan 31 12:10 mydomain.key\nThe .key file should be kept private on your server. The .csr file is your certificate signing request, and can be sent to a Certificate Authority.\n\n\nStep 2. Secure-copy .csr file from server to local machine\nIn this step we use Secure Copy protocol (SCP) which is a means of securely transferring files between hosts on a network. This example will save the file in the Home directory, but you can also save it into any other project folder on your machine.\nNavigate to directory of choice. In this case, we‚Äôll use home.\nusername@localmachine .ssh % cd ~\nUse scp to secure copy .csr file from your external server. If you have followed ___these steps to enable 1-step SSH access to your VPS, you can do this using the alias you set, and the .csr file name which should be your external server FQDN.csr. Don‚Äôt forget to add the . at the end of the command.\nusername@localmachine ~ % scp externalserveralias:~/external-server-FQDN.nl.csr .\nCheck to see that it saved on your local machine using ls:\nusername@localmachine ~ % ls\nApplications        Movies\nDesktop             Music\nDocuments           Pictures\nDownloads           Public\nDropbox             external-server-FQDN.nl.csr\nLibrary             surfdrive\nIf you have not set up 1-step SSH connection to your VPS, the file transfer procedure from the VPS to your local computer is composed of two steps:\n\nFrom the VPS to the intermediary server, and\nFrom the intermediary server to the local computer.\n\nFor the first step use:\nscp &lt;path to the csr file&gt; &lt;netid&gt;@&lt;intermediary_server_address&gt;:&lt;a path in the intermediary_server&gt; (e.g., scp thredds.tudelft.nl.csr mynetid@linux-bastion-ex.tudelft.nl:~).\nIn the second step, you need to copy the file from the intermediary server to the local computer using the same command but with a different source and destination:\nscp &lt;netid&gt;@&lt;intermediary_server_address&gt;:&lt;the path in the intermediary_server to the selected file&gt; &lt;a path in the local computer&gt; (e.g., scp mynetid@linux-bastion-ex.tudelft.nl:~/thredds.tudelft.nl.csr .)\nPlease note, if you are a Windows user, for the second step you need to install cygwin and ssh to the intermediary server using:\nssh &lt;netid&gt;@&lt;intermediary_server_address&gt; (e.g., ssh mynetid@linux-bastion-ex.tudelft.nl).\n\n\nStep 3. Submit Certificate Server Request to TU Delft ICT via TopDesk form\nTU Delft ICT will use the information stored in your .csr file to get the SSL certificate from the signing authority and send the SSL certificate to you. In order to make this request, you must attach your .csr file from the previous step.\nNavigate to TopDesk form for TU Delft. TOPdesk SSL certificate server request.\nChoose ‚ÄúAttach file‚Äù and navigate to directory where .csr file is stored** (in this example, it is in ‚ÄúHome‚Äù). Select ‚Äúexternal-server-FQDN.nl.csr‚Äù.\nSubmit request. You can delete this file from your home directory after you submit the form.\nICT will respond with a SSL certificate (with the extension .crt, .cer, and/or .pem) that comes from the signing authority. When you have this, you can configure the SSL certificate to work with the web server on your VPS.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSL certificates"
    ]
  },
  {
    "objectID": "docs/infrastructure/VPS_SSL_Certs.html#notes-and-next-steps",
    "href": "docs/infrastructure/VPS_SSL_Certs.html#notes-and-next-steps",
    "title": "Configure SSL certificates",
    "section": "Notes and Next Steps",
    "text": "Notes and Next Steps\nSSL certificates can expire - TU Delft ICT will let you know when this is about to happen. To renew, you will need a new .csr file. You can send this to TU Delft ICT via the original TopDesk form and they will forward to the signing authority.\nTo use your SSL certificate with your web server, you need to change some configuration settings based on the web server you are using (e.g., Apache, nginx). See ___Set up an Apache web server for more information.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Configure SSL certificates"
    ]
  },
  {
    "objectID": "docs/infrastructure/apache_webserver.html",
    "href": "docs/infrastructure/apache_webserver.html",
    "title": "Set up an Apache web server",
    "section": "",
    "text": "If you want to host a website for your lab, or a web application of some sort, you are going to need to work with a webserver. Apache Web Server is a software package that turns a computer into an HTTP server. That is, it sends web pages ‚Äì stored as HTML files ‚Äì to people on the internet who request them. It is open-source software, which means it can be used and modified freely.\n\nThe job of a web server is to serve websites on the internet. To achieve that goal, it acts as a middleman between the server and client machines. It pulls content from the server on each user request and delivers it to the web‚Ä¶..One of the most popular web servers, Apache allows you to run a secure website without too much of a headache. It is free and open-source, making it a frequent choice of solopreneurs and small businesses who want a presence on the web‚Ä¶..The way Apache HTTP server works is that it will accept requests from the web browser, such as Google Chrome and Microsoft Edge, and turn programming scripts into web pages which contents are visible by the visitors.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Setting up an Apache web server"
    ]
  },
  {
    "objectID": "docs/infrastructure/apache_webserver.html#background",
    "href": "docs/infrastructure/apache_webserver.html#background",
    "title": "Set up an Apache web server",
    "section": "",
    "text": "If you want to host a website for your lab, or a web application of some sort, you are going to need to work with a webserver. Apache Web Server is a software package that turns a computer into an HTTP server. That is, it sends web pages ‚Äì stored as HTML files ‚Äì to people on the internet who request them. It is open-source software, which means it can be used and modified freely.\n\nThe job of a web server is to serve websites on the internet. To achieve that goal, it acts as a middleman between the server and client machines. It pulls content from the server on each user request and delivers it to the web‚Ä¶..One of the most popular web servers, Apache allows you to run a secure website without too much of a headache. It is free and open-source, making it a frequent choice of solopreneurs and small businesses who want a presence on the web‚Ä¶..The way Apache HTTP server works is that it will accept requests from the web browser, such as Google Chrome and Microsoft Edge, and turn programming scripts into web pages which contents are visible by the visitors.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Setting up an Apache web server"
    ]
  },
  {
    "objectID": "docs/infrastructure/apache_webserver.html#what-this-documentation-will-help-achieve",
    "href": "docs/infrastructure/apache_webserver.html#what-this-documentation-will-help-achieve",
    "title": "Set up an Apache web server",
    "section": "What this documentation will help achieve",
    "text": "What this documentation will help achieve\nThis guide will help you install the Apache web server on Ubuntu Linux and configure a HTTPS secure connection for all incoming web traffic.\nThe steps outlined below will ensure that all incoming web traffic to your server from port 80 (HTTP) will be redirected to port 443 (HTTPS). Port 80 is still accessible but redirects automatically. Redirection is configured after the SSL certificate is in place.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Setting up an Apache web server"
    ]
  },
  {
    "objectID": "docs/infrastructure/apache_webserver.html#prerequisites",
    "href": "docs/infrastructure/apache_webserver.html#prerequisites",
    "title": "Set up an Apache web server",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nA system running Ubuntu Server\nAn internet connection\nAccess to a user account with sudo privileges",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Setting up an Apache web server"
    ]
  },
  {
    "objectID": "docs/infrastructure/apache_webserver.html#tools-software",
    "href": "docs/infrastructure/apache_webserver.html#tools-software",
    "title": "Set up an Apache web server",
    "section": "Tools / Software",
    "text": "Tools / Software\n\nA command-line utility (Use keyboard shortcut CTRL-ALT-T, or right-click the desktop and left-click Open Terminal)\nA firewall ‚Äì the default UFW (Uncomplicated Firewall) in Ubuntu is fine\nThe APT package manager, installed by default on Ubuntu",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Setting up an Apache web server"
    ]
  },
  {
    "objectID": "docs/infrastructure/apache_webserver.html#steps",
    "href": "docs/infrastructure/apache_webserver.html#steps",
    "title": "Set up an Apache web server",
    "section": "Steps",
    "text": "Steps\n\nRequest a Virtual Private Server (VPS) from TU Delft ICT\nInstall Apache web server on the VPS\nRequest an SSL certificate from TU Delft ICT\nConfigure the SSL certificate file on your VPS\nRedirect all incoming web traffic to HTTPS\n\n\nStep 1. Request a Virtual Private Server from TU Delft ICT\nYou can make a request for a server via the TopDesk self service portal. If you would like more information, documentation can be found here ___\nNote: to run a web server, ports 80 (HTTP) and 443 (HTTPS) must be opened.\n\n\nStep 2. Install Apache web server on the VPS\nApache is an open source web server that‚Äôs available for Linux servers. It is one of the most commonly used softwares for creating a web server. And, it‚Äôs free!\nInstalling Apache can be done using commands in the terminal. These instructions are documented with further information at the link in the beginning of this paragraph. First, make sure your local software packages are up to date by running:\nsudo apt-get update\nWhen that has finished, install the Apache package using:\nsudo apt-get install apache2\nThe system prompts for confirmation ‚Äì do so, and allow the system to complete the installation.\nFind the IP address of your VPS by running:\nhostname -I | awk '{print $1}'\nUse this IP address to enter the following command in your terminal, replacing local.server.ip with the actual IP address of your server:\nhttp://local.server.ip\nIf the installation was completed successfully, you should see the Apache2 Ubuntu Default page in your web browser.\nAlthough the Apache installation process is complete, there is one more additional step. Configure the default UFW firewall to allow traffic on port 80.\nStart by displaying available app profiles on UFW:\nsudo ufw show app list\nUse the following command to allow normal web traffic on port 80:\nsudo ufw allow 'Apache Full'\nVerify the changes by checking UFW status:\nsudo ufw status\nAt this point, your Apache web server is serving over HTTP, which is a good first step! But remember, we need to secure the connection over HTTPS. So, we still have a few more steps.\n\n\nStep 3. Request an SSL certificate from TU Delft ICT\nDetailed directions on how to do this can be found here ___\nYou can create the .csr file directly on the VPS by first create a directory on /etc/apache2 called ssl:\nmkdir /etc/apache2/ssl\nThen, generate a CSR and private key using:\nopenssl req -x509 -newkey rsa:4096 -keyout &lt;server_domain&gt;.key -out &lt;server_domain&gt;.csr -nodes\nAfter successfully running the command it will ask for the information of certificate request. Complete it using the appropriate information and then .key and .csr files will be generated.\nThe .csr file must be sent to TU Delft ICT using this TopDesk form: TOPdesk SSL certificate server request.\n\n\nStep 4. Configure the SSL certificate on your VPS\nWhen you receive SSL certificate files from the signing authority via TU Delft ICT, you need to put the information from this certificate in a specific place on your VPS in order to securely expose the web server. These instructions come from here: - Configure ssl for https\nNavigate to the default Apache site config directory using the following command:\nsudo nano /etc/apache2/sites-available/default-ssl.conf\nThis config file tells the server where to find SSL certificate. It should look like this:\n                &lt;IfModule mod_ssl.c&gt;\n                &lt;VirtualHost _default_:443&gt;\n                ServerAdmin webmaster@localhost\n\n                DocumentRoot /var/www/html\n\n                ErrorLog ${APACHE_LOG_DIR}/error.log\n                CustomLog ${APACHE_LOG_DIR}/access.log combined\n\n                SSLEngine on\n\n                SSLCertificateFile    /etc/ssl/certs/ssl-cert-snakeoil.pem\n                SSLCertificateKeyFile /etc/ssl/private/ssl-cert-snakeoil.key\n\n                &lt;FilesMatch \".(cgi|shtml|phtml|php)$\"&gt;\n                SSLOptions +StdEnvVars\n                &lt;/FilesMatch&gt;\n                &lt;Directory /usr/lib/cgi-bin&gt;\n                SSLOptions +StdEnvVars\n                &lt;/Directory&gt;\n\n                &lt;/VirtualHost&gt;\n                &lt;/IfModule&gt;\nEdit this: ServerAdmin webmaster@localhost to this: ServerAdmin email@example.net\nAdd this right below the ServerAdmin line:\n                ServerName ADD_YOUR_IP_OR_DOMAIN_NAME_HERE\nNow, edit these lines with our certificate location:\n                SSLCertificateFile    /etc/apache2/ssl/apache.crt\n                SSLCertificateKeyFile /etc/apache2/ssl/apache.key\nOur file should look like this:\n                &lt;IfModule mod_ssl.c&gt;\n                &lt;VirtualHost _default_:443&gt;\n                ServerAdmin email@example.net\n                ServerName 203.0.113.122\n\n                DocumentRoot /var/www/html\n\n                ErrorLog ${APACHE_LOG_DIR}/error.log\n                CustomLog ${APACHE_LOG_DIR}/access.log combined\n\n                SSLEngine on\n\n                SSLCertificateFile    /etc/apache2/ssl/apache.crt\n                SSLCertificateKeyFile /etc/apache2/ssl/apache.key\n\n                &lt;FilesMatch \".(cgi|shtml|phtml|php)$\"&gt;\n                SSLOptions +StdEnvVars\n                &lt;/FilesMatch&gt;\n                &lt;Directory /usr/lib/cgi-bin&gt;\n                SSLOptions +StdEnvVars\n                &lt;/Directory&gt;\n\n                &lt;/VirtualHost&gt;\n                &lt;/IfModule&gt;\nSave the file, and close it.\nNote: If you are using something other than Apache Web Server (like, nginx for example) you can also create the SSL config file from scratch. Each application will have different syntax that should be used in this file. You can see how the syntax is set up by using this tool\nEnable the SSL module using following command:\nsudo a2enmod ssl\nNow enable the site we have just edited:\nsudo a2ensite default-ssl.conf\nRestart Apache:\nsudo service apache2 restart\nThe website is now secure, access it using following address in the browser\nhttps://YOUR_SERVER_IP\n\n\nStep 5. Redirect all incoming web traffic to HTTPS\nsudo a2enmod proxy\nsudo a2enmod proxy_http\nsudo a2enmod rewrite\nAdd in apache conf:\n                ProxyPass /thredds http://localhost:8080/thredds\n                ProxyPassReverse /thredds http://localhost:8080/thredds\n                RedirectMatch ^/$ /thredds/",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Setting up an Apache web server"
    ]
  },
  {
    "objectID": "docs/infrastructure/apache_webserver.html#notes-and-next-steps",
    "href": "docs/infrastructure/apache_webserver.html#notes-and-next-steps",
    "title": "Set up an Apache web server",
    "section": "Notes and Next Steps",
    "text": "Notes and Next Steps\nTest that your web server is secured by HTTPS by typing the Fully Qualified Domain Name (FQDN) of your server in a web browser. If HTTPS is enabled, the URL should begin with it - if it still says HTTP, something will need to be reconfigured.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers",
      "Setting up an Apache web server"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_docker.html",
    "href": "docs/infrastructure/gitlab/gitlab_docker.html",
    "title": "CI with Gitlab",
    "section": "",
    "text": "If you happen to be working with TU Delft GitLab instance and you want to implement DevOps or CI/CD pipelines, then you need to install a GitLab runner on your own. This should runner should be in a server, responding to changes such as commits or pull requests in your GitLab repository.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Continuous Integration with GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_docker.html#background",
    "href": "docs/infrastructure/gitlab/gitlab_docker.html#background",
    "title": "CI with Gitlab",
    "section": "",
    "text": "If you happen to be working with TU Delft GitLab instance and you want to implement DevOps or CI/CD pipelines, then you need to install a GitLab runner on your own. This should runner should be in a server, responding to changes such as commits or pull requests in your GitLab repository.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Continuous Integration with GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_docker.html#quick-overview-of-how-it-works",
    "href": "docs/infrastructure/gitlab/gitlab_docker.html#quick-overview-of-how-it-works",
    "title": "CI with Gitlab",
    "section": "Quick overview of how it works",
    "text": "Quick overview of how it works\nIn order to be ready to run CI/CD pipeline, a gitlab-runner Docker container is running on the server all the time. When a new commit is made in the GitLab repository, this triggers the CI/CD process to run a job (e.g., unit test) based on the pipeline defined in the .gitlab-ci.yml file in the repository. The container used to carry out the CI/CD tests is defined in the .gitlab-ci.yml file in the first line, and spawned from within the continuously running gitlab-runner container. In our example, we define image:python:3.12.3 so every time a commit is made in the repository, a new container based on the python:3.12.3 Docker image is started and used to run tests on the python scripts and generate artifacts as defined in the .gitlab-ci.yml file.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Continuous Integration with GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_docker.html#what-this-documentation-will-help-achieve",
    "href": "docs/infrastructure/gitlab/gitlab_docker.html#what-this-documentation-will-help-achieve",
    "title": "CI with Gitlab",
    "section": "What this documentation will help achieve",
    "text": "What this documentation will help achieve\nThe documentation below will help you deploy GitLab runner in a Docker container on a server to automatically run CI/CD tests and store artifacts every time there is a new commit to a GitLab repository.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Continuous Integration with GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_docker.html#prerequisites",
    "href": "docs/infrastructure/gitlab/gitlab_docker.html#prerequisites",
    "title": "CI with Gitlab",
    "section": "Prerequisites",
    "text": "Prerequisites\nServer: This example uses a server to run the whole process. You can request a server from TU Delft ICT service following these directions here. It is useful to set this up on a server so that Docker can be running continuously, and be ready to run CI/CD tests whenever a new commit occurs in the repository.\nDocker: We use a Docker container to run the GitLab runner and initialise the CI/CD pipeline.\nGitlab runner: (from GitLab documentation) ‚ÄúRunners are the agents that run the CI/CD jobs that come from GitLab. When you register a runner, you are setting up communication between your GitLab instance and the machine where GitLab Runner is installed. Runners usually process jobs on the same machine where you installed GitLab Runner.‚Äù Link\nGitLab repository: A remote repository that can store your code and keeps track of your project development. You‚Äôre on one right now! :) If you haven‚Äôt already, you use your netID and password to login to TU Delft‚Äôs GitLab instance at gitlab.tudelft.nl and create a repository containing your project code.\nCI/CD pipeline: ‚ÄúA CI/CD pipeline automates your software delivery process. The pipeline builds code, runs tests (CI), and safely deploys a new version of the application (CD)‚Äù Link.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Continuous Integration with GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_docker.html#toolssoftware",
    "href": "docs/infrastructure/gitlab/gitlab_docker.html#toolssoftware",
    "title": "CI with Gitlab",
    "section": "Tools/Software",
    "text": "Tools/Software\n\nGitLab (TU Delft instance)\nDocker\ngitlab-runner Docker image",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Continuous Integration with GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_docker.html#steps",
    "href": "docs/infrastructure/gitlab/gitlab_docker.html#steps",
    "title": "CI with Gitlab",
    "section": "Steps",
    "text": "Steps\n\nRequest the server\nConnect to the server via ssh\nInstall Docker on the server\nPull in the gitlab-runner image\nCreate a unit test function stored as a file in the repository\nMake the .gitlab-ci.yml file\nSet up the GitLab runner\nDeploy the GitLab runner in a Docker container\nRegister the runner\nTest the CI/CD pipeline\n\n\nStep 1. Request server running Ubuntu\nIf you don‚Äôt have a VPS already, you can request one from TU Delft ICT. Instructions for requesting a server and storage from ICT can be found under Remote servers/Request a Virtual Private Server.\nWe recommend the following configuration for configuring a GitLab runner:\n\nBasic Configuration 4 (Ubuntu)\nNo additional ports need to be configured for deploying a GitLab runner with Docker.\nAdditional space if your Docker images are larger than ~10Gb.\n\n\n\nStep 2. Connect to the server via ssh\nThe email response from Sysadmin@TUDelft.nl confirming the successful deployment of your server should contain instructions to connect via ssh.\nThe default login procedure is to connect to the Bastion host (an intermediary server) and then to your server, so it is a two-step process. Please check your email for Steps A and B as described by ICT admin.\nYou can also connect to your server using Putty (Windows) or, on Mac/Linux, configure one-step access by storing ssh keys between your local machine and your server and designating an alias.\nWhen you are successfully connected, you should see in your terminal/command prompt something like this:\n\n\n\nStep 3. Install Docker on the server\nServers often do not come with Docker installed, so you may need to do it by yourself. To check whether Docker is installed, run docker --version. If you get an error message, you can install it using the following commands:\nsudo su (this will give you the root access) apt install docker.io\nNow, Docker is installed. You can check if it is installed successfully by again typing docker --version in the terminal. The result should show the version of Docker you just installed.\n\n\nStep 4. Pull the gitlab-runner Docker image\nIn order to run CI/CD jobs for your repository, you need to install GitLab Runner. GitLab Runner is an application that works with GitLab CI/CD to run jobs in a pipeline. Rather than install GitLab Runner directly on the server, we will run a lightweight version of it as a Docker container. To do so, we first need to pull the gitlab-runner Docker image by running:\ndocker pull gitlab/gitlab-runner\nYou can check whether it was successful by running docker images - you should see the gitlab/gitlab-runner image listed in the output.\n\n\nStep 5. Create a unit test function stored as a file in the repository\n\n\nStep 6. Set up the CI by configuration of the .gitlab-ci.yml file\nThis file in the root of your repository defines what CI/CD tests to run upon each new commit. It does this by prescribing what container to run, what scripts to run inside the container, and what things to store as artefacts.\nIn the first line of the file, you can write image: &lt;image_name&gt;:&lt;tag&gt; to indicate you want to run the runner in a Docker container container. &lt;image_name&gt; should be replaced by the name of the image you want to use to start a container and &lt;tag&gt; should be replaced by the tag of the image you want to use(image names can be found on DockerHub). Tag will be set to latest by default.\nImportant: The file must be named exactly .gitlab-ci.yml so it will be recognizable by GitLab runner. Below is an example .gitlab-ci.yml file.\n# This is a sample build configuration for Python.\n# Check our guides at https://confluence.atlassian.com/x/x4UWN for more examples.\n# Only use spaces to indent your .yml configuration.\n# -----\ntest:\n  # You can specify a custom docker image from Docker Hub as your build environment.\n  image: python:3.12.3\n  cache:\n    paths:\n      - .cache/pip\n      - venv/\n  script: # Modify the commands below to build your repository.\n    - pip install -r requirements.txt\n    - nosetests --with-coverage  --cover-html\n  artifacts:\n    paths:\n      - cover/\nTags can be added as a final section in your .gitlab-ci.yml file (they are optional, we didn‚Äôt enter any in this example). You then need to enter these tags exactly when registering the runner.\n\n\nStep 7. Setup the GitLab runner\n\nFollow the instructions here till step 7 to create a GitLab runner for your repository\nChoose ‚ÄòLinux‚Äô under operating systems\nCopy the authentication token generated and keep it handy. It will be required in Step 9.\n\n\n\nStep 8. Deploy GitLab runner in a Docker container\ndocker run -d --name gitlab-runner --restart always \\\n-v /srv/gitlab-runner/config:/etc/gitlab-runner \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\ngitlab/gitlab-runner:latest\non Mac OS, use /Users/Shared/ instead of /srv/\nCheck that gitlab-runner container is running using docker ps -a\n\n\nStep 9. Register the runner using authentication token\nRun the following command to register your runner and configure it to deploy in a Docker container on your server.\ndocker run --rm -it -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register\non Mac OS, use /Users/Shared/ instead of /srv/\nIn response to this command you will be prompted to answer the following questions\n- GitLab URL: https://gitlab.tudelft.nl\n- gitlab-ci token: Paste the authentication token generated in Step 7.\n- Enter name of the runner: example-runner\n- Type of executor: docker\n- Default Docker image: Specify the same image as the one specified in the 'image' field of the .gitlab-ci.yml file.\nSee an example below.\ndocker run --rm -it -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register\nEnter the GitLab instance URL (for example, https://gitlab.com/):\nhttps://gitlab.tudelft.nl\nEnter the registration token:\nxxxxxxxxxxxxxxx\nVerifying runner... is valid                        runner=xxxxxxx\nEnter a name for the runner. This is stored only in the local config.toml file:\n[xxxxxxx]: example-runner\nEnter an executor: instance, kubernetes, docker-windows, docker-autoscaler, parallels, shell, ssh, virtualbox, docker+machine, custom, docker:\ndocker\nEnter the default Docker image (for example, ruby:2.7):\njulia:1.6\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\n\nConfiguration (with the authentication token) was saved in \"/etc/gitlab-runner/config.toml\"\n\n\nStep 10. Check that the CI/CD process is activated and your pipeline runs successfully\n\nIn your repository, navigate to Settings &gt; CI/CD &gt; Click on Expand under Runners: You should see that the runner is active as indicated by a green dot. This means that the CI pipeline is ready to run, but it needs to be triggered.\nIn order to trigger the CI pipeline, you should make a new commit to the GitLab repository.\nAfter you have made a new commit to the repository, navigate to Your Project -&gt; Build -&gt; Pipelines to check the status of CI/CD pipelines connected to your repository. If you find a green message that says ‚Äúpassed‚Äù with a check mark then congratulations, your pipeline works! If you see a red message that says ‚Äúfailed‚Äù, check to see the error message associated with it - sometimes you need to reconfigure your .gitlab-ci.yml file to make sure it uses the correct formatting and defines the tests appropriately.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Continuous Integration with GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_intro.html",
    "href": "docs/infrastructure/gitlab/gitlab_intro.html",
    "title": "TU Delft GitLab",
    "section": "",
    "text": "Imagine the following: you are working with a group on a research software code base. At this point your codebase might be quite large, dozens of scripts, and it has a good amount of dependencies. Furthermore, other researchers depend on your code to work properly for their own research. When your code becomes more relevant to yourself and your community, you will feel the urge to have more control on the quality of contributions. You would like to be able to easily upgrade and maintain the code, but also automate the process of packaging and publishing your code, instead of doing it manually everytime.\nThe TU Delft offers a local instance of GitLab at gitlab.tudelft.nl. GitLab is an online Git repository management tool with a wiki, issue tracker, Continuous Integration and Continuous Deployment built-in. The service is intended for researchers. Similar services are, for example, GitHub.com or GitLab.com. In contrast to these services, GitLab TU Delft is hosted by the TU Delft itself, on campus. For more information, please consult the documentation.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/gitlab_intro.html#github-or-tu-delft-gitlab",
    "href": "docs/infrastructure/gitlab/gitlab_intro.html#github-or-tu-delft-gitlab",
    "title": "TU Delft GitLab",
    "section": "GitHub or TU Delft GitLab?",
    "text": "GitHub or TU Delft GitLab?\nThe current instance of the TU Delft GitLab has a few limitations:\n\nHosting a website through pages is currently deactivated\nContinuous integration is not available by default. See our guide on setting this up.\nContainer registry has been disabled\n‚Ä¶\n\nThe free edition of GitLab has the following limitations:\n\nWiki is not available in a private repository\n‚Ä¶",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/runner_matlab.html",
    "href": "docs/infrastructure/gitlab/runner_matlab.html",
    "title": "Setting up a GitLab runner for MATLAB",
    "section": "",
    "text": "With the continuous method of software development, you continuously build, test, and deploy iterative code changes. This iterative process helps reduce the chance that you develop new code based on buggy or failed previous versions. With this method, you strive to have less human intervention or even no intervention at all, from the development of new code until its deployment.\n\n\nWith this guide, you will create a Continuous Integration Pipeline on a repository within the TU Delft Gitlab to use a Matlab environment.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Setting up a Gitlab runner for MATLAB"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/runner_matlab.html#background",
    "href": "docs/infrastructure/gitlab/runner_matlab.html#background",
    "title": "Setting up a GitLab runner for MATLAB",
    "section": "",
    "text": "With the continuous method of software development, you continuously build, test, and deploy iterative code changes. This iterative process helps reduce the chance that you develop new code based on buggy or failed previous versions. With this method, you strive to have less human intervention or even no intervention at all, from the development of new code until its deployment.\n\n\nWith this guide, you will create a Continuous Integration Pipeline on a repository within the TU Delft Gitlab to use a Matlab environment.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Setting up a Gitlab runner for MATLAB"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/runner_matlab.html#prerequisites",
    "href": "docs/infrastructure/gitlab/runner_matlab.html#prerequisites",
    "title": "Setting up a GitLab runner for MATLAB",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nTU Delft netID\nMATLAB account\nBasic knowledge of Linux (for setting up a server)\nBasic knowledge of Docker (for creating a custom MATLAB image)\n\n\n\n\n\n\n\nTip\n\n\n\nTo learn more about Docker containers, please look at the Reproducible Computational Environments Using Docker lesson from the Software Carpentries.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Setting up a Gitlab runner for MATLAB"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/runner_matlab.html#glossary-of-terms",
    "href": "docs/infrastructure/gitlab/runner_matlab.html#glossary-of-terms",
    "title": "Setting up a GitLab runner for MATLAB",
    "section": "Glossary of terms",
    "text": "Glossary of terms\nCI/CD pipeline\nA CI/CD pipeline automates your software delivery process. The pipeline builds code, runs tests (Continuous Intergation), and safely deploys a new version of the application (Continuous Delivery). See this introduction.\nDocker\nWe use a Docker container to run the Gitlab runner and initialise the CI/CD pipeline.\nGitlab runner (from GitLab documentation)\nRunners are the agents that run the CI/CD jobs that come from GitLab. When you register a runner, you are setting up communication between your GitLab instance and the machine where GitLab Runner is installed. Runners usually process jobs on the same machine where you installed GitLab Runner.\nGitlab jobs\nPipeline configuration begins with jobs. Jobs are the most fundamental element of a .gitlab-ci.yml file. Each job is executed by a Gitlab runner. See Gitlab documentation for more info.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Setting up a Gitlab runner for MATLAB"
    ]
  },
  {
    "objectID": "docs/infrastructure/gitlab/runner_matlab.html#steps",
    "href": "docs/infrastructure/gitlab/runner_matlab.html#steps",
    "title": "Setting up a GitLab runner for MATLAB",
    "section": "Steps",
    "text": "Steps\n\nRequest a TU Delft Virtual Private Server\nSet up a Gitlab runner\nCreate a Docker image with a custom Matlab installation\nRegister a gitlab runner for the Matlab container\nObtain a Matlab license file\nConfigure the CI/CD pipeline\nAdd a job to test the pipeline\nOptional: Updating the Matlab version\n\n\nStep 1. Request a TU Delft VPS\nIf you want to work with the TU Delft Gitlab instance and you want to implement CI/CD pipelines, then you need to install a Gitlab runner on your own. Runners are the agents that run the CI/CD jobs that come from GitLab. Currently, the TU Delft instance does not provide this feature out-of-the-box. Therefore, we need a separate (virtual) server to run the Gitlab runners and execute the jobs in the CI/CD pipeline.\nThe TU Delft offers Virtual Private Servers (VPS) for researchers through the TopDesk selfservice portal. If you don‚Äôt have a VPS already, please follow this guide to request a Virtual Private Server)\nVPS requirements\n\n50Gb disk space (the Matlab installation in this guide requires ~10 Gb, but this depends on the size of the installed addons)\n\n\n\nStep 2. Setting up Gitlab runners\nTo set up a gitlab runner on the VPS, please follow this guide for setting up GitLab runners.\nTLDR\n\nInstall docker with\nsudo apt install docker.io\nVerify installation with\nsudo docker --version\nOptional: Move default storage location to larger drive\nIf the file space in the Docker Root directory is not adequate, we must relocate the Docker Root. Please consult this guide for instructions.\nDeploy the gitlab-runner with\ndocker run -d --name gitlab-runner --restart always \\\n-v /srv/gitlab-runner/config:/etc/gitlab-runner \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\ngitlab/gitlab-runner:latest\nVerify deployment with\nsudo docker ps -a\n\n\n\nStep 3. Create a Docker image containing a custom Matlab installation\nIn order for a Gitlab runner to execute MATLAB code, it needs to be able to access a container with MATLAB installed. The aim of this step is to create a Docker image with MATLAB installation that can be used by a Gitlab runner. By building our own Docker image, we can specify the MATLAB version and customize the installed toolboxes.\n\n\n\n\n\n\nNote\n\n\n\nWe have looked into using the Docker images developed by Mathworks. When running these images, you are prompted to supply your MATLAB‚Äôs account username and password to activate the instance. Although it is possible to create a new image from such an activated container and use it on the VPS, we have so far not been able to get this solution working with Gitlab runners. We thus rely on downloading a license file (step 6) and storing it as a Variable on Gitlab (step 7).\n\n\nThis Dockerfile is based on MATLAB‚Äôs Dockerfile template. We will make the following modifications to this template:\n\nset bash as the default run command (Gitlab runners need to access a shell)\nadd additional MATLAB products with the flag --products. In this example, we have added the Parallel Computing Toolbox and the Mapping Toolbox.\n\nIn your user folder on the VPS (/home/username), create a file called Dockerfile\nsudo nano Dockerfile\nand copy the content below in the Dockerfile. Make sure to update the MATLAB release and installed addons to your requirements (see in bold).\n\n\n\n\n\n\n# Copyright 2019 - 2021 The MathWorks, Inc.\n\n# To specify which MATLAB release to install in the container, edit the value of the MATLAB_RELEASE argument.\n# Use lower case to specify the release, for example: ARG MATLAB_RELEASE=r2020a\nARG MATLAB_RELEASE=r2021b\n\n# When you start the build stage, this Dockerfile by default uses the Ubuntu-based matlab-deps image.\n# To check the available matlab-deps images, see: https://hub.docker.com/r/mathworks/matlab-deps\nFROM mathworks/matlab-deps:${MATLAB_RELEASE}\n\n# Declare the global argument to use at the current build stage\nARG MATLAB_RELEASE\n\n# Install mpm dependencies\nRUN export DEBIAN_FRONTEND=noninteractive && apt-get update && \\\n    apt-get install --no-install-recommends --yes \\\n    wget \\\n    unzip \\\n    ca-certificates && \\\n    apt-get clean && apt-get autoremove\n\n# Run mpm to install MATLAB in the target location and delete the mpm installation afterwards\nRUN wget -q https://www.mathworks.com/mpm/glnxa64/mpm && \\ \n    chmod +x mpm && \\\n    ./mpm install \\\n    --release=${MATLAB_RELEASE} \\\n    --destination=/opt/matlab \\\n    --products MATLAB Parallel_Computing_Toolbox Mapping_Toolbox && \\\n    rm -f mpm /tmp/mathworks_root.log && \\\n    ln -s /opt/matlab/bin/matlab /usr/local/bin/matlab\n\n# Add \"matlab\" user and grant sudo permission.\nRUN adduser --shell /bin/bash --disabled-password --gecos \"\" matlab && \\\n    echo \"matlab ALL=(ALL) NOPASSWD: ALL\" &gt; /etc/sudoers.d/matlab && \\\n    chmod 0440 /etc/sudoers.d/matlab\n\n# Set user and work directory\nUSER matlab\nWORKDIR /home/matlab\nCMD [\"bash\"]\n\n\n\n\nTo build a Docker image with the name matlab-gitlab and the version reference r2021b, run the following command in the folder containing the Dockerfile:\nsudo docker build . -t matlab-gitlab:r2021b\nYou can verify the presence of the image with\nsudo docker images\nThis image is now available locally on the VPS.\n\n\n\n\n\n\nTip\n\n\n\nYou can also upload your Docker image to Dockerhub and have it available from there. This removes the need to build the image on the VPS as it can be pulled directly from DockerHub.\n\n\n\n\nStep 4. Register the MATLAB runner\nAfter deploying the gitlab-runner in step 2, we need to register a new runner for our matlab-gitlab image. Run the following command to register your runner and configure it to deploy in a Docker container on your server.\ndocker run --rm -it -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register\nIn response to this command you will be prompted to answer a series of questions. You can find the required gitlab-ci token in your Gitlab repository under Settings -&gt; CI/CD -&gt; Runners:\nsudo docker run --rm -it -v /srv/gitlab-runner/config:/etc/gitlab-runner gitlab/gitlab-runner register \\\n  --non-interactive \\\n  --url \"https://gitlab.tudelft.nl/\" \\\n  --registration-token \"REPOSITORY_TOKEN\" \\\n  --executor \"docker\" \\\n  --docker-image matlab-gitlab:r2021b \\\n  --description \"matlab-runner\" \\\n  --tag-list \"matlab\" \\\n  --docker-privileged=true \\\n  --docker-cap-add \"NET_ADMIN\" \\\n  --docker-pull-policy \"if-not-present\" \\\nFor the changes to take effect, restart the gitlab-runner with\nsudo docker restart gitlab-runner\nThe runner configurations are stored in /srv/gitlab-runner/config/config.toml. If you would like to view or or modify the MATLAB runner, run\nsudo nano /srv/gitlab-runner/config/config.toml\nAfter registering the runner, the configuration file should contain:\n\n\n\n\n\n\nNote\n\n\n\n\n\nconcurrent = 4\ncheck_interval = 0\n\n[session_server]\n  session_timeout = 1800\n\n[[runners]]\n  name = \"matlab-gitlab\"\n  url = \"https://gitlab.tudelft.nl\"\n  token = \"&lt;token&gt;\"\n  executor = \"docker\"\n  [runners.custom_build_dir]\n  [runners.cache]\n    [runners.cache.s3]\n    [runners.cache.gcs]\n    [runners.cache.azure]\n  [runners.docker]\n    tls_verify = false\n    image = \"matlab-gitlab:r2021b\"\n    privileged = true\n    disable_entrypoint_overwrite = false\n    cap_add = [\"NET_ADMIN\"]\n    oom_kill_disable = false\n    disable_cache = false\n    volumes = [\"/cache\"]\n    pull_policy = \"if-not-present\"\n    shm_size = 0\n\n\n\n\n\nStep 5. Obtain a MATLAB license file\nEvery TU Delft employee has access to an Individual MATLAB license. Normally, you would activate MATLAB only once after installation through an online activation step. However, this does not work for a Docker container as it is relaunched for each CI trigger.\nThe following steps for activating MATLAB on an offline machine are adapted from the MATLAB Forum:\n\nObtain your Host ID\nObtain your computer login name or username\nActivate the license through the License Center to obtain license file\n\n1. Obtain your Host ID\nThe MATLAB license can only be activated for a specifc computer. In the Docker container, we will set the hostID of the container to 0242ac11ffff.\n\n\n\n\n\n\nNote\n\n\n\nDocker automatically assigns an IP address to each running container, starting from 172.17.0.2 until 172.17.0.255. These IP addresses determine the container‚Äôs MAC address (see here for more details), which in turn needs to match with our license. To prevent the MAC address of the MATLAB container from switching and thereby invalidating the license, we will set it to 02:42:ac:11:ff:ff in the .gitlab-ci.yml file.\n\n\n2. Obtain your computer login name or username\nThe MATLAB license is created for a specific user. In the Docker container, we will set the username to matlab.\n3. Activate the license through the License Center to obtain license file\n\nGo to the License Center: https://www.mathworks.com/mwaccount\nUnder My Software, click the license number you want to activate. If you do not see your license number, in the bottom right hand corner, click View Additional Licenses or Trials.\nClick the Install and Activate tab\nClick Activate to Retrieve License File and/or Activate a Computer\nEnter the following information:\n\nthe release you are activating = r2021b (same version as in the Dockerfile)\nthe operating system = Linux\nthe host ID = 0242ac11ffff\nyour user or login name = matlab\nthe Activation Label = matlab-gitlab\n\n\nDownload the license.lic file\n\n\n\nStep 6. Configure the CI/CD pipeline on Gitlab\nBefore we can run a CI job, we need to configure a few settings in our Gitlab repository\n1. Add tag to MATLAB runner\nUnder Settings -&gt; CI/CD -&gt; Runners we can find the available specific runners. Press the edit button on the matlab-gitlab runner and add the tag matlab-gitlab. With this, we can call more easily call this specific runner within our CI pipeline.\n2. Add license as Variable\nUnder Settings -&gt; CI/CD -&gt; Variables add a new variable called MATLAB_LICENSE, past the content of the downloaded license.lic file and set type to file. Having the license available as a Gitlab variable allows us to update it without having to change the MATLAB image.\n\n\n\n\n\n\nNote\n\n\n\nAlternatively, we could have added the license file directly to the Docker image. With the license file in the same folder as the Dockerfile and adding the following command to the Dockerfile, we can build a Docker image with an activated MATLAB:\nCOPY license.lic /opt/matlab/licenses/\nHere, we opted to have it accessible through the Gitlab settings together with the accompanying hostid.\n\n\n\n\n\n\nWarning\n\n\n\nNever share any Docker images that contain license files or other confidential information.\n\n\n\n\n\n\nStep 7. Add a job to test the pipeline\nTo test the pipeline, add the following content to .gitlab-ci.yml via CI/CD -&gt; Editor in your repository.\nvariables:\n  MAC_ADDRESS: 02:42:ac:11:ff:ff\n\ncheck_matlab:\n  tags: \n    - matlab-gitlab\n  before_script:\n    # Change the mac-address to match the MATLAB license\n    - sudo ifconfig eth0 hw ether \"$MAC_ADDRESS\"\n\n    # Add the Matlab license to the Matlab installation in the container\n    - sudo mkdir /opt/matlab/licenses\n    - sudo mv ${MATLAB_LICENSE} /opt/matlab/licenses/license.lic   \n  script:    \n    # Run a MATLAB function/script through the -batch argument\n    - matlab -batch \"disp('hello world!')\"\nAfter commiting, the pipeline should run and execute the job check_matlab. You can check the status of the pipeline via CI/CD -&gt; Pipelines.\nIf all went well, you have successfully setup a Gitlab runner to run MATLAB code. Congrats!\n\n\nStep 8. Optional: Updating the MATLAB version\nIf you need to update the MATLAB version of the Docker container, you will need to go throught the following steps:\n\nUpdate the MATLAB version in the Dockerfile\nBuild the docker image with sudo docker build . -t matlab-gitlab:&lt;version&gt;\nDownload a new license.lic file (see step 5 of this guide)\nUpdate the CI Variable MATLAB_LICENSE with the new license content\nUpdate the image names (not the tags) in .gitlab-ci.yml to use the new image.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to test your code with multiple MATLAB versions to ensure backward compatibility, please look at this example to use multiple docker images.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "TU Delft GitLab",
      "Setting up a Gitlab runner for MATLAB"
    ]
  },
  {
    "objectID": "docs/infrastructure/intro_servers.html",
    "href": "docs/infrastructure/intro_servers.html",
    "title": "Servers",
    "section": "",
    "text": "TU Delft offers its employees the use of physical or virtual servers. These servers are known as Faculty Managed Servers and can be requested to conduct work related to a specific project within a Faculty.\n\n\n\n\n\n\nNote\n\n\n\nIt is not possible to use the servers to set up services that are already provided by the ICT department.\n\n\nVirtual vs Physical Servers\nThere is a choice between virtual and physical servers. Virtual servers are provided free of charge and can be requested via TOPdesk. Physical servers can be requested by contacting the Faculty‚Äôs IT Manager and any associated costs are paid by the purchasing department.\nIn most cases, a virtual server is the most suitable option. However, a physical server may be necessary when it is intended for use as a GPU or computing cluster.\nServer Configuration\nWhen requesting a virtual server, users can choose from a range of predefined hardware and operating system configurations. The following operating systems are available: Windows Server 2019, Windows Server 2022, Red Hat Enterprise Linux (latest supported version), and Ubuntu (latest LTS version).\nIf additional capacity is needed, it can be requested via the ‚ÄòICT malfunction‚Äô or ‚Äòrequest ICT service‚Äô forms in TOPdesk. This includes options such as increasing the number of processors, cores per processor, RAM, or disk storage.\nSome considerations:\n\nICT provides the server, operating system, and network access.\nUsers are granted administrator privileges, allowing them to install any required software, provided it complies with the conditions specified in the request form.\nAccess can be granted to both TU Delft members and external users.\nICT provides daily backups, restoration services, and virus scanning for Windows servers.\nICT ensures that the server operating system remains up to date (e.g.¬†security patches), except for Linux systems.\n\n\n\n\n\n\n\nTip\n\n\n\nDetailed information on managing the server, including network and firewall settings, is provided at the bottom of the TOPdesk application form.\n\n\nExample Use Cases\n\nPerforming computational or data processing tasks that require a dedicated server environment.\nRunning an instance of a service or application, such as ABAQUS, COMSOL or other specialized tools for a lab or research group.\nHosting a static website, a web application, or an API for a project.\nHosting databases, such as MySQL, PostgreSQL, MongoDB or other database management systems.\nDeploying and managing TU Delft GitLab runners for CI/CD pipelines.\n\nRelevant links\n\nIntranet page for faculty managed servers\nTOPdesk form to request a new virtual server\nIntranet page for Faculty IT Managers.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">‚öôÔ∏è</span> **Computing Infrastructure**",
      "Remote servers"
    ]
  },
  {
    "objectID": "docs/listing.html",
    "href": "docs/listing.html",
    "title": "References",
    "section": "",
    "text": "üöß Under construction! üèóÔ∏è"
  },
  {
    "objectID": "docs/resources/curriculum.html",
    "href": "docs/resources/curriculum.html",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "These materials represent a curated curriculum designed to help you develop and maintain your repository and code base. All of the resources listed below are free to access and use, and supplementary material like video lessons has been added where possible and relevant.\n\n\n\nWhat is Bash? - of all the shells available, Bash is one of the most popular, the most powerful, and the most friendly\nBash Essentials ‚Äì Bash commands commonly used to navigate file directories in your Terminal/GitBash\nThe Unix Shell lesson from Software Carpentries - use of the shell is fundamental to using a wide range of other powerful tools and computing resources. These lessons will start you on a path towards using these resources effectively\nInstallation Instructions - particularly important for Windows users, as Bash comes pre-installed on Mac. Windows users will need to install GitBash following the instructions at this link\nUsing the Terminal in Mac - The Terminal app allows you to control your Mac using a command prompt\n\n\n\n\n\nWhat is Git?- 2-minute video overview of the technology and how it works\nInstall Git from GitHub Guides - Check if Git is already installed on your machine; if not, follow these instructions to get started. Notes: If you‚Äôve already installed GitBash on Windows OS, you will have Git already. Installing GitHub Desktop will also install the latest version of Git if you don‚Äôt already have it.\nInstalling Git from Software Carpentries - Alternative installation instructions from Software Carpentries, including videos and details per OS.\nIntro to version control with Git from Code Refinery ‚Äì self-paced introductory lesson to version control using Git\nGit Intro video lesson from Code Refinery - Day 1 - Recorded lesson from a May 2021 Code Refinery workshop on material in Intro to version control with Git, part 1/2\nGit Intro video lesson from Code Refinery - Day 2 - Recorded lesson from a May 2021 Code Refinery workshop on material in Intro to version control with Git, part 2/2\nBranching and merging ‚Äì lesson from Code Refinery on concept of branching in Git (featuring octopus diagram)\nWhat is .gitignore? ‚Äì introduction to how and why to use the .gitignore file to not track some files in a project folder (e.g., because of their size or sensitivity)\nGit command cheat sheet ‚Äì commonly used Git commands in one page that can also be downloaded\n\n\n\n\n\nUnderstanding the GitHub flow ‚Äì guide from GitHub on how and why to work with branches\nCollaborative distributed version control - We have learned how to make a git repository for a single person. What about sharing?\nSSH connection to GitHub ‚Äì instructions to set up SSH connection to GitHub so that you do not need to input your login credentials with every push/pull\nGitlab and SSH keys - instructions to add an SSH key to your (TU Delft) GitLab account for the same reason as above\nGitHub without the Command Line from Code Refinery - practice collaborating and sharing using either the GitHub website or GitHub desktop application\nGitHub Guides: Mastering Markdown - Markdown is a lightweight and easy-to-use syntax for styling all forms of writing on the GitHub platform.\n\n\n\n\n\nIntroduction to Jupyter and JupyterLab - lesson material on the user interface of JupyterLab, how Jupyter notebooks work, and what some common and powerful usecases are\n\n\n\n\n\nAnaconda Installation Guide from Software Carpentries - Although one can install a plain-vanilla Python and all required libraries by hand, we recommend installing Anaconda, a Python distribution that comes with the latest version of Python and Jupyter Notebooks by default\nIntro to Anaconda Navigator - Anaconda Navigator is a graphical user interface to the conda package and environment manager. This 10-minute guide to Navigator will have you navigating the powerful conda program in a web-like interface without having to learn command line commands\nIntroduction to Conda for (Data) Scientists - Conda is an open source package and environment management system that easily creates, saves, loads, and switches between environments on your local computer\nManaging Conda environments - documentation on performing a range of common tasks with Conda using the command line\n\n\n\n\n\nScientific Computing with Python - a free video course series that teaches the basics of using Python 3\nApplied Data Science with Python Specialization - Coursera course in which you can enroll for free\nLearnPython.org - Whether you are an experienced programmer or not, this website is intended for everyone who wishes to learn the Python programming language\nProgramming with Python from Software Carpentries - this introduction to Python is built around a common scientific task: data analysis\nPlotting and Programming with Python from Software Carpentries - an introduction to programming in Python for people with little or no previous programming experience using plotting as its motivating example\nData Analysis and Visualization with Python for Social Scientists - basic information about Python syntax, the Jupyter notebook interface, how to import CSV files, using the pandas package to work with data frames, how to calculate summary information from a data frame, and a brief introduction to plotting. The last lesson demonstrates how to work with databases directly from Python\nCan You Speak Python? - test your knowledge of some important features of the Python programming language and the NumPy and Pandas libraries\n\n\n\n\n\nGetting started with Pandas - documentation and quick start guide for Pandas, an essential Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data\nPandas Tutorial - 14-part tutorial series featuring live code examples and tests of your knowledge\nPandas Data Wrangling Cheat Sheet - a cheat sheet of some of the most used syntax that you probably don‚Äôt want to miss\nPandas Cheat Sheet - Visual - visual, printable 2-page reference guide on commonly performed operations using Pandas\nUltimate Pandas Guide ‚Äî Inspecting Data Like a Pro - Whether you‚Äôre working on a simple analysis or a complex machine learning model, there‚Äôs a lot of value in being able to answer quick, exploratory questions about the nature of your data. This is a walk through of several DataFrame attributes and methods that make data inspection painless and productive\n10 Efficient Ways for Inspecting a Pandas DataFrame Object - A guide to using pandas effectively and efficiently\n\n\n\n\n\nGetting Started with Plotly - The plotly Python library is an interactive, open-source plotting library that supports over 40 unique chart types covering a wide range of statistical, financial, geographic, scientific, and 3-dimensional use-cases\nPlotly Python Open Source Graphing Library - Examples of how to make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts\nHeatmaps with Plotly - How to make Heatmaps in Python with Plotly\n\n\n\n\n\nIpywidgets documentation - ipywidgets, also known as jupyter-widgets or simply widgets, are interactive HTML widgets for Jupyter notebooks and the IPython kernel.\nIntroduction to ipywidgets - in this tutorial video, learn about ipywidgets, a Python library for building interactive HTML widgets for your Jupyter browser.\nIpywidgets Interact Function | ipywidgets Examples of Slider, Dropdown, Checkbox, Text Box - Video demo on how to make an ipywidgets slider, ipywidgets dropdown, ipywidgets checkbox, or an ipywidgets text box using Python code.\n\n\n\n\n\nInstall R guide from Software Carpentries - R is a programming language that is especially powerful for data exploration, visualization, and statistical analysis. To interact with R, we use RStudio, which must also be installed separately from here\nProgramming with R from Software Carpentries - this introduction to R is built around a common scientific task: data analysis\nR for Reproducible Data Analysis from Software Carpentries - write modular code and best practices for using R for data analysis\nR for Social Scientists - basic information about R syntax, the RStudio interface, how to import CSV files, the structure of data frames, how to deal with factors, how to add/remove rows and columns, how to calculate summary statistics from a data frame, and a brief introduction to plotting\n\n\n\n\n\nUsing git with MATLAB - Introduction into using MATLAB and version control with git\nProgramming with MATLAB - Lesson from the Software Carpentries on the basics of programming with MATLAB\n\n\n\n\n\nWriting tests - lesson from CodeRefinery on automated testing\nVideo testing lesson - recording from software testing workshop by Code Refinery\nModular coding - modular code development from Code Refinery\n\n\n\n\n\nInstalling Docker - installation instructions for Windows, macOS, and Linux\nInstall WSL2 update - manual WSL2 update for Windows\nDockerfile reference - information on how to write a Dockerfile\n\n\n\n\n\nSetting up VSCode for Linux - guide to getting started using VSCode with Windows Subsystem for Linux\n\n\n\n\n\nGitHub Actions introduction course - an introductory course from GitHub on how to use GitHub Actions\n\n\n\n\n\nReproducible Research material from Code Refinery - demonstrates how version control, workflows, containers, and package managers can be used to record reproducible environments and computational steps\nReproducible Research video lesson from Code Refinery - Recorded video lesson from Code Refinery workshop in May 2021 on Reproducible Research material\nData + Code + Software = PDF - Slides to an overview on how to integrate data and software into a PDF."
  },
  {
    "objectID": "docs/resources/curriculum.html#bash",
    "href": "docs/resources/curriculum.html#bash",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "What is Bash? - of all the shells available, Bash is one of the most popular, the most powerful, and the most friendly\nBash Essentials ‚Äì Bash commands commonly used to navigate file directories in your Terminal/GitBash\nThe Unix Shell lesson from Software Carpentries - use of the shell is fundamental to using a wide range of other powerful tools and computing resources. These lessons will start you on a path towards using these resources effectively\nInstallation Instructions - particularly important for Windows users, as Bash comes pre-installed on Mac. Windows users will need to install GitBash following the instructions at this link\nUsing the Terminal in Mac - The Terminal app allows you to control your Mac using a command prompt"
  },
  {
    "objectID": "docs/resources/curriculum.html#git",
    "href": "docs/resources/curriculum.html#git",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "What is Git?- 2-minute video overview of the technology and how it works\nInstall Git from GitHub Guides - Check if Git is already installed on your machine; if not, follow these instructions to get started. Notes: If you‚Äôve already installed GitBash on Windows OS, you will have Git already. Installing GitHub Desktop will also install the latest version of Git if you don‚Äôt already have it.\nInstalling Git from Software Carpentries - Alternative installation instructions from Software Carpentries, including videos and details per OS.\nIntro to version control with Git from Code Refinery ‚Äì self-paced introductory lesson to version control using Git\nGit Intro video lesson from Code Refinery - Day 1 - Recorded lesson from a May 2021 Code Refinery workshop on material in Intro to version control with Git, part 1/2\nGit Intro video lesson from Code Refinery - Day 2 - Recorded lesson from a May 2021 Code Refinery workshop on material in Intro to version control with Git, part 2/2\nBranching and merging ‚Äì lesson from Code Refinery on concept of branching in Git (featuring octopus diagram)\nWhat is .gitignore? ‚Äì introduction to how and why to use the .gitignore file to not track some files in a project folder (e.g., because of their size or sensitivity)\nGit command cheat sheet ‚Äì commonly used Git commands in one page that can also be downloaded"
  },
  {
    "objectID": "docs/resources/curriculum.html#githubgitlab-remote-repositories",
    "href": "docs/resources/curriculum.html#githubgitlab-remote-repositories",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Understanding the GitHub flow ‚Äì guide from GitHub on how and why to work with branches\nCollaborative distributed version control - We have learned how to make a git repository for a single person. What about sharing?\nSSH connection to GitHub ‚Äì instructions to set up SSH connection to GitHub so that you do not need to input your login credentials with every push/pull\nGitlab and SSH keys - instructions to add an SSH key to your (TU Delft) GitLab account for the same reason as above\nGitHub without the Command Line from Code Refinery - practice collaborating and sharing using either the GitHub website or GitHub desktop application\nGitHub Guides: Mastering Markdown - Markdown is a lightweight and easy-to-use syntax for styling all forms of writing on the GitHub platform."
  },
  {
    "objectID": "docs/resources/curriculum.html#jupyter-notebooks-and-jupyterlab",
    "href": "docs/resources/curriculum.html#jupyter-notebooks-and-jupyterlab",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Introduction to Jupyter and JupyterLab - lesson material on the user interface of JupyterLab, how Jupyter notebooks work, and what some common and powerful usecases are"
  },
  {
    "objectID": "docs/resources/curriculum.html#anaconda-navigator-and-managing-conda-environments",
    "href": "docs/resources/curriculum.html#anaconda-navigator-and-managing-conda-environments",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Anaconda Installation Guide from Software Carpentries - Although one can install a plain-vanilla Python and all required libraries by hand, we recommend installing Anaconda, a Python distribution that comes with the latest version of Python and Jupyter Notebooks by default\nIntro to Anaconda Navigator - Anaconda Navigator is a graphical user interface to the conda package and environment manager. This 10-minute guide to Navigator will have you navigating the powerful conda program in a web-like interface without having to learn command line commands\nIntroduction to Conda for (Data) Scientists - Conda is an open source package and environment management system that easily creates, saves, loads, and switches between environments on your local computer\nManaging Conda environments - documentation on performing a range of common tasks with Conda using the command line"
  },
  {
    "objectID": "docs/resources/curriculum.html#python",
    "href": "docs/resources/curriculum.html#python",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Scientific Computing with Python - a free video course series that teaches the basics of using Python 3\nApplied Data Science with Python Specialization - Coursera course in which you can enroll for free\nLearnPython.org - Whether you are an experienced programmer or not, this website is intended for everyone who wishes to learn the Python programming language\nProgramming with Python from Software Carpentries - this introduction to Python is built around a common scientific task: data analysis\nPlotting and Programming with Python from Software Carpentries - an introduction to programming in Python for people with little or no previous programming experience using plotting as its motivating example\nData Analysis and Visualization with Python for Social Scientists - basic information about Python syntax, the Jupyter notebook interface, how to import CSV files, using the pandas package to work with data frames, how to calculate summary information from a data frame, and a brief introduction to plotting. The last lesson demonstrates how to work with databases directly from Python\nCan You Speak Python? - test your knowledge of some important features of the Python programming language and the NumPy and Pandas libraries"
  },
  {
    "objectID": "docs/resources/curriculum.html#pandas",
    "href": "docs/resources/curriculum.html#pandas",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Getting started with Pandas - documentation and quick start guide for Pandas, an essential Python library used for working with data sets. It has functions for analyzing, cleaning, exploring, and manipulating data\nPandas Tutorial - 14-part tutorial series featuring live code examples and tests of your knowledge\nPandas Data Wrangling Cheat Sheet - a cheat sheet of some of the most used syntax that you probably don‚Äôt want to miss\nPandas Cheat Sheet - Visual - visual, printable 2-page reference guide on commonly performed operations using Pandas\nUltimate Pandas Guide ‚Äî Inspecting Data Like a Pro - Whether you‚Äôre working on a simple analysis or a complex machine learning model, there‚Äôs a lot of value in being able to answer quick, exploratory questions about the nature of your data. This is a walk through of several DataFrame attributes and methods that make data inspection painless and productive\n10 Efficient Ways for Inspecting a Pandas DataFrame Object - A guide to using pandas effectively and efficiently"
  },
  {
    "objectID": "docs/resources/curriculum.html#plotly",
    "href": "docs/resources/curriculum.html#plotly",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Getting Started with Plotly - The plotly Python library is an interactive, open-source plotting library that supports over 40 unique chart types covering a wide range of statistical, financial, geographic, scientific, and 3-dimensional use-cases\nPlotly Python Open Source Graphing Library - Examples of how to make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts\nHeatmaps with Plotly - How to make Heatmaps in Python with Plotly"
  },
  {
    "objectID": "docs/resources/curriculum.html#ipywidgets",
    "href": "docs/resources/curriculum.html#ipywidgets",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Ipywidgets documentation - ipywidgets, also known as jupyter-widgets or simply widgets, are interactive HTML widgets for Jupyter notebooks and the IPython kernel.\nIntroduction to ipywidgets - in this tutorial video, learn about ipywidgets, a Python library for building interactive HTML widgets for your Jupyter browser.\nIpywidgets Interact Function | ipywidgets Examples of Slider, Dropdown, Checkbox, Text Box - Video demo on how to make an ipywidgets slider, ipywidgets dropdown, ipywidgets checkbox, or an ipywidgets text box using Python code."
  },
  {
    "objectID": "docs/resources/curriculum.html#r",
    "href": "docs/resources/curriculum.html#r",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Install R guide from Software Carpentries - R is a programming language that is especially powerful for data exploration, visualization, and statistical analysis. To interact with R, we use RStudio, which must also be installed separately from here\nProgramming with R from Software Carpentries - this introduction to R is built around a common scientific task: data analysis\nR for Reproducible Data Analysis from Software Carpentries - write modular code and best practices for using R for data analysis\nR for Social Scientists - basic information about R syntax, the RStudio interface, how to import CSV files, the structure of data frames, how to deal with factors, how to add/remove rows and columns, how to calculate summary statistics from a data frame, and a brief introduction to plotting"
  },
  {
    "objectID": "docs/resources/curriculum.html#matlab",
    "href": "docs/resources/curriculum.html#matlab",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Using git with MATLAB - Introduction into using MATLAB and version control with git\nProgramming with MATLAB - Lesson from the Software Carpentries on the basics of programming with MATLAB"
  },
  {
    "objectID": "docs/resources/curriculum.html#modular-code-and-testing",
    "href": "docs/resources/curriculum.html#modular-code-and-testing",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Writing tests - lesson from CodeRefinery on automated testing\nVideo testing lesson - recording from software testing workshop by Code Refinery\nModular coding - modular code development from Code Refinery"
  },
  {
    "objectID": "docs/resources/curriculum.html#docker",
    "href": "docs/resources/curriculum.html#docker",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Installing Docker - installation instructions for Windows, macOS, and Linux\nInstall WSL2 update - manual WSL2 update for Windows\nDockerfile reference - information on how to write a Dockerfile"
  },
  {
    "objectID": "docs/resources/curriculum.html#vscode",
    "href": "docs/resources/curriculum.html#vscode",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Setting up VSCode for Linux - guide to getting started using VSCode with Windows Subsystem for Linux"
  },
  {
    "objectID": "docs/resources/curriculum.html#continuous-integration",
    "href": "docs/resources/curriculum.html#continuous-integration",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "GitHub Actions introduction course - an introductory course from GitHub on how to use GitHub Actions"
  },
  {
    "objectID": "docs/resources/curriculum.html#reproducible-research",
    "href": "docs/resources/curriculum.html#reproducible-research",
    "title": "Research Software Curriculum",
    "section": "",
    "text": "Reproducible Research material from Code Refinery - demonstrates how version control, workflows, containers, and package managers can be used to record reproducible environments and computational steps\nReproducible Research video lesson from Code Refinery - Recorded video lesson from Code Refinery workshop in May 2021 on Reproducible Research material\nData + Code + Software = PDF - Slides to an overview on how to integrate data and software into a PDF."
  },
  {
    "objectID": "docs/software/code_quality/code_smells.html",
    "href": "docs/software/code_quality/code_smells.html",
    "title": "Code smells",
    "section": "",
    "text": "CC-BY-4.0 ¬© 2021 Balaban et al.\n\n\nCode smells are software characteristics that suggest there might be an issue with the code‚Äôs design or implementation. While code smells themselves might not always indicate a bug or malfunction, they can make the code harder to understand and extend, which can lead to bugs and other issues down the line. Code smells are usually noticed and addressed during code reviews, when writing tests, adding new features, fixing bugs, and during automated code analysis.\n\n\n\n\n\n\n How to use these cards?\n\n\n\nEach guide provides an overview of a code smell, its symptoms and an example on how to refactor it. We don‚Äôt intend to cover all refactoring techniques, but we aim to provide a starting point for identifying and addressing common code smells.\n\n\n\n\n\nLong Method\nProblem: A function is very long and hard to understand.\n\n Refactor long methods\n\n\n\n\n\nLarge Classes\nProblem: A class contains too many responsibilities or functionalities.\n\n Refactor large classes\n\n\n\n\n\nCode Duplication\nProblem: The same or very similar code appears in multiple places.\n\n Refactor duplicate code\n\n\n\n\n\nHard-Coded Values\nProblem: Literal values (e.g., numeric values or strings) are directly embedded in the code.\n\n Refactor hard-coded values\n\n\n\n\n\nDeep Nesting\nProblem: There are excessive levels of nested for-loops or if-statements.\n\n Refactor nested logic\n\n\n\n\n\nMany Inputs\nProblem: Functions require a long list of parameters.\n\n Refactor argument lists\n\n\n\n\n\nInappropriate Intimacy\nProblem: Two classes or methods depend too much on each other‚Äôs internals.\n\n Refactor coupling\n\n\n\n\n\nSide Effects\nProblem: Changes in one part of the code cause unexpected behavior in another.\n\n Refactor side effects\n\n\n\n\n\nCommented out Code\nProblem: There is a significant amount of outdated or commented-out code.\n\n Refactor commented code\n\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nTen simple rules for quick and dirty scientific programming\nGood enough practices in scientific computing",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/deep_nesting.html",
    "href": "docs/software/code_quality/code_smells/deep_nesting.html",
    "title": "Deep Nesting",
    "section": "",
    "text": "‚ÄúCode is like humor. When you have to explain it, it‚Äôs bad.‚Äù\nCory House\nDeep nesting occurs when there are too many levels of indentation in the code, making it harder to understand, maintain, and debug. It can lead to reduced readability, and increases cognitive load for developers.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Deep nesting"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/deep_nesting.html#symptoms",
    "href": "docs/software/code_quality/code_smells/deep_nesting.html#symptoms",
    "title": "Deep Nesting",
    "section": "Symptoms",
    "text": "Symptoms\n\nExcessive indentation makes it hard to track logic.\nMany nested if statements or for loops.\nHard-to-follow branching logic.\nSlow performance due to inefficient code.\nIncreased likelihood of bugs due to complexity.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Deep nesting"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/deep_nesting.html#example---deeply-nested-conditional-statements",
    "href": "docs/software/code_quality/code_smells/deep_nesting.html#example---deeply-nested-conditional-statements",
    "title": "Deep Nesting",
    "section": "Example - Deeply nested conditional statements",
    "text": "Example - Deeply nested conditional statements\ndef validate_model_convergence(model):\n    if model.convergence &gt; 1:\n        if model.convergence &lt; 0.1:\n            if model.secondary_condition == True\n                return True\n            else:\n                return False\n        else:\n            return False\n    else:\n        return False\n\nSolutions\nRefactoring deep nesting improves readability and maintainability. Techniques to reduce deep nesting include:\n\nUsing early returns to eliminate unnecessary indentation.\nExtracting complex logic into helper functions for better modularity.\nUsing built-in functions like any and all to simplify conditions.\n\n\nSolution 1: Using early returns\ndef validate_model_convergence(model):\n    if model.convergence &lt;= 1:\n        return False\n    if model.convergence &gt;= 0.1:\n        return False\n    if not model.secondary_condition:\n        return False\n    return True\n        \nThia solution uses early returns to reduce the nesting level and make the code more readable. Each condition is checked separately, and if it fails, the function returns immediately, avoiding further nesting and evaluation of unnecessary conditions.\n\n\nSolution 2: Using all for conciseness\nAlternatively, we can use the all function to check multiple conditions in a single line, which can make the code more concise and easier to read.\ndef validate_model_convergence(model):\n    return all([\n        model.convergence &gt; 1,\n        model.convergence &lt; 0.1,\n        model.secondary_condition,\n    ])",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Deep nesting"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/deep_nesting.html#example---deeply-nested-loops",
    "href": "docs/software/code_quality/code_smells/deep_nesting.html#example---deeply-nested-loops",
    "title": "Deep Nesting",
    "section": "Example - Deeply nested loops",
    "text": "Example - Deeply nested loops\nIn this example, we have three nested loops to iterate over three 3D arrays and sum their corresponding elements. This code can be refactored using NumPy to improve performance and readability.\n# Create three random 10x10x10 arrays\nA = np.random.rand(10, 10, 10)\nB = np.random.rand(10, 10, 10)\nC = np.random.rand(10, 10, 10)\n\n# Using nested loops (inefficient)\nresult = np.zeros((10, 10, 10))\nfor i in range(10):\n    for j in range(10):\n        for k in range(10):\n            result[i, j, k] = A[i, j, k] + B[i, j, k] + C[i, j, k]\n\nSolution\nUsing NumPy, we can perform the same operation without nested loops, which is more efficient and easier to read.\n# Create three random 10x10x10 arrays\nA = np.random.rand(10, 10, 10)\nB = np.random.rand(10, 10, 10)\nC = np.random.rand(10, 10, 10)\n\n# Vectorized solution (fast & efficient)\nresult = A + B + C",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Deep nesting"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/deep_nesting.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/deep_nesting.html#key-takeaways",
    "title": "Deep Nesting",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nDeep nesting makes code harder to read and maintain.\nTechniques like early returns, helper functions, and built-in functions can simplify complex logic.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nRealPython - ‚ÄúLook Ma, No For-Loops‚Äù",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Deep nesting"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/hardcoded_values.html",
    "href": "docs/software/code_quality/code_smells/hardcoded_values.html",
    "title": "Hard coding",
    "section": "",
    "text": "Hard-coding variables occurs when constants, configuration values, or logic are directly embedded into the code, making changes difficult. Hard-coding leads to rigid systems that require modifying the source code itself to change behavior, rather than adjusting parameters, settings, or external configurations.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Hard-coded values"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/hardcoded_values.html#symptoms",
    "href": "docs/software/code_quality/code_smells/hardcoded_values.html#symptoms",
    "title": "Hard coding",
    "section": "Symptoms",
    "text": "Symptoms\n\nMagic numbers or string literals appear directly in the code.\nYou find yourself searching the codebase for specific values to tweak behavior for different executions.\nThe same constant value appears multiple times, making updates error-prone.\nThe logic is less readable, since magic numbers don‚Äôt indicate what they represent.\nA small behavior change requires altering the core code, instead of adjusting an input parameters of config file.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Hard-coded values"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/hardcoded_values.html#example---hard-coding-and-magic-numbers",
    "href": "docs/software/code_quality/code_smells/hardcoded_values.html#example---hard-coding-and-magic-numbers",
    "title": "Hard coding",
    "section": "Example - Hard coding and magic numbers",
    "text": "Example - Hard coding and magic numbers\ndef calculate_area(radius):\n    # Hard-coded value of pi\n    return 3.14 * radius * radius # What if you need more precision?\n\ndef check_temperature(temperature):\n    # Hard-coded temperature values for thresholding\n    if temperature &gt; 30: # What does 30 represent\n        print(\"It's too hot!\")\n    elif temperature &lt; 10:\n        print(\"It's too cold!\")\n\nIssues\n\nThe value of pi is hard-coded as 3.14, which can lead to precision issues.\nThe temperature thresholds (30, 10) are buried in the logic, making them difficult to modify.\nThe meaning of 30 and 10 is unclear - are they for a specific region, season, or use case?\n\n\n\nSolution\nUsing named constants and configurable parameters makes the code more readable, maintainable, and flexible.\nimport numpy as np  # Use a library constant\n\nHOT_THRESHOLD = 30  # Defined constant for readability\nCOLD_THRESHOLD = 10  # Defined constant for readability\n\ndef calculate_area(radius):  # Default parameter allows customization\n    return np.pi * radius * radius # Use library constant for pi\n\ndef check_temperature(temperature, hot_threshold=HOT_THRESHOLD, cold_threshold=COLD_THRESHOLD):\n    if temperature &gt; hot_threshold: # Use named constants for readability\n        print(\"It's too hot!\")\n    elif temperature &lt; cold_threshold:\n        print(\"It's too cold!\")",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Hard-coded values"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/hardcoded_values.html#example---rigid-code",
    "href": "docs/software/code_quality/code_smells/hardcoded_values.html#example---rigid-code",
    "title": "Hard coding",
    "section": "Example - Rigid code",
    "text": "Example - Rigid code\nThis simulation hard-codes the time step and duration, making it rigid.\ndef run_simulation():\n    step_size = 0.01  # Fixed timestep\n    total_time = 10  # Fixed total duration\n    for t in range(0, total_time, step_size):\n        update_system(t)\n\nIssues\n\nChange the step size of total duration required modifying the source code.\nThe code is not reusable across different simulations.\n\n\n\nSolution\nIntroduce function parameters or external configuration files for flexibility and reproducibility.\ndef run_simulation(step_size=0.01, total_time=10):\n    for t in range(0, total_time, step_size):\n        update_system(t)\n\n# Calling with different configurations\nrun_simulation(step_size=0.05, total_time=20)  # Adjust without modifying the underlying code\nFor larger projects, moving configuration values to a separate file or class can further improve reproducibility and maintainability. Users would then only need to adjust the (text-based) configuration file without touching the core code.\n# config.yaml\nsimulation:\n  step_size: 0.01\n  total_time: 10\nimport yaml\n\ndef load_config(file_path=\"config.yaml\"):\n    with open(file_path, 'r') as file:\n        return yaml.safe_load(file)\n\nconfig = load_config()\nrun_simulation(config['simulation']['step_size'], config['simulation']['total_time'])",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Hard-coded values"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/hardcoded_values.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/hardcoded_values.html#key-takeaways",
    "title": "Hard coding",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nUse named constants for improved readability.\nExternalize configuration values to allow easy adjustments without modifying the source code.\nConfiguration files or classes can further improve maintainability and reproducibility.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Hard-coded values"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/large_class.html",
    "href": "docs/software/code_quality/code_smells/large_class.html",
    "title": "Large Classes",
    "section": "",
    "text": "A monolithic design is where an entire system is built as a single, tightly coupled unit without clear separation of responsibilities or modularization. This often leads to large, complex classes that handle multiple responsibilities, making the codebase harder to understand, modify, and maintain.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Large classes"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/large_class.html#symptoms",
    "href": "docs/software/code_quality/code_smells/large_class.html#symptoms",
    "title": "Large Classes",
    "section": "Symptoms",
    "text": "Symptoms\n\nLarge classes that try to handle too many responsibilities.\nCode duplication across multiple parts of the system.\nDifficulties in testing because changes in one part of the code affect others.\nLimited reusability of components due to tight coupling.\nSmall modifications require extensive changes across the codebase.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Large classes"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/large_class.html#example---violating-the-single-responsibility-principle",
    "href": "docs/software/code_quality/code_smells/large_class.html#example---violating-the-single-responsibility-principle",
    "title": "Large Classes",
    "section": "Example - Violating the Single Responsibility Principle",
    "text": "Example - Violating the Single Responsibility Principle\nIn this example, we are writing code for a temperature monitoring system. A bad design would be putting everything inside one big class:\nclass SensorSystem:\n    def __init__(self):\n        self.temperature = 0\n\n    def read_temperature(self):\n        # Simulated temperature reading\n        self.temperature = 25  \n        print(f\"Temperature: {self.temperature}¬∞C\")\n\n    def log_temperature(self):\n        # Simulated logging\n        print(f\"Logging temperature: {self.temperature}¬∞C\")\n\n    def send_alert(self):\n        if self.temperature &gt; 30:\n            print(\"ALERT: High temperature detected!\")\n\ndef main():\n    sensor_system = SensorSystem()\n    sensor_system.read_temperature()\n    sensor_system.log_temperature()\n    sensor_system.send_alert()\n\nif __name__ == \"__main__\":\n    main()\n\nSolution\nWe should split this class into smaller, focused classes: - TemperatureSensor ‚Äì Handles sensor readings. - Logger ‚Äì Handles logging. - AlertSystem ‚Äì Handles alerts.\n\nFollow the Single Responsibility Principle (SRP) - Ensure that each class has only one job. If a class is doing too much, split its responsibilities into separate classes.\nUse dependency injection: Reduce class coupling by calling dependencies as arguments (injecting dependencies) rather than hard-coding them. This promotes modularity and testability, as well as making it easier to swap out components.\n\nclass TemperatureSensor:\n    def read_temperature(self):\n        # Simulated sensor reading\n        return 25  \n\nclass Logger:\n    def log(self, message):\n        print(f\"LOG: {message}\")\n\nclass AlertSystem:\n    def send_alert(self, temperature):\n        temperature_threshold = 30\n        if temperature &gt; temperature_threshold:\n            print(\"ALERT: High temperature detected!\")\n\nclass SensorSystem:\n    def __init__(self, sensor, logger, alert_system):\n        self.sensor = sensor\n        self.logger = logger\n        self.alert_system = alert_system\n\n    def monitor_temperature(self):\n        temperature = self.sensor.read_temperature()\n        self.logger.log(f\"Temperature: {temperature}¬∞C\")\n        self.alert_system.send_alert(temperature)\n\n# Dependency Injection\ndef main():\n    sensor = TemperatureSensor()\n    logger = Logger()\n    alert_system = AlertSystem()\n    sensor_system = SensorSystem(sensor, logger, alert_system) # dependencies injected\n\n    sensor_system.monitor_temperature()\n\nif __name__ == \"__main__\":\n    main()\nWhy is this better?\n\nNo unnecessary mixing of concerns.\nEasily swap different logging or alerting mechanisms.\nEach component can be tested in isolation.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Large classes"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/large_class.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/large_class.html#key-takeaways",
    "title": "Large Classes",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nIf your class is doing too many things, split it into smaller, focused classes.\nUse dependency injection to keep components flexible and testable.\nFollowing modular design makes your code easier to understand, modify, and reuse.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nArjanCodes - Dependency Injection Best Practices",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Large classes"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/many_arguments.html",
    "href": "docs/software/code_quality/code_smells/many_arguments.html",
    "title": "Many arguments",
    "section": "",
    "text": "When a function or method takes many parameters (inputs), it can become difficult to understand, maintain, and test. If a function needs a lot of information to work, it might be doing too many things at once, and this can confuse programmers or lead to mistakes. Refactoring the code to reduce the number of parameters or organizing the data in a more logical way can make the code easier to read and work with.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Many inputs"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/many_arguments.html#symptoms",
    "href": "docs/software/code_quality/code_smells/many_arguments.html#symptoms",
    "title": "Many arguments",
    "section": "Symptoms",
    "text": "Symptoms\n\nFunctions or methods with many parameters, especially if some of them are not used within the function.\nFunctions with long and confusing parameter lists, which are hard to remember or use correctly.\nCode that‚Äôs hard to change or update because of too many parameters being passed around.\nFunctions often require the same set of parameters, which can be grouped together logically.\n\n\n\n\n\n\n\nA good rule of thumb\n\n\n\n\n1-3 parameters: Generally fine.\n4-5 parameters: Might be acceptable if needed, but review if they can be grouped.\n6+ parameters: Strongly consider refactoring the function or method.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Many inputs"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/many_arguments.html#example---long-parameter-list",
    "href": "docs/software/code_quality/code_smells/many_arguments.html#example---long-parameter-list",
    "title": "Many arguments",
    "section": "Example - Long parameter list",
    "text": "Example - Long parameter list\nHere‚Äôs an example of a function that takes many parameters:\ndef process_machine_operation(machine_id, temperature, pressure, speed, duration):\n    # Perform machine operation\n    print(\"Machine ID:\", machine_id)\n    print(\"Temperature:\", temperature)\n    print(\"Pressure:\", pressure)\n    print(\"Speed:\", speed)\n    print(\"Operation Duration:\", duration)\n\n# Usage\nprocess_machine_operation(\n    machine_id=\"M001\", \n    temperature=100.5, \n    pressure=200.0, \n    speed=1500.0, \n    duration=5.0)\nThis function takes a lot of information at once: the machine ID, temperature, pressure, speed, and duration. If the function grows even more complex, it will become very hard to keep track of what each parameter means, and it could make the code difficult to maintain.\n\nSolutions\nTo solve this problem, we can do one or both of the following:\n\nSimplify the Function: Break the function into smaller parts that do one thing each.\nUse Objects to Group Related Data: Instead of passing many individual pieces of information, we can group them together into one object or structure that holds related information.\n\n\n1. Using a Dataclass\nfrom dataclasses import dataclass\n\n# Create a dataclass to group the machine operation parameters\n@dataclass\nclass MachineOperationData:\n    machine_id: str\n    temperature: float\n    pressure: float\n    speed: float\n    duration: float\nNow, instead of passing five separate parameters to our function, we‚Äôll just pass one object that holds everything. Next, we change our process_machine_operation function to accept this new object, making it simpler and cleaner.\ndef process_machine_operation(operation_data):\n    # Perform machine operation\n    print(\"Machine ID:\", operation_data.machine_id)\n    print(\"Temperature:\", operation_data.temperature)\n    print(\"Pressure:\", operation_data.pressure)\n    print(\"Speed:\", operation_data.speed)\n    print(\"Operation Duration:\", operation_data.duration)\n\n# Usage \noperation_data = MachineOperationData(\n    machine_id=\"M001\", \n    temperature=100.5, \n    pressure=200.0, \n    speed=1500.0, \n    duration=5.0)\nprocess_machine_operation(operation_data)\n\n\n\n\n\n\nTip\n\n\n\nYou can combine dataclasses with data validation through Pydantic.\n\n\n\n\n2. Divide and conquer\nAlthough using a single dataclass is a good start, we don‚Äôt want our data structure to become too big and complicated. If the dataclass starts holding too much data, it can make the code harder to understand. Instead, we can break it into smaller, simpler data classes that work together. For example:\n@dataclass\nclass Machine:\n    machine_id: str\n    manufacturer: str\n\n@dataclass\nclass OperationParameters:\n    temperature: float\n    pressure: float\n    speed: float\n    duration: float\n\n@dataclass\nclass EnvironmentalConditions:\n    humidity: float\n    altitude: float\n\n@dataclass\nclass MachineOperationData:\n    machine: Machine\n    operation_parameters: OperationParameters\n    environmental_conditions: EnvironmentalConditions\n\ndef process_machine_operation(operation_data):\n    print(\"Machine ID:\", operation_data.machine.machine_id)\n    \n    # Implement machine operation\nHere, instead of having one large MachineOperationData dataclass, we‚Äôve divided it into smaller pieces. Each class now represents a specific part of the data, which can then be used individually as smaller classes or grouped together as needed. This approach keeps everything organized and easy to work with.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Many inputs"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_smells/many_arguments.html#key-takeaways",
    "href": "docs/software/code_quality/code_smells/many_arguments.html#key-takeaways",
    "title": "Many arguments",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nDon‚Äôt pass too many parameters. If a function requires many parameters, it‚Äôs a sign that the function might be doing too much. Group related data together to reduce the number of parameters or break the function into smaller parts.\nUse classes or dataclasses to help organize related data into neat packages that are easy to pass around in your code.\nKeep things simple: Don‚Äôt let your classes become too big. If necessary, break them down into smaller parts, but keep them organized and easy to understand.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nRealPython - Data Classes",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code smells",
      "Many inputs"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_style.html",
    "href": "docs/software/code_quality/code_style.html",
    "title": "Code style and tools",
    "section": "",
    "text": "‚ÄúPrograms must be written for people to read, and only incidentally for machines to execute.‚Äù\nHarold Abelson",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code style"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_style.html#style-guide",
    "href": "docs/software/code_quality/code_style.html#style-guide",
    "title": "Code style and tools",
    "section": "Style guide",
    "text": "Style guide\nStyle guides are a set of rules and conventions that define how code should be written in a particular programming language. They cover aspects such as naming conventions, indentation, line length, and other formatting rules. Style guides help to ensure that code is consistent, readable, and maintainable, and they are often enforced by static analysis tools and formatters. Many programming languages have official style guides, and there are also community-driven style guides that provide additional recommendations and best practices.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code style"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_style.html#static-analysis-tool",
    "href": "docs/software/code_quality/code_style.html#static-analysis-tool",
    "title": "Code style and tools",
    "section": "Static analysis tool",
    "text": "Static analysis tool\nStatic analysis tools are used to analyze source code without executing it. They can identify potential issues in the code, such as syntax errors, bugs, and code smells. Static analysis tools can also enforce coding standards and best practices, and help to identify security vulnerabilities. They are often integrated into Continuous Integration workflows to ensure that code quality is maintained throughout the development process.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code style"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_style.html#formatters",
    "href": "docs/software/code_quality/code_style.html#formatters",
    "title": "Code style and tools",
    "section": "Formatters",
    "text": "Formatters\nFormatters are tools that automatically adjust the formatting of your code to make it consistent and readable according to predefined style guidelines. They do not identify errors in the logic of the code but instead can restructure the whitespace, line breaks, and indentation so that the code is more uniform across a project.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code style"
    ]
  },
  {
    "objectID": "docs/software/code_quality/code_style.html#overview-of-programming-languages",
    "href": "docs/software/code_quality/code_style.html#overview-of-programming-languages",
    "title": "Code style and tools",
    "section": "Overview of programming languages",
    "text": "Overview of programming languages\n\n\n\nLanguage\nStyle Guide\nStatic Analysis Tools\nFormatters\n\n\n\n\nPython\nPEP 8\npylint, flake8, prospector\nblack, autopep8, yapf\n\n\nR\nTidyverse Style Guide\nlintr\nstyler\n\n\nMATLAB\nMATLAB Style Guidelines 2.0\ncheckcode\nCode Analyzer\n\n\nC/C++\nGoogle C++ Style Guide\ncppcheck, clang-tidy\nclang-format, astyle\n\n\nJulia\nJulia Style Guide, Blue Style Guide\nJET.jl, Aqua.jl\nJuliaFormatter.jl\n\n\nFortran\nFortran Best Practices\nfortran-linter\nfprettify\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nThe Turing Way - Code Quality\nThe Turing Way - Code Style\nRealPython - Python Code Quality\nRealPython - PEP8",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Code style"
    ]
  },
  {
    "objectID": "docs/software/code_quality/online_services.html",
    "href": "docs/software/code_quality/online_services.html",
    "title": "Online services",
    "section": "",
    "text": "Sonar\nSonar is a cloud-based service that provides inspection of code quality to perform automatic reviews with static code analysis to detect bugs, code smells and security vulnerabilities in a project. It supports many programming languages and integrates with GitHub (and GitLab and Bitbucket) as part of the Continuous Integration workflows. Sonar is particularly useful for projects that require compliance with coding standards or need regular feedback on the quality of the code.\n Learn more: SonarQube Cloud documentation\n\n\n\n\n\n\nConsideration\n\n\n\nWhile Sonar offers valuable features for code quality analysis, be aware that for non open-source projects it is a paid service, and pricing model depends on how many lines of code you want to check.\n\n\n\n\nGitHub CodeQL\nGitHub CodeQL is a semantic code analysis engine that allows you to write queries to find security vulnerabilities in your codebase. It is particularly useful for identifying security vulnerabilities in open-source projects, and it can be integrated into your GitHub Actions workflow to automatically scan your code for vulnerabilities. CodeQL is available for a variety of programming languages, and it can help you identify and fix security issues before they become a problem.\n\n\n\n\n\n\n Learn more\n\n\n\n\nGitHub CodeQL\nIntroduction to code scanning\n\n\n\n\n\nCode coverage\nCode coverage quantifies the proportion of source code that is run by a software program‚Äôs (unit) test suite. It helps to identify which parts of the codebase have been tested, and achieving a high code coverage generally indicates a lower likelihood of hidden bugs. However, it is important to note that high code coverage does not necessarily translate to high code quality - it simply tells us how much of the codebase is being tested.\n\n\n\n\n\n\n Learn more\n\n\n\n\nSonar - Test coverage\nCodecov - Test coverage\n\n\n\n\n\nDependabot\nDependabot is a GitHub app that helps you keep your dependencies up to date. It checks for outdated dependencies in your project and automatically creates pull requests to update them. This can help you stay on top of security vulnerabilities and ensure that your project is using the latest features and bug fixes.\n Enabling Dependabot for your repository\n\n\nOpenSSF\nThe Open Source Security Foundation (OpenSSF) Best Practices badge provides a way for Free/Libre and Open Source Software (FLOSS) projects to demonstrate their adherence to best practices. Projects can choose to self-certify for free. Inspired by the numerous badges available on GitHub, the OpenSSF Best Practices Badge allows to quickly identify which FLOSS projects are committed to best practices and are therefore more likely to deliver high-quality and secure software.\nThe criteria for earning the passing badge and additional details about the OpenSSF Best Practices Badging program can be found on GitHub.\n\n\n\n\n\n\n Learn more\n\n\n\n\nOpenSSF - Best Practices\nGitHub - Best Practices Badge",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Code quality",
      "Online services"
    ]
  },
  {
    "objectID": "docs/software/containers/docker_gui.html",
    "href": "docs/software/containers/docker_gui.html",
    "title": "Using a docker container with a GUI",
    "section": "",
    "text": "Docker is an open platform for developing, shipping, and running applications. Docker provides the ability to package and run an application in a loosely isolated environment called a container. Containers are lightweight and contain everything needed to run the application, so you do not need to rely on what is currently installed on the host system. You can easily share containers while you work, and be sure that everyone you share with gets the same container that works in the same way.\nDockerfile ‚Äì is a text document that contains all the commands you would normally execute manually in order to build a Docker image. The instructions include a choice of operating system and all the libraries we need to install into it. Docker can build images automatically by reading the instructions from a Dockerfile.\nDocker Images ‚Äì are the basis of containers. A Docker image is an immutable (unchangeable) file that contains the source code, libraries, dependencies, tools, and other files needed for an application to run.\nDocker Container ‚Äì A container is, ultimately, just a running image."
  },
  {
    "objectID": "docs/software/containers/docker_gui.html#docker-installation",
    "href": "docs/software/containers/docker_gui.html#docker-installation",
    "title": "Using a docker container with a GUI",
    "section": "Docker installation",
    "text": "Docker installation\nDocker can be installed on Windows, macOS, and Linux. Please visit the Docker website for downloading and installation instructions. Note, you will need admin access to your system.\nPlease check the Issues/troubleshooting session at the end of this page if you encounter some problems during installation. If your problem is not listed you can add it as an issue in the main repository.\n\nVerify Docker installation\nRun the following commands in the terminal (see below) to verify your installation:\n\ndocker --version\nWill output the version number\ndocker run hello-world\nWill output a welcome message. If you haven‚Äôt run this command before, you will receive the message Unable to find image: ‚Äòhello-world:latest‚Äô locally. Docker will then proceed by downloading and running the latest version from DockerHub."
  },
  {
    "objectID": "docs/software/containers/docker_gui.html#terminal-access",
    "href": "docs/software/containers/docker_gui.html#terminal-access",
    "title": "Using a docker container with a GUI",
    "section": "Terminal access",
    "text": "Terminal access\nLinux\nThe default Unix Shell for Linux operating systems is usually Bash. On most versions of Linux, it is accessible by running the (Gnome) Terminal or (KDE) Konsole or xterm, which can be found via the applications menu or the search bar. If your machine is set up to use something other than bash, you can run it by opening a terminal and typing bash.\nmacOS\nFor a Mac computer, the default Unix Shell is Bash, and it is available via the Terminal Utilities program within your Applications folder. To open Terminal, try one or both of the following:\n\nGo to your Applications. Within Applications, open the Utilities folder. Locate Terminal in the Utilities folder and open it.\nUse the Mac ‚ÄòSpotlight‚Äô computer search function. Search for: Terminal and press Return.\n\nFor more info: How To use a terminal on Mac\nWindows\nComputers with Windows operating systems do not automatically have a Unix Shell program installed. We encourage you to use an emulator included in Git for Windows, which gives you access to both Bash shell commands and Git. To install, please follow these instructions."
  },
  {
    "objectID": "docs/software/containers/docker_gui.html#x-windows-system",
    "href": "docs/software/containers/docker_gui.html#x-windows-system",
    "title": "Using a docker container with a GUI",
    "section": "X Windows System",
    "text": "X Windows System\nDocker doesn‚Äôt have any build-in graphics, which means it cannot run desktop applications by default. For this, we require the X Windows System. The X Window System (X11, or simply X) is a windowing system for bitmap displays, common on Unix-like operating systems. X provides the basic framework for a GUI environment: drawing and moving windows on the display device and interacting with a mouse and a keyboard.\nIf you are on a desktop Linux, you already have one. For macOS, you can download XQuartz, and for Windows, we tested VcXsrv.\nDesktop applications will run in Docker and will try to communicate with the X server you‚Äôre running on your PC. They don‚Äôt need to know anything but the location of the X server and an optional display that they target. This is denoted by an environmental variable named DISPLAY, with the following syntax: DISPLAY=xserver-host:0. The number you see after the : is the display number; for the intents and purpose of this article, we will consider this to be equivalent to 0 is the primary display attached to the X server.\nIn order to set up the environment variable, we need to add the following code to the docker run command in the terminal:\n\nWindowsmacOSLinux\n\n\n-e DISPLAY=host.docker.internal:0\n\n\n-e DISPLAY=docker.for.mac.host.internal:0\n\n\n--net=host -e DISPLAY=:0\n\n\n\nWith these commands (and an active X server on the host system), any graphical output inside the container will be shown on your own desktop."
  },
  {
    "objectID": "docs/software/containers/docker_gui.html#mount-a-volume",
    "href": "docs/software/containers/docker_gui.html#mount-a-volume",
    "title": "Using a docker container with a GUI",
    "section": "Mount a volume",
    "text": "Mount a volume\nThe docker image with which you can spawn a container contains all the software and general datafiles. However, we still need to give the container access to your dataset. To do so, we can mount a directory on your own system inside the container with the following command structure: -v &lt;abs_path_host&gt;:&lt;abs_path_container&gt;. Assuming your terminal is opened inside the data folder on your system, the specific commands for the different operating systems mount this folder as the /data folder inside the container, are:\nFor Windows in GitBash: -v /$(pwd):/data\nFor Windows in cmd: -v %cd%:/data\nFor Linux and macOS: -v $(pwd):/data\n$(pwd) can be replaced with the absolute path of the datafolder, or be used to access subdirectories (e.g.¬†$(pwd)/data:/data).\nFor more info about mounting volumes, check this StackOverflow question"
  },
  {
    "objectID": "docs/software/containers/docker_gui.html#running-a-container-with-data-and-graphical-output",
    "href": "docs/software/containers/docker_gui.html#running-a-container-with-data-and-graphical-output",
    "title": "Using a docker container with a GUI",
    "section": "Running a container with data and graphical output",
    "text": "Running a container with data and graphical output\nTo start a container from an image, we use the command docker run &lt;image_name&gt;. We also pass the additional flags --rm to delete the container after closing and -it to be able to interact with the container. Combining all arguments then leads to the following commands to run (and automatically close) the container:\n\nWindowsmacOSLinux\n\n\ndocker run --rm -it -e DISPLAY=host.docker.internal:0 -v /$(pwd):/data &lt;image_name&gt;:&lt;image_version&gt;\n\n\ndocker run --rm -it -e DISPLAY=docker.for.mac.host.internal:0 -v $(pwd):/data &lt;image_name&gt;:&lt;image_version&gt;\n\n\ndocker run --rm -it --net=host -e DISPLAY=:0 -v $(pwd):/data &lt;image_name&gt;:&lt;image_version&gt;"
  },
  {
    "objectID": "docs/software/containers/docker_gui.html#issuestroubleshooting",
    "href": "docs/software/containers/docker_gui.html#issuestroubleshooting",
    "title": "Using a docker container with a GUI",
    "section": "Issues/Troubleshooting",
    "text": "Issues/Troubleshooting\n\nFor Linux users encountering the error Unable to init server, please run xhost + in the terminal and rerun the docker run command. For more info, see here.\nWSL 2 installation incomplete for Windows users\n\nEnable the virtualization in the BIOS\nFollow ALL the steps described in: https://docs.microsoft.com/en-us/windows/wsl/install-manual\n\nFailing to port a display in the docker container for Mac users.\n\nSolution: Change the docker run command by this one , docker run --rm -it -e DISPLAY=IPADDRESS:0 -v $(pwd):/data &lt;image_name&gt;:&lt;image_version&gt;\nThe IPADDRESS is gotten from typing ifconfig in the terminal.\n\nFailing to run the pipeline once the GUI is open\n\nCheck that all documents are closed before run it , namely the Getting started and the adapter files documents.\n\nFailing to mount an external hard drive in Windows when running a docker container\n\nError:\n\n      libGL error: No matching fbConfigs or visuals found\n      libGL error: failed to load driver: swrast\n\nSolution (noy yet found):\n\nLook into this links:\n\nhttps://stackoverflow.com/questions/46586013/glxgears-not-working-inside-of-docker"
  },
  {
    "objectID": "docs/software/development_workflow/envs_dependencies.html",
    "href": "docs/software/development_workflow/envs_dependencies.html",
    "title": "Environment and dependency management",
    "section": "",
    "text": "Properly managing dependencies and your environment is a critical aspect of any software project. This ensures that your project can be reliably reproduced, simplifies setup for collaborators, and reduces conflicts between third-party libraries.\n\n\n\n Python\nEnvironment and dependency management in Python.\n\nLearn more ¬ª\n\n\n\n MATLAB\nEnvironment and dependency management in MATLAB.\n\nLearn more ¬ª\n\n\n\n R\nEnvironment and dependency management in R.\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Environments and dependencies"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/envs_dependencies/python_envs_dependencies.html",
    "href": "docs/software/development_workflow/envs_dependencies/python_envs_dependencies.html",
    "title": "Environment and dependency management in Python",
    "section": "",
    "text": "When working with Python, managing dependencies and environments is important to ensure your project can be reproduced and shared.\n\n\n\n\n\n\n Definitions:\n\n\n\nA dependency is any external library your project needs, and a virtual environment is an isolated workspace where dependencies are installed.\n\n\nThere are several ways to manage dependencies and environments:\n\nConda environments\nVirtual environments (venv/virtualenv)\nDependency management tools (e.g.¬†poetry, pipenv)\n\n\nConda Environments\nConda is a package and environment manager popular in the research and data science community. It allows you to manage both Python and non-Python dependencies.\n\nBasic commands\n# Create a new environment, e.g. with python 3.12\nconda create -n your_env_name python=3.12\n\n# List all environments\nconda env list\n\n# Activate an environment\nconda activate your_env_name\n\n# Install packages in an environment\nconda install package_name\n\n# Remove a package\nconda remove package_name\n\n# Export an environment to a file\nconda env export &gt; environment.yml\n\n# Deactivate an environment\nconda deactivate\n\n# Remove an environment\nconda env remove -n your_env_name\n\n\nConda environment files\nConda environment files (environment.yml) are used to specify the dependencies of a project. They can be used to create an environment from scratch, or to update an existing environment.\n# Export an environment to a file\nconda env export &gt; environment.yml\n\n# Create an environment from a file\nconda env create -f environment.yml\n\n# Update an environment from a file\nconda env update -f environment.yml\n\n\n\nVirtual Environments (venv/virtualenv)\nPython provides venv as a buil-in tool for creating virtual environments. virtualenv is a third-party tool that provides similar functionality.\n\nBasic commands\n# Creating a virtual environment\n# Using venv (Python 3.3+ built-in)\npython -m venv your-env-name\n\n# Using virtualenv (must be installed first)\npip install virtualenv\nvirtualenv your-env-name\n\n#Activating the environment\n# Linux/macOS\nsource your-env-name/bin/activate\n# Windows\nyour-env-name\\Scripts\\activate\n\n# Installing a library (package)\npip install lib_name\n\n# Uninstalling a library (package)\npip uninstall lib_name\n\n# To deactivate\ndeactivate\n\n\nManaging dependencies with pip\nA requirements.txt file lists all dependencies with their specific versions.\n# Export requirements.txt from an activated environment\npip freeze &gt; requirements.txt\n\n# Install dependencies from requirements.txt\npip install -r requirements.txt\n\n\n\n\n\n\n Tip\n\n\n\nUse pip-chill or pipreqs instead of pip freeze to exclude unnecessary dependencies. pip-chill lists only packages you installed, while pipreqs lists packages your code actually uses.\n\n\n\n\n\nDependency Management Tools\nConsider using tools that offer more sophisticated dependency management by integrating virtual environment creation and dependency resolution. They maintain a project manifest (e.g., pyproject.toml for Poetry) that specifies primary dependencies and generate lock files to pin exact versions for reproducibility.\n\nPipenv: Combines pip and virtualenv into a single tool, with a focus on simplicity and ease of use.\nPoetry: Manages dependencies, environments, and package building in a streamlined way.\nPixi: A new tool that aims to provide a more user-friendly experience for managing Python environments and dependencies.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nCodeRefinery - Recording dependencies\nThe Turing Way - Package Management Systems\nConda documentation\nvirtualenv documentation\nvirtualenvwrapper extension",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Environments and dependencies",
      "Python"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/index.html",
    "href": "docs/software/development_workflow/index.html",
    "title": "Development workflow",
    "section": "",
    "text": "A well-organized workspace and clear software development process make research easier and more effective. Organizing your project repository clearly and following steps for working alone or with others can help improve your research and make it easier to expand. This section provides guidance on how to manage your project, structure your project, reuse projects, manage environments and dependencies, choose a branching strategy, and collaborate with others.\n\n\n\n Project Management\nManaging your projects through version control platforms.\n\nLearn more ¬ª\n\n\n\n Project Structue\nStructuring your project.\n\nLearn more ¬ª\n\n\n\n Project Templates and Reusability\nReusing projects and repositories.\n\nLearn more ¬ª\n\n\n\n Environments and Dependencies\nManaging your environments and dependencies.\n\nLearn more ¬ª\n\n\n\n Branch Management\nChoosing a branching strategy.\n\nLearn more ¬ª\n\n\n\n Collaboration\nCollaborative workflow.\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_structure.html",
    "href": "docs/software/development_workflow/project_structure.html",
    "title": "Project structure",
    "section": "",
    "text": "In software development, the choices you make at the start will affect your project‚Äôs final outcome. One key decision is how to structure your project, as a well-organised setup is essential for reproducibility and long-term maintainability.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project structure"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/project_structure.html#repository-structures",
    "href": "docs/software/development_workflow/project_structure.html#repository-structures",
    "title": "Project structure",
    "section": "Repository structures",
    "text": "Repository structures\nThe following are recommendations of how you can structure your project repository for Python, MATLAB, and R projects.\n\nPythonMATLABR\n\n\nyour_project/\n‚îÇ\n‚îú‚îÄ‚îÄ docs/                     # Documentation directory\n‚îú‚îÄ‚îÄ notebooks/                # Jupyter notebooks\n‚îú‚îÄ‚îÄ src/                      # Contains your main code\n‚îÇ   ‚îî‚îÄ‚îÄ your_project/            # A folder where your organized code lives\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py       # A marker file that indicates this folder is for Python code\n‚îÇ       ‚îú‚îÄ‚îÄ module            # A file or folder with specific functions or classes\n‚îÇ       ‚îî‚îÄ‚îÄ extras/           # A folder for additional, related code\n‚îÇ           ‚îî‚îÄ‚îÄ __init__.py   # A marker file for the additional code folder\n‚îú‚îÄ‚îÄ tests/                    # Your test directory  \n‚îÇ\n‚îú‚îÄ‚îÄ data/                     # Data files used in the project (if applicable)\n‚îú‚îÄ‚îÄ processed_data/           # Files from your analysis (if applicable)\n‚îú‚îÄ‚îÄ results/                  # Results (if applicable)\n‚îÇ\n‚îú‚îÄ‚îÄ .gitignore                # Untracked files \n‚îú‚îÄ‚îÄ requirements.txt          # Software dependencies (environment.yml if using Conda)\n‚îÇ                             # ‚Üë Even better to use a build system config (pyproject.toml)\n‚îÇ                             # ‚Üë which is becoming the new standard\n‚îú‚îÄ‚îÄ README.md                 # README\n‚îî‚îÄ‚îÄ LICENSE                   # License information\n Choosing between a src/ layout and a flat layout for Python\n\n\nyour_project/\n‚îÇ\n‚îú‚îÄ‚îÄ docs/                   # Documentation and user guides\n‚îú‚îÄ‚îÄ src/                    # Main MATLAB code\n‚îÇ   ‚îú‚îÄ‚îÄ utils/              # Helper functions and scripts\n‚îÇ   ‚îú‚îÄ‚îÄ models/             # Core functions or classes implementing models/algorithms\n‚îÇ   ‚îî‚îÄ‚îÄ main_script.m       # Main script/-s or entry point for the project\n‚îÇ\n‚îú‚îÄ‚îÄ scripts/                # Scripts folder (e.g. for analysis and demo scripts)\n‚îú‚îÄ‚îÄ tests/                  # Tests folder (e.g. MATLAB unit tests)\n‚îú‚îÄ‚îÄ data/                   # Raw data files\n‚îú‚îÄ‚îÄ results/                # Output files (figures, processed data, etc.)\n‚îú‚îÄ‚îÄ examples/               # Example usage or tutorials\n‚îÇ\n‚îú‚îÄ‚îÄ .gitignore              # Specifies files/folders to ignore in version control\n‚îú‚îÄ‚îÄ README.md               # Project overview and instructions\n‚îî‚îÄ‚îÄ LICENSE                 # License information\n\n\nyour_project/\n‚îÇ\n‚îú‚îÄ‚îÄ R/                        # R scripts and functions (can also be called src/)\n‚îÇ   ‚îú‚îÄ‚îÄ function.R            # R functions used across analyses\n‚îÇ   ‚îî‚îÄ‚îÄ other_function.R      \n‚îÇ\n‚îú‚îÄ‚îÄ data/                     # raw data files (if applicable)\n‚îú‚îÄ‚îÄ processed_data/           # processed data files (if applicable)\n‚îÇ\n‚îú‚îÄ‚îÄ doc/                      # project documentation\n‚îú‚îÄ‚îÄ man/                      # helper files for package functions generated from roxygen2 (if applicable)\n‚îÇ      \n‚îú‚îÄ‚îÄ vignettes/                # explanatory vignettes for the project (if applicable)\n‚îÇ   ‚îî‚îÄ‚îÄ function_vignette.Rmd # vignettes for each function\n‚îÇ\n‚îú‚îÄ‚îÄ tests/                    # test cases for your functions (highly recommended)\n‚îÇ   ‚îî‚îÄ‚îÄ testthat/             # using the testthat package\n‚îÇ\n‚îú‚îÄ‚îÄ results/                  # output from data analyses etc. (if applicable)\n‚îÇ\n‚îú‚îÄ‚îÄ scripts/                  # high-level scripts for running analyses\n‚îÇ   ‚îî‚îÄ‚îÄ analysis_script.R     # script running the main analysis\n‚îÇ\n‚îú‚îÄ‚îÄ .gitignore                # gitignore\n‚îú‚îÄ‚îÄ DESCRIPTION               # package description file (if applicable)\n‚îú‚îÄ‚îÄ NAMESPACE                 # namespace file for package (if applicable)\n‚îú‚îÄ‚îÄ README.md                 # README\n‚îî‚îÄ‚îÄ LICENSE                   # license information\n\n\n\nThese structures are a starting point and can be adapted based on the specific needs and practices of your project. Some additional tips:\n\nParticular metadata files are often capitalized, such as README, LICENSE, CONTRIBUTING, CODE_OF_CONDUCT, CHANGELOG, CITATION.cff, NOTICE, and MANIFEST.\nGenerally, all content that is generated upon building or running your code should be added to .gitignore. This likely includes the content of processed_data and results folder.\nGit cannot track empty folders. If you want to add empty folders to enforce a folder structure, e.g., processed_data orresults, the convention is to add the file .gitkeep to the folder.\n\n\n\n\n\n\n\n Managing data\n\n\n\nIf your raw data files or any data assets are large (typically more than a few megabytes), it‚Äôs usually best not to include them directly in the repository. Instead:\n\nKeep such files externally (e.g.¬†cloud storage, Git LFS), and add only a reference or a small sample to the repository.\nAdding placeholder files or instructions in the README for how to obtain the complete datasets.\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nCode Refinery - Organizing your projects\nArjanCodes guide to structuring Python projects\nA collection of .gitignore templates\nGit LFS",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Project structure"
    ]
  },
  {
    "objectID": "docs/software/documentation/citation.html",
    "href": "docs/software/documentation/citation.html",
    "title": "CITATION.cff",
    "section": "",
    "text": "It‚Äôs straightforward to cite research papers, but with software sometimes it‚Äôs not as obvious. It is recommended to place a CITATION.cff file in the root of your repository to inform others about the preferred way to cite the software. GitHub can automatically parse the .cff file to create citation snippets in APA or BibTeX format. If you‚Äôd prefer the software to be cited through a journal publication, you can mention this in the README and in the CITATION.cff file.\n\n\n\n\n\n\n An example of a CITATION.cff\n\n\n\n\n\ncff-version: 1.2.0\nmessage: \"If you are using this software, please cite it as shown below.\"\nauthors:\n- family-names: \"Doe\"\n  given-names: \"Jane\"\n  orcid: \"https://orcid.org/9999-9999-9999-9999\"\ntitle: \"Name of your software\"\nversion: 1.0.1\ndoi: \"11.1111/11111\"\ndate-released: 2024-12-31\nlicense: MIT\nurl: \"https://github.com/your_repo\"\n\n\n\nWhen citing a paper that is linked to the software you can use preferred-citation argument.\n\n\n\n\n\n\n An example of a CITATION file citing a research article\n\n\n\n\n\ncff-version: 1.2.0\nmessage: \"If you are using this software, please cite it as shown below.\"\nauthors:\n- family-names: \"Doe\"\n  given-names: \"Jane\"\n  orcid: \"https://orcid.org/9999-9999-9999-9999\"\ntitle: \"Name of your software\"\nversion: 1.0.1\ndoi: \"11.1111/11111\"\ndate-released: 2024-12-31\nlicense: MIT\nurl: \"https://github.com/your_repo\"\npreferred-citation:\n    type: article\n    authors:\n    - family-names: \"Doe\"\n      given-names: \"Jane\"\n      orcid: \"https://orcid.org/9999-9999-9999-9999\"\n    doi: \"11.1111/11111\"\n    journal: \"The title of the journal\"\n    month: 12\n    start: 19 # the first page number\n    end: 29 #the last page number\n    title: \"Name of your submitted paper\"\n    issue: 9\n    volume: 2\n    year: 2024\n    \n\n\n\n\n\n\n\n\n\n How the citation would look on GitHub\n\n\n\n\n\nOn GitHub, it will show in either APA or BibTeX formatting, as they are the currently supported formats. If you add a CITATION.cff file to your repository, then a label for citing will automatically be generated and will show up on the right sidebar of the repository.\nAPA\n\nDoe, J. (2024). Name of your software (Version 1.0.1) [Computer software]. https://doi.org/11.1111/11111\n\nBibTeX\n\n@software{Joe_Name_of_your_software_2024, author = {Doe, Jane}, doi = {11.1111/11111}, month = {12}, title = {{Name of your software}}, url = {https://github.com/your_repo}, version = {1.0.1}, year = {2024} }\n\nThis is an example of software citation.\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nCITATION.cff documentation\nGitHub documentation on CITATION files - this resource also includes how to cite something other than software or a journal article.\nGenerate CITATION.cff files\nCitation File Format GitHub",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "CITATION"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/matlab_documentation.html",
    "href": "docs/software/documentation/code_documentation/matlab_documentation.html",
    "title": "MATLAB documentation",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation",
      "MATLAB projects"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/r_documentation.html",
    "href": "docs/software/documentation/code_documentation/r_documentation.html",
    "title": "R documentation",
    "section": "",
    "text": "The standard approach for documenting R projects is using roxygen2, a package that enables inline documentation for R scripts and packages. It is tightly integrated with the R ecosystem, making it straightforward to generate user-friendly documentation in the form of help files (.Rd files). roxygen2 allows you to write documentation alongside your code as specially formatted comments, which are then parsed and converted into the appropriate documentation format as .Rd files.\nKey features of roxygen2:\n\nInline documentation: Document functions, arguments, and return values directly in the script.\nIntegration with R‚Äôs help option: Generates .Rd files, which are then converted into the help pages users can access with ?function_name.\nCross-referencing: You can easily link to other functions within the documentation.\nNamespace management: Automatically manages the NAMESPACE file for proper imports and exports. A NAMESPACE file is typical for CRAN submissions.\n\n\n\n\nInstall with install.packages(\"roxygen2\").\nEnsure you are in the correct project directory and it has the standard R package structure.\nWriting documentation: Documentation is written as comments starting with #' directly above your function definitions. roxygen2 processes this and stores .Rd files in the man/ directory. Common tags include:\n\n@param: Describes function arguments.\n@return: Describes the return value.\n@examples: Provides example usage.\n@import: For importing functions from other packages.\n@inheritParams: To inherit parameter descriptions from another documented function.\n@export: Makes the function available to package users.\n@seealso : For cross-referencing.\n\nGenerating documentation: Run roxygenise() to convert your documentation into .Rd files. You can also use devtools::document()since it is a wrapper around roxygenise().\nWhen packaging your R project, you can use devtools::check() to ensure your documentation is consistent with your function definitions.\n\n\n\n\n\n\n\n roxygen2 example\n\n\n\n\n\n#' Summarize a numeric vector\n#'\n#' This function calculates the mean, median, and standard deviation of a given \n#' numeric vector and returns the results in a data frame.\n#'\n#' @param x A numeric vector.\n#' @return A data frame with the following columns:\n#' \\describe{\n#'   \\item{mean}{The mean of the numeric vector.}\n#'   \\item{median}{The median of the numeric vector.}\n#'   \\item{sd}{The standard deviation of the numeric vector.}\n#' }\n#' @details This function provides a quick summary for a numeric vector, returning \n#' measures of central tendency (mean and median) and a measure of \n#' dispersion (standard deviation) using R‚Äôs base functions mean(), median(), and sd().\n#' @examples\n#' # Basic example\n#' summarize_vector(c(1, 2, 3, 4, 5))\n#' \n#' @export\nsummarize_vector &lt;- function(x) {\n  if (!is.numeric(x)) stop(\"Input must be a numeric vector.\")\n  \n  mean_val &lt;- mean(x)\n  median_val &lt;- median(x)\n  sd_val &lt;- sd(x)\n  \n  return(data.frame(mean = mean_val, median = median_val, sd = sd_val))\n}\n\n\n\n\n\n\n\n\n\n Example repositories using roxygen2:\n\n\n\n\nggplot2 on GitHub\ndplyr on GitHub",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation",
      "R projects"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/r_documentation.html#roxygen2",
    "href": "docs/software/documentation/code_documentation/r_documentation.html#roxygen2",
    "title": "R documentation",
    "section": "",
    "text": "The standard approach for documenting R projects is using roxygen2, a package that enables inline documentation for R scripts and packages. It is tightly integrated with the R ecosystem, making it straightforward to generate user-friendly documentation in the form of help files (.Rd files). roxygen2 allows you to write documentation alongside your code as specially formatted comments, which are then parsed and converted into the appropriate documentation format as .Rd files.\nKey features of roxygen2:\n\nInline documentation: Document functions, arguments, and return values directly in the script.\nIntegration with R‚Äôs help option: Generates .Rd files, which are then converted into the help pages users can access with ?function_name.\nCross-referencing: You can easily link to other functions within the documentation.\nNamespace management: Automatically manages the NAMESPACE file for proper imports and exports. A NAMESPACE file is typical for CRAN submissions.\n\n\n\n\nInstall with install.packages(\"roxygen2\").\nEnsure you are in the correct project directory and it has the standard R package structure.\nWriting documentation: Documentation is written as comments starting with #' directly above your function definitions. roxygen2 processes this and stores .Rd files in the man/ directory. Common tags include:\n\n@param: Describes function arguments.\n@return: Describes the return value.\n@examples: Provides example usage.\n@import: For importing functions from other packages.\n@inheritParams: To inherit parameter descriptions from another documented function.\n@export: Makes the function available to package users.\n@seealso : For cross-referencing.\n\nGenerating documentation: Run roxygenise() to convert your documentation into .Rd files. You can also use devtools::document()since it is a wrapper around roxygenise().\nWhen packaging your R project, you can use devtools::check() to ensure your documentation is consistent with your function definitions.\n\n\n\n\n\n\n\n roxygen2 example\n\n\n\n\n\n#' Summarize a numeric vector\n#'\n#' This function calculates the mean, median, and standard deviation of a given \n#' numeric vector and returns the results in a data frame.\n#'\n#' @param x A numeric vector.\n#' @return A data frame with the following columns:\n#' \\describe{\n#'   \\item{mean}{The mean of the numeric vector.}\n#'   \\item{median}{The median of the numeric vector.}\n#'   \\item{sd}{The standard deviation of the numeric vector.}\n#' }\n#' @details This function provides a quick summary for a numeric vector, returning \n#' measures of central tendency (mean and median) and a measure of \n#' dispersion (standard deviation) using R‚Äôs base functions mean(), median(), and sd().\n#' @examples\n#' # Basic example\n#' summarize_vector(c(1, 2, 3, 4, 5))\n#' \n#' @export\nsummarize_vector &lt;- function(x) {\n  if (!is.numeric(x)) stop(\"Input must be a numeric vector.\")\n  \n  mean_val &lt;- mean(x)\n  median_val &lt;- median(x)\n  sd_val &lt;- sd(x)\n  \n  return(data.frame(mean = mean_val, median = median_val, sd = sd_val))\n}\n\n\n\n\n\n\n\n\n\n Example repositories using roxygen2:\n\n\n\n\nggplot2 on GitHub\ndplyr on GitHub",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation",
      "R projects"
    ]
  },
  {
    "objectID": "docs/software/documentation/code_documentation/r_documentation.html#vignettes",
    "href": "docs/software/documentation/code_documentation/r_documentation.html#vignettes",
    "title": "R documentation",
    "section": "Vignettes",
    "text": "Vignettes\nVignettes are detailed guides or tutorials included with R packages, providing users with in-depth explanations and examples, complementing the shorter help files. They are useful for demonstrating package functionality and use cases. Vignettes are automatically compiled and included in the package documentation.\nYou can create a vignette by running:\nusethis::use_vignette(\"your_vignette_name\")\nThis creates a template in the vignettes/ directory with the necessary YAML header and structure. You can combine text, code chunks, and outputs using standard R Markdown syntax. Include explanations, usage examples, and visualizations to enhance clarity.\nOnce written, build the vignette using:\ndevtools::build_vignettes()\nThis generates HTML or PDF versions of the vignette, which are then included in the package documentation. Use devtools::install(build_vignettes = TRUE) to test your package and built vignettes together (see how a user would experience them).\n\n\n\n\n\n\n Learn More\n\n\n\n\nExplore vignette(\"roxygen2\") in R\nroxygen2 documentation\nFunction documentation from R Packages\nWriting vignettes\nCRAN Submission guidelines",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Code documentation",
      "R projects"
    ]
  },
  {
    "objectID": "docs/software/documentation/contributing_guidelines.html",
    "href": "docs/software/documentation/contributing_guidelines.html",
    "title": "Contributing guidelines",
    "section": "",
    "text": "A well-maintained README provides an overview of your project‚Äôs current state, while a CONTRIBUTING guide encourages user/developer involvement. Together, these documents help maintain project clarity and make it easier to manage contributions.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Contributing guidelines"
    ]
  },
  {
    "objectID": "docs/software/documentation/contributing_guidelines.html#setting-up-a-contributing-guide",
    "href": "docs/software/documentation/contributing_guidelines.html#setting-up-a-contributing-guide",
    "title": "Contributing guidelines",
    "section": "Setting up a CONTRIBUTING guide",
    "text": "Setting up a CONTRIBUTING guide\nThere are no strict guidelines for a contributing guide and the content will depend on the project size, the number of collaborators, and your particular workflow. Consider including:\n\nIntroduction: Welcome the contributors and express appreciation for community contributions.\nAdd a code of conduct: This helps to maintain a respectful and inclusive environment.\nHow to contribute: Explain precise contribution guidelines\n\nIssue tracking: Explain how to report issues (bugs, feature requests, etc.).\nPull requests: Detail the process for submitting pull requests. This includes instructions on forking the repository, creating a branch, making changes, and the follow-up steps for a successful pull request.\nCode review process: Describe how contributions will be reviewed and integrated.\n\nCommunity and communication: List the channels through which contributors can communicate and set their expectations regarding the responsiveness and availability of project maintainers.\nStyle guide and coding standards: Providing a (separate) coding style guide or documenting coding standards would be best practice. This way contributors would ensure consistency across the codebase.\nLegal implications: Inform contributors about the licensing under which their contributions will be used and any intellectual property considerations they should be aware of.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nGitHub‚Äôs guide to setting guidelines for repository contributors\nGitHub‚Äôs own CONTRIBUTING guide",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Contributing guidelines"
    ]
  },
  {
    "objectID": "docs/software/documentation/index.html",
    "href": "docs/software/documentation/index.html",
    "title": "Documentation",
    "section": "",
    "text": "Documentation serves as a bridge between the developer and user, and effectively communicating and explaining the code is as important as the code itself. Often, two types of documentation are distinguished - user and developer documentation. Both are essential for the success of a software project, and they serve different purposes.\n\nUser documentation\nUser documentation is aimed at those who will use the software. This documentation typically includes user manuals and tutorials, possibly FAQs and troubleshooting guides. The focus is on simplicity and accessibility, ensuring that anyone can understand how to use the software.\n\n\n\n\n README\nHow to write a good README.\n\nLearn more ¬ª\n\n\n\n Licenses\nApply an open-source license.\n\nLearn more ¬ª\n\n\n\n CITATION\nCite your software.\n\nLearn more ¬ª\n\n\n\n\n\nDeveloper documentation\nDeveloper documentation targets developers who need to understand the internal parts of the software for purposes of development, maintenance, or integration. It can include additional details such as API documentation and development guidelines. Developer documentation is more detailed providing insights necessary for modifying and enhancing the software.\n\n\n\n\n Code Documentation\nDocumenting your codebase.\n\nLearn more ¬ª\n\n\n\n Tooling\nDeploy your documentation.\n\nLearn more ¬ª\n\n\n\n Hosting\nHost your documentation.\n\nLearn more ¬ª\n\n\n\n Contributing Guidelines\nDefine how to contribute to your project.\n\nLearn more ¬ª\n\n\n\n Code of Conduct\nSet expectations for respectful, inclusive collaboration among contributors.\n\nLearn more ¬ª",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation"
    ]
  },
  {
    "objectID": "docs/software/documentation/tooling.html",
    "href": "docs/software/documentation/tooling.html",
    "title": "Tooling",
    "section": "",
    "text": "There are various tools available that can help you create, manage, and deploy project documentation more effectively.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Tooling"
    ]
  },
  {
    "objectID": "docs/software/documentation/tooling.html#sphinx",
    "href": "docs/software/documentation/tooling.html#sphinx",
    "title": "Tooling",
    "section": "Sphinx",
    "text": "Sphinx\nSphinx is a versatile documentation tool that is well-suited for documenting Python projects due to its easy integration with Python‚Äôs docstrings. Its capabilities extend beyond Python, making it a great solution for creating comprehensive documentation for projects in various programming languages (e.g.¬†MATLAB).\nSome key features of Sphinx include:\n\nCross-referencing code and documentation across files.\nAutomatic generation of documentation from docstrings.\nSyntax highlighting for code examples.\nSupport for extensions and custom themes.\nMultiple output formats.\n\n\nGetting started with Sphinx\n\n\n\n\n\n\n Tip\n\n\n\nTo get started with Sphinx, we recommend the Coderefinery lesson on Sphinx and Markdown\n\n\n\nInstall dependency: You can install Sphinx in various ways, either through apt-get for Linux, Homebrew for macOS, or through Chocolatey for Windows. Assuming you have Python on your machine you can install it through conda or pip.\nSetup documentation: Create a directory for your documentation (/docs), and run sphinx-quickstart in that directory. The default answers to the questions are fine.\nConfigure Sphinx: Once you have the conf.py and index.rst files, you will need to modify them further. The index.rst file acts as the front page of your documentation and the root of the table of contents. The conf.py file is the main configuration file for the Sphinx documentation. It holds all your extensions and controls various aspects of the build process that can be customized to suit your needs. For example, sphinx.ext.autodoc is used for pulling documentation from docstrings, and sphinx.ext.mathjax for displaying mathematical content.\n\nBuilt-in extensions\nThird-party extensions\n\nWrite content: Add content to your documentation. In addition to reStructureText, Sphinx also integrates with markdown documentation through the MyST parser.\nBuild documentation: Once you have added the documentation files, you can build the documentation from the folder /docs with sphinx-build . _build/ or make html.\nFurther customization: You can customize the look of your documentation by changing themes in the conf.py file.\n\n\n\n\n\n\n\n Sphinx configuration template\n\n\n\n\n\n\n\n\n\nconfig.py\n\n\n\n\n\n# Configuration file for the Sphinx documentation builder\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, as shown here.\n#\nimport os\nimport sys\nsys.path.insert(0, os.path.abspath('..'))\n\n\n# -- Project information -----------------------------------------------------\n\nproject = \"Project\"\ncopyright = \"year, name\"\nauthor = \"name\"\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# The full version, including alpha/beta/rc tags\nrelease = \"0.1.0\"\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"myst_parser\", # MyST markdown parser\n    \"sphinxcontrib.matlab\", # Required for MATLAB\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx_copybutton\",\n    \"sphinx.ext.viewcode\",\n    \"sphinx_tabs.tabs\"\n]\n\nmyst_enable_extensions = [\n    \"linkify\",\n]\n\n# MATLAB settings for autodoc\n# here = os.path.dirname(os.path.abspath(__file__))\n# matlab_src_dir = os.path.abspath(os.path.join(here, \"..\"))\n# primary_domain = \"mat\"\n\n# Napoleon settings\nnapoleon_google_docstring = True\n# napoleon_numpy_docstring = True\n# napoleon_use_param = False\n# napoleon_preprocess_types = True\n\n# This value contains a list of modules to be mocked up.\n# autodoc_mock_imports = []\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = ['_templates']\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n\n# html_theme = \"sphinx_book_theme\"\nhtml_theme = \"sphinx_rtd_theme\"\n# html_theme = \"pydata_sphinx_theme\"\n\n\nhtml_title = \"title\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = ['_static']\n\n\n\n When using Sphinx extensions or custom themes beyond core functionality, a requirements.txt file is mandatory for reproducible documentation builds across environments. For example, this is required for hosting platforms like Read the Docs.\n\n\n\n\n\n\nrequirements.txt\n\n\n\n\n\n# Core\nsphinx\n\n# Sphinx extensions\nsphinxcontrib-matlabdomain # Only for matlab source code\nsphinx-tabs\nsphinx-copybutton\n\n# MyST parser\nmyst-parser\nlinkify-it-py\n\n# Themes\npydata-sphinx-theme\nsphinx-book-theme\nsphinx-rtd-theme\n\n\n\n\n\n\n\n\n\n\n\n Example repositories using Sphinx for Python:\n\n\n\n\nPython‚Äôs official documentation is created using Sphinx\nRead The Docs - the platform for hosting documentation is itself documented using Sphinx.\nNumPy\n\n\n\n\n\nSphinx autodoc\nOnce the Sphinx config.py is set up, you can generate the API reference documentation by using the sphinx-autodoc extension. By creating .rst files with the autodoc syntax, Sphinx will build the API reference.\n\n\nSphinx-matlabdomain\nFor documenting MATLAB projects, Sphinx can be extended for MATLAB. The sphinxcontrib-matlabdomain extension allows Sphinx to interpret and render MATLAB specific documentation. The extension can be installed through pip install sphinxcontrib-matlabdomain and add the extension to the conf.py file.\n\n\n\n\n\n\n Example repositories using sphinx for MATLAB:\n\n\n\n\nENIGMA Toolbox - provides documentation in both Python and MATLAB, generated by Sphinx and hosted using Read the Docs.\nCobra Toolbox\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nCoderefinery lesson on Sphinx and Markdown\nGetting started with Sphinx",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Tooling"
    ]
  },
  {
    "objectID": "docs/software/documentation/tooling.html#jupyter-book",
    "href": "docs/software/documentation/tooling.html#jupyter-book",
    "title": "Tooling",
    "section": "Jupyter Book",
    "text": "Jupyter Book\nJupyter Book uses Sphinx to convert notebooks and Markdown documents into an interactive publishing framework (with executable content). It integrates Jupyter Notebooks with Sphinx‚Äôs documentation capabilities, enabling features like cell execution and output caching directly within the documentation. Jupyter Book is essentially a specialized wrapper around Sphinx and the MyST-NB extension, designed to make publishing content easier.\n\n\n\n\n\n\n The TU Delft OPEN Interactive Textbooks platform uses Jupyter Book to create textbooks.\n\n\n\n\nFeatures\n\nJupyter Book can integrate outputs by allowing code execution within the content, making it ideal for tutorials, courses, and technical documentation that require live examples.\nJupyter Book uses Markdown for Jupyter (MyST) which extends the traditional Markdown syntax to include features normally available in reStructuredText (reST). This makes it easier to include complex formatting and dynamic content directly in Markdown files.\nJupyter Book can execute notebook cells and cache outputs. This means that content including code outputs can be generated once and reused.\n\n\n\nGetting started\nJupyterBook has extensive documentation on getting started with building a book.\n\n\n\n\n\n\n Further reading\n\n\n\n\nHow Jupyter Book and Sphinx relate to one another",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Tooling"
    ]
  },
  {
    "objectID": "docs/software/documentation/tooling.html#mkdocs",
    "href": "docs/software/documentation/tooling.html#mkdocs",
    "title": "Tooling",
    "section": "MkDocs",
    "text": "MkDocs\nMkDocs is a static site generator that uses markdown for all documentation, simplifying the writing process, and is configured with a single YAML file. It is lightweight compared to Sphinx but less feature-rich for complex use cases, and is best suitable for straightforward project documentation without heavy API generation needs.\n\nGetting started\n\nYou can install it through pip (pip install mkdocs). Then you can initialize your MkDocs project by running mkdocs new your_project_name.\nPlace your markdown documentation in your docs directory and define the structure in your mkdocs.yml file.\nYou can preview your site locally and see live updates as you make changes by running mkdocs serve.\nWhen you want to publish your documentation run mkdocs build.\nMkDocs is designed to be hosted on almost any static file server and works well with GitHub Pages.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nMkDocs official site that includes a Getting Started and User Guide.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Tooling"
    ]
  },
  {
    "objectID": "docs/software/documentation/tooling.html#quarto",
    "href": "docs/software/documentation/tooling.html#quarto",
    "title": "Tooling",
    "section": "Quarto",
    "text": "Quarto\nSimilar to Jupyter Book, Quarto is a publishing framework that allows you to create dynamic documents, presentations, reports, websites, and more. It supports multiple programming languages, including Python, R, and Julia, enabling the inclusion of executable code, interactive visualizations, equations, and rich formatting directly within the documents.\n\n\n\n\n\n\n‚Æï All of these guides are created with Quarto!\n\n\n\n\nGetting started\n\nDownloading: You can download the installer for your operating system from the Quarto website.\nRunning Quarto: You can run Quarto either from your command line or from VS Code, JupyterLab, RStudio, or any text editor. For VS Code you will need to install a Quarto extension. It is a stand-alone application and does not require Python.\nMarkdown flavour: Quarto projects use .qmd files which are a Markdown flavour.\n\n\n\n\n\n\n\n Basic structure of a Quarto file\n\n\n\n\n\n    ---\n    title: \"Your Document Title\"\n    format: html # Or pdf, word, etc.\n    ---\n\n    # Introduction\n\n    Some text...\n\n    ## Section 1\n\n    Some text...\n\n    ```python\n    # This is a code block\n    import pandas as pd\n    data = pd.read_csv(\"data.csv\")\n    print(data.head())\n    ```\n\n    ## Section 2\n\n    Some more text....\n\n\n\n\n\nAdding content: Write your text using standard Markdown syntax and add code blocks.\nBuilding documentation:\n\nTo compile a Quarto document, use quarto render your-file-name.qmd. This command converts your .qmd file into the output format specified in the file‚Äôs header (e.g., HTML, PDF).\nYou can watch a file or directory for changes and automatically re-render with quarto preview your-file-name.qmd, which is useful to see live updates.\n\nAdditional features:\n\nQuarto supports cross-referencing figures, tables, and other elements within your document. You can also use BibTeX for citations.\nYou can have interactive components for web outputs (e.g.¬†embeded Plotly charts).\nExtensive options for custom styles and layouts.\n\nPublishing: Quarto documents are portable and can be shared as is, allowing others to compile them on their own systems or published by hosting the output files on a server like GitHub Pages.\n\n\n\n\n\n\n\n Examples\n\n\n\n\nQuarto gallery\n\n\n\n\n\n\n\n\n\n PDF engine\n\n\n\nIn order to create PDFs you will need to install a LaTeX engine if you do not have one installed already. You could use a lightweight distribution like TinyTeX, which you can install with quarto install tool tinytex.\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nGetting started with Quarto\nComprehensive guide to using Quarto\nCarpentries Incubator - Introduction to Working with Quarto documents",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Tooling"
    ]
  },
  {
    "objectID": "docs/software/documentation/tooling.html#tools-for-r",
    "href": "docs/software/documentation/tooling.html#tools-for-r",
    "title": "Tooling",
    "section": "Tools for R",
    "text": "Tools for R\nR project documentation generally includes in-line comments and function documentation using roxygen2. Additionally, comprehensive examples and usage guides are often provided through vignettes, which are included within an R package itself.\nTo extend roxygen2 documentation into a static website for your package you can use pkgdown. pkgdown automatically generates a website from your package‚Äôs documentation and vignettes, similar to how Sphinx is used for Python projects.\n\n\n\n\n\n\n Learn more\n\n\n\n\npkgdown",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Documentation",
      "Tooling"
    ]
  },
  {
    "objectID": "docs/software/fair_software/checklist.html",
    "href": "docs/software/fair_software/checklist.html",
    "title": "FAIR checklist for research software",
    "section": "",
    "text": "This checklist provides a set of recommendations for FAIR software. It outlines best practices and guidelines to ensure the quality, reproducibility, and sustainability of software projects. The checklist covers various aspects, such as version control, documentation, testing, licensing, and collaboration, providing a comprehensive framework for improving your software development process.\nTo support implementation, each checklist section contains a tab with pre-formatted markdown templates (FAIR cards). These can be copied directly into your repository as issues to systematically track progress in adopting FAIR research software best practices.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "FAIR Software",
      "FAIR checklist for research software"
    ]
  },
  {
    "objectID": "docs/software/fair_software/checklist.html#checklist",
    "href": "docs/software/fair_software/checklist.html#checklist",
    "title": "FAIR checklist for research software",
    "section": "Checklist",
    "text": "Checklist\n\nVersion controlVersion control (.md format)\n\n\nEssential\n\nUse git as a version control system\nUpload your project on GitHub or TU Delft GitLab\n\nRecommended\n\nMake your repository public\nConsider your branch hygiene\nUse a branching model (e.g.¬†GitFlow)\nUse meaningful commit messages\n\n\n\n_Essential_\n- [ ] Use [git](https://www.atlassian.com/git) as a version control system \n- [ ] Upload your project on [GitHub](https://github.com/) or [TU Delft GitLab](https://gitlab.tudelft.nl/)\n\n_Recommended_  \n- [ ] Make your repository [public](https://coderefinery.github.io/social-coding/)\n- [ ] Consider your [branch hygiene](https://coderefinery.github.io/git-branch-design/)\n- [ ] Use a branching model (e.g. [GitFlow](https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow))\n- [ ] Use [meaningful commit messages](https://www.git-scm.com/book/en/v2/Distributed-Git-Contributing-to-a-Project#_commit_guidelines)\n\n\n\n\nCollaborationCollaboration (.md format)\n\n\nEssential\n\nMake use of GitHub issues\n\nRecommended\n\nContribution guidelines\nCode of conduct\n\n\n\n_Essential_  \n- [ ] Make use of [GitHub issues](https://docs.github.com/en/issues/tracking-your-work-with-issues/about-issues)\n\n_Recommended_\n- [ ] [Contribution guidelines](https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions/setting-guidelines-for-repository-contributors)\n- [ ] [Code of conduct](https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions/adding-a-code-of-conduct-to-your-project)\n\n\n\n\nProject documentationProject documentation (.md format)\n\n\nEssential\n\nREADME\nApply a TU Delft pre-approved LICENSE\nCITATION\n\n\n\n_Essential_  \n- [ ] [README](https://www.makeareadme.com)\n- [ ] Apply a TU Delft pre-approved [LICENSE](https://zenodo.org/records/4629635)\n- [ ] [CITATION](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-citation-files)\n\n\n\n\nSoftware documentationSoftware documentation (.md format)\n\n\nEssential\n\nSource code documentation (docstrings)\nDocument your project dependencies\nInstallation instructions\nUser documentation\n\nRecommended\n\nDeveloper documentation and setup\nExamples and tutorials (e.g.¬†Jupyter Notebooks)\n\nOptional\n\nDocumentation tools (Sphinx, JupyterBook, Quarto)\nBuild an API reference from docstrings\nHosting (GitHub Pages, Readthedocs)\n\n\n\n_Essential_  \n- [ ] Source code documentation ([docstrings](https://numpydoc.readthedocs.io/en/latest/format.html))\n- [ ] Document your project dependencies\n- [ ] Installation instructions\n- [ ] User documentation\n\n_Recommended_  \n- [ ] Developer documentation and setup\n- [ ] Examples and tutorials (e.g. Jupyter Notebooks)\n\n_Optional_\n- [ ] Documentation tools ([Sphinx](https://coderefinery.github.io/documentation/sphinx/), [JupyterBook](https://jupyterbook.org/intro.html), [Quarto](https://quarto.org/docs/guide/))\n- [ ] Build an [API reference](https://developer.lsst.io/python/numpydoc.html) from docstrings\n- [ ] Hosting ([GitHub Pages](https://pages.github.com/), [Readthedocs](https://readthedocs.org/))\n\n\n\n\nSoftware testingSoftware testing (.md format)\n\n\nEssential\n\nInstallation/execution verification\n\nRecommended\n\nDefensive programming\nTest your software with integration tests and unit tests\nMake use of Continuous Integration to automate testing\n\nOptional\n\nCode coverage check (e.g.¬†Sonarcloud, codecov)\n\n\n\n_Essential_\n- [ ] Installation/execution verification\n\n_Recommended_\n- [ ] [Defensive programming](https://swcarpentry.github.io/python-novice-inflammation/10-defensive.html)\n- [ ] Test your software with [integration tests](https://the-turing-way.netlify.app/reproducible-research/testing/testing-integrationtest.html) and [unit tests](https://the-turing-way.netlify.app/reproducible-research/testing/testing-unittest.html)\n- [ ] Make use of [Continuous Integration](https://coderefinery.github.io/testing/continuous-integration/) to automate testing\n\n_Optional_\n- [ ] Code coverage check (e.g. [Sonarcloud](https://sonarcloud.io/), [codecov](https://about.codecov.io))\n\n\n\n\nSoftware qualitySoftware quality (.md format)\n\n\nEssential\n\nOrganize your project for reproducibility\nRecord and manage your software dependencies\n\nRecommended\n\nMake refactoring part of your workflow\nFollow best coding practices\n\nRecommended for Python\n\nFollow PEP8 guidelines\nUse a tool for dependency management (e.g.¬†poetry)\nUse linter (e.g.¬†pylint, flake8)\nUse a formatter (e.g.¬†black)\n\n\n\n_Essential_\n- [ ] [Organize](https://coderefinery.github.io/reproducible-research/organizing-projects/) your project for reproducibility\n- [ ] [Record and manage](https://coderefinery.github.io/reproducible-research/dependencies/) your software dependencies \n\n_Recommended_\n- [ ] Make [refactoring](https://refactoring.guru/refactoring) part of your workflow\n- [ ] Follow [best coding practices](https://alan-turing-institute.github.io/rse-course/html/module07_construction_and_design/index.html)\n\n_Recommended for Python_\n- [ ] Follow [PEP8 guidelines](https://realpython.com/python-pep8/)\n- [ ] Use a tool for dependency management (e.g. [poetry](https://python-poetry.org/docs/))\n- [ ] Use linter (e.g. [pylint](https://pypi.org/project/pylint/), [flake8](https://pypi.org/project/flake8/))\n- [ ] Use a formatter (e.g. [black](https://github.com/psf/black))\n\n\n\n\nReleasesReleases (.md format)\n\n\nEssential\n\nObtain a DOI (Zenodo or 4TU.ResearchData)\n\nRecommended\n\nUse semantic versioning\nCreate tagged releases (GitHub)\nCHANGELOG\nUpload to registry (e.g.¬†PyPI, conda)\nReleasing guide\n\nOptional\n\nContinuous Integration for automated build and release\n\n\n\n_Essential_  \n- [ ] Obtain a DOI ([Zenodo](https://zenodo.org/) or [4TU.ResearchData](https://data.4tu.nl/info/about-your-data/getting-started))\n\n_Recommended_  \n- [ ] Use [semantic versioning](https://semver.org/)\n- [ ] Create tagged releases ([GitHub](https://docs.github.com/en/repositories/releasing-projects-on-github))\n- [ ] [CHANGELOG](https://keepachangelog.com/en/1.0.0/)\n- [ ] Upload to [registry](https://github.com/NLeSC/awesome-research-software-registries) (e.g. [PyPI](https://realpython.com/pypi-publish-python-package/), [conda](https://conda.io/projects/conda-build/en/latest/user-guide/tutorials/build-pkgs.html))\n- [ ] [Releasing guide](https://docs.github.com/en/repositories/releasing-projects-on-github/managing-releases-in-a-repository)\n\n_Optional_\n- [ ] [Continuous Integration](https://the-turing-way.netlify.app/reproducible-research/ci/ci-options.html) for automated build and release\n\n\n\n\nExample repositories\n\neScience Center - matchms - Matchms is an open-source Python package to import, process, clean, and compare mass spectrometry data.\nTU Delft - Transposonmapper - Transposonmapper is an open-source python package and Docker image for mapping transposons from sequencing data.\n\n\nFor more information on the principles behind FAIR software, please have a look at the following resources:\n\nThe Turing Way - Guide for Reproducible Research - general guide to reproducible research\nTowards FAIR principles for research software - publication on the translation of FAIR principles for data to FAIR principles for software\nFrom FAIR research data toward FAIR and open research software\nFAIR Principles for Research Software\n\n\n\n\nAcknowledgements\nThe checklist was in part based on the checklist provided by the eScience Center, licensed under CC BY 4.0.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "FAIR Software",
      "FAIR checklist for research software"
    ]
  },
  {
    "objectID": "docs/software/fair_software/software_management_plan.html",
    "href": "docs/software/fair_software/software_management_plan.html",
    "title": "Software management plan",
    "section": "",
    "text": "A software management plan (SMP) helps to implement best practices during software development and ensures that software is accessible and reusable in the short and longer term. The Netherlands eScience Center and NWO, the Dutch Research Council, have taken the initiative to develop (national) guidelines for software management plans, which resulted in the publication of the Practical guide to Software Management Plans in October 2022.\nAs an introduction to Software Management Plans, TU Delft has created a video:\n\n‚ÄúNavigating Research Data and Software: A Practical Guide for PhD Supervisors 2025‚Äù, TU Delft Library. CC-BY-4.0\n\n\n\n\n\n\n Tip\n\n\n\nThe Intermediate Research Software Development course from The Carpentries is a good resource to learn the core principle of intermediate-level software development and best practices collaborating in a team.\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nSoftware Development Plan: A quick start on building software development plans.\nSoftware Development Life Cycle: A guide on how to follow the software development lifecycle (SDLC) systematically, and different SDLC methodologies.\nWriting Software Management Plans: A guide from the Software Sustainability Institute on how to write research software management plans.\nSoftware Management Plans documentation: A detailed documentation about software management plans, including up-to-date templates.\nA Framework for Understanding Research Software: A proposal for categorizing different types of research software, and a framework for sustaining research software.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "FAIR Software",
      "Software management plan"
    ]
  },
  {
    "objectID": "docs/software/releases_archiving/archiving.html",
    "href": "docs/software/releases_archiving/archiving.html",
    "title": "Archiving",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Publish and share",
      "Archiving"
    ]
  },
  {
    "objectID": "docs/software/releases_archiving/packaging.html",
    "href": "docs/software/releases_archiving/packaging.html",
    "title": "Packaging",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Publish and share",
      "Packaging"
    ]
  },
  {
    "objectID": "docs/software/testing/index.html",
    "href": "docs/software/testing/index.html",
    "title": "Software testing",
    "section": "",
    "text": "When you‚Äôre writing software ‚Äì especially for research ‚Äì it‚Äôs important to make sure your programs work as expected. Testing is like a safety net: it helps you catch mistakes early and keeps your code reliable as you add new features or make changes. In research software, tests are even more crucial because they help ensure that your results are accurate and that others can reproduce your work. Beyond detecting bugs early, it is an investment in the quality and long-term maintainability of your codebase.\n\n\n\n Approach to testing\nA guide to help you get started with testing your software.\n\nLearn more ¬ª\n\n\n\n Test types\nDifferent types of tests to ensure your software works as expected.\n\nLearn more ¬ª\n\n\n\n Additional concepts\nMore concepts to help you write better tests.\n\nLearn more ¬ª\n\n\n\n Python testing\nTesting your Python code.\n\nLearn more ¬ª\n\n\n\n MATLAB testing\nTesting your MATLAB code.\n\nLearn more ¬ª\n\n\n\n R testing\nTesting your R code.\n\nLearn more ¬ª\n\n\n\n\n\n\n\n\n\n\nRecommended courses\n\n\n\n\nThe Turing Way - Testing\nCodeRefinery - Lesson on testing\nSoftware Carpentry - Testing and Continuous Integration with Python\nR Packages - Testing",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing"
    ]
  },
  {
    "objectID": "docs/software/testing/matlab.html",
    "href": "docs/software/testing/matlab.html",
    "title": "Testing in MATLAB",
    "section": "",
    "text": "This guide explains how to write and execute tests in MATLAB. For additional details, refer to the official MATLAB documentation.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Testing in MATLAB"
    ]
  },
  {
    "objectID": "docs/software/testing/matlab.html#writing-tests",
    "href": "docs/software/testing/matlab.html#writing-tests",
    "title": "Testing in MATLAB",
    "section": "Writing tests",
    "text": "Writing tests\nMATLAB supports script-based, function-based, and class-based unit tests, allowing for a range of testing strategies from simple to advanced use cases. See the MATLAB documentation for more information:\n\nMatlab - Ways to write unit tests\n\nScript-based testing\nFunction-based testing\nClass-based testing\n\n\n\nConvention for writing tests\n\nIt is recommened place tests in a separate folder, typically named tests/.\nPrefix test files with ‚Äútest‚Äù followed by the file that is tested. For example, a test for the file DrawRandomNumber.m should be called TestDrawRandomNumber.m. Matlab will recognize any scripts that are prefixed or suffixed with the string ‚Äútest‚Äù as tests.\n\n\n\nClass-based unit tests\nBecause of the limited features of the script- and function-based testing, this guide will discuss class-based testing. Class-based tests give you access to shared test fixtures, test parameterization, and grouping tests into categories. Check out our additional testing concepts for more information about these concepts.\n\n\n\n\n\n\n Introduction to class-based testing\n\n\n\nCheck out this short MATLAB video on writing class-based tests.\n\n\nYou can find an example below with the matlab syntax for writing Class-based unit tests:\nclassdef TestSumNumbers &lt; matlab.unittest.TestCase\n    methods (Test)\n        function testSumNumbers(testCase)\n            result = sumNumbers(2, 3);            \n            testCase.verifyEqual(result, 5)\n        end\n    end\nend\n Check out the MATLAB documentation for an introductory example: Write Simple Test Case Using Classes\n\n\n\n\n\n\nAnnotated class-based unit test example\n\n\n\n\n\n% Test classes are created by inheriting (&lt; symbol) the  Matlab Testing \n% framework.\n%\n% e.g. classdef nameOfTest &lt; matlab.unittest.TestCase\n%      end\n\nclassdef (TestTags = {'Unit'}) test_example &lt; matlab.unittest.TestCase \n%                              It's convention to name the test file \n%                              test_\"filename being tested\".m\n%\n%         TestTags are an optional feature that are useful for identifying \n%         what kind of test you're coding, as you might only want to run \n%         certain tests that are related.\n\n    properties \n        % Class properties are not required, but are useful to contain \n        % common parameters between tests.\n    end\n    \n    methods (TestClassSetup) \n        % TestClassSetup methods are not required, but are usually used to\n        % setup common testing variables, or loading data. These methods\n        % are executed *prior to* the (Test) methods.\n    end\n    \n    methods (TestClassTeardown) \n        % TestClassTeardown methods are not required, but are useful to\n        % delete any files created during the test execution. These methods\n        % are executed *after* the (Test) methods.\n    end\n    \n    methods (Test) % Each test is it's own method function, and takes \n                   % testCase as their only argument.\n\n        function test_sumNumbers_returns_expected_value_for_integer_case(testCase) \n        % Use very descriptive test method names - this helps for debugging\n        % when error occurs.\n                        \n            % Call the function you'd like to test, e.g:\n%             actualValue = sumNumbers(2,2); % Test example integer case, 2+2\n            % Since the function sumNumbers is not defined, the test will\n            % fail. Instead, we will define the actual value.\n            actualValue = 4;\n\n\n            expectedValue = 4; % We know that we expect that 2+2 = 4\n\n            testCase.assertEqual(expectedValue, actualValue)\n            % Assert functions are the core of unit tests; if it fails,\n            % test log will return failed tests and details.\n            %\n            % They are called as methods of the testCase object.\n            %\n            % Example assert methods:\n            %\n            % assertEqual(expected, actual): Passes if the two input values\n            %                                are equal.\n            % assertTrue(boolValue): Passes if the value or statement is \n            %                        true (e.g. 2&gt;1)\n            % assertFalse(boolValue): Passes if the value or statement is\n            %                         false (e.g. 1==0)\n            %\n            % See Matlab's documentation for more assert methods: \n            % https://www.mathworks.com/help/matlab/ref/matlab.unittest.qualifications.assertable-class.html\n        end\n    end\n\nend",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Testing in MATLAB"
    ]
  },
  {
    "objectID": "docs/software/testing/matlab.html#executing-tests",
    "href": "docs/software/testing/matlab.html#executing-tests",
    "title": "Testing in MATLAB",
    "section": "Executing tests",
    "text": "Executing tests\n\n1. Running tests in the MATLAB Command Window\nYou can run tests through the MATLAB Command Window, by executing the following command in the root of your repository:\nresults = runtests(pwd, \"IncludeSubfolders\", true);\n\n% The argument `pwd` specifies the current working directory\n% `IncludeSubfolders` specifies whether to include subfolders in the search for tests\nMATLAB will automatically find all tests. If you make use of tags to categorize tests, you can run specific tags with:\nresults = runtests(pwd, \"IncludeSubfolders\", true, \"Tag\", '&lt;tag-name&gt;');\n For more details: runtests() documentation\n\nCustom testsuite script\nWe have a custom script available to run tests in a more structured way. It can be useful to:\n\nrun tests with specific tags\nignore specific tests\ngenerate various test reports\n\nWhen placed in the folder tests/, the script can be executed by running the following command in the MATLAB Command Window:\nrun_testsuite('TestTag', 'Unit')\n\n\n\n2. Script editor\nYou can run tests interactively by opening a test file in the MATLAB Editor and selecting ‚ÄúRun All‚Äù or ‚ÄúRun Current Test‚Äù.\n\n\n\nMathWorks, Script editor testing, MATLAB Documentation, link to image.\n\n\n For more details: Script Editor documentation\n\n\n3. MATLAB Test Browser App\nThe Test Browser app (available since R2023a) enables you to run script-based, function-based, and class-based tests interactively. You can run all tests, selected tests, or individual tests.\n\n\n\nMathWorks, MATLAB test browser, MATLAB Documentation, link to image.\n\n\n For more details: MATLAB Test browser documentation\n\n\nSimulink testing\nFor Simulink models, MATLAB provides Simulink Test for simulation-based testing.\n\nSimulink Test - Introduction video\nSimulink Test - Examples",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Testing in MATLAB"
    ]
  },
  {
    "objectID": "docs/software/testing/r_test.html",
    "href": "docs/software/testing/r_test.html",
    "title": "Testing in R",
    "section": "",
    "text": "üöß Coming soon! ‚è≥",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Testing in R"
    ]
  },
  {
    "objectID": "docs/software/testing/test_types.html",
    "href": "docs/software/testing/test_types.html",
    "title": "Types of tests",
    "section": "",
    "text": "In writing tests for research software, we often differentiate between four types of tests: unit tests, integration tests, and end-to-end tests. In addition, regression tests are used to ensure that recent code changes haven‚Äôt adversely affected existing features or functionality.\n\n\n\nTesting pyramid ¬© 2023 SketchingDev\n\n\n\nUnit tests\nA unit test is a type of test where individual units or components of the software application are tested in isolation from the rest of the application. A unit can be a function, method, or class. The main purpose of unit testing is to validate that each unit of the software performs as designed.\n\n\nIntegration tests\nIntegration testing is a level of software testing where individual units are combined and tested as a group. The purpose is to verify that the units work together as expected and that the interfaces between them function correctly. Integration tests aims to expose defects in the interactions between integrated components.\n\n\nEnd-to-end tests\nEnd-to-end testing is focused on checking the entire system from start to finish, simulating real use cases. The goal is to verify the software functions as a whole from the user‚Äôs perspective.\n\n\nRegression tests\nRegression testing aims to verify that recent code changes haven‚Äôt adversely affected existing features or functionality. It involves re-running previously executed test cases to ensure that the software still behaves as expected after modifications. The primary purpose of regression testing is to catch unintended side effects of code changes and ensure that new features or bug fixes haven‚Äôt introduced regressions or broken existing functionality elsewhere in the code. Regression tests can include both unit tests and integration tests, as well as higher-level tests.\n\n\nDesigning a test case\nFor more complex integration, regression, or end-to-end tests, it can be useful to first describe the test case in words.\n\nDescription: Description of test case\nPreconditions: Conditions that need to be met before executing the test case\nTest Steps: To execute test cases, you need to perform some actions. Mention all the test steps in detail and the order of execution\nTest Data: If required, list data that needed to execute the test cases\nExpected Result: The result we expect once the test cases are executed\nPostcondition: Conditions that need to be achieved when the test case was successfully executed",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Software testing",
      "Test types"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/branch_management.html",
    "href": "docs/software/development_workflow/branch_management.html",
    "title": "Branch management",
    "section": "",
    "text": "Branch management in Git is essential for collaborative software development in version-controlled environments. The core advantage of branching is that it provides separate, dedicated environments for code development, independent of the main (working) version. This approach enables parallel development streams, allowing for experimentation and modification without impacting the stable main version of the project. Note, this approach is also valuable for projects with only one developer!\nA branching strategy defines a set of best practices for writing, merging, and releasing code. Choosing the right approach helps teams collaborate efficiently while maintaining a stable codebase.",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Branch management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/branch_management.html#branch-models",
    "href": "docs/software/development_workflow/branch_management.html#branch-models",
    "title": "Branch management",
    "section": "Branch models",
    "text": "Branch models\nWhile multiple branching strategies exist, GitHub Flow and GitFlow are well-suited for research software projects, depending on collaboration style and release cycle:\n\nGitHub Flow is a simplified and straightforward workflow, relying on a single main branch. Developers create so-called feature branches off of the main branch, work on their changes, and then merge them back into the main branch via pull requests. The process is built around the principle of continuous collaboration and is particularly useful for projects where regular updates and deployments are common.\nGitflow relies on two primary branches - main and develop. Developers create feature branches off of the develop branch. Once a feature is complete, it is merged back into the develop branch, which itself is merged with main for each new release of the software. It can be a better choice for managing larger projects with distinct release cycles and versioning requirements (e.g., tools tied to publications) or requiring parallel development of features and experiments.\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nGitHub Flow getting started\nIntroduction GitHub Flow",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Branch management"
    ]
  },
  {
    "objectID": "docs/software/development_workflow/branch_management.html#branch-management-in-action",
    "href": "docs/software/development_workflow/branch_management.html#branch-management-in-action",
    "title": "Branch management",
    "section": "Branch management in action",
    "text": "Branch management in action\n\nPersonal projects and small teams\nGitHub Flow model:\n\nTypically starts with just the main branch.\nUse branches for unfinished/untested ideas.\nUse branches when you are not sure about a change.\nAdd tags to mark important milestones.\n\n\n\n\n\n\n%%{init: {'theme': 'base', 'themeVariables': {\n              'git0': '#bfbf40',\n              'git1': '#bf8040',\n              'git2': '#40bfbf'\n              }, 'gitGraph': {'showCommitLabel': false}}}%%\ngitGraph LR:\n   commit\n   commit\n   branch \"feature_a\"\n   checkout \"feature_a\"\n   commit\n   commit type:REVERSE\n   checkout main\n\n   commit\n   branch \"feature_b\"\n   checkout \"feature_b\"\n   commit\n   commit\n   commit\n\n   checkout main\n   merge \"feature_b\"\n   commit tag:\"v1.0.0\"\n\n\n\n\n\n\n\nWhen applying this workflow for small teams, you accept things breaking sometimes.\nWhen there is more control required, follow:\n\nThe main branch is write-protected.\nYou create new feature branches for changes.\nChanges are reviewed before they are merged to the main branch.\nOnly merges to main branch through pull requests (and optionally code reviews).\n\n\n\n\n\n\n\nWhat is the difference between master and main branches?\n\n\n\n\n\nGitHub decided to rename the default branch from master to main for new repositories after October 2020. This change was part of a broader industry move to replace terms that may be considered insensitive or non-inclusive. It‚Äôs important to note that while the terms main and master refer to the default branch in a repository, they are functionally the same. Be aware that repositories created before October 2020 may still use master instead of main.\n\n\n\n\n\nDistributing releases\nWhen you need to distribute releases, your main branch will serve as the latest stable version.\n\nThe main branch is protected and read-only.\nYou set up a develop branch for active development.\nCreate feature branches of the develop branch.\nMerge feature branches (through Pull Requests) back to develop.\nOnly merge develop into main when releasing a new stable (and tested) version.\n\n\n\n\n\n\n%%{init: {'theme': 'base', 'themeVariables': {\n              'git0': '#bfbf40',\n              'git1': '#4080bf',\n              'git2': '#bf8040',\n              'git3': '#40bfbf'\n              }, 'gitGraph': {'showCommitLabel': false}}}%%\ngitGraph\n    \n   commit tag:\"v0.1.0\"\n   branch develop\n   commit\n\n   checkout develop\n   commit\n   branch feature_a\n   checkout feature_a\n   commit\n   checkout develop\n   merge feature_a\n   commit\n   commit\n   branch feature_b\n   checkout feature_b\n   commit\n   commit\n   checkout develop\n   merge feature_b\n   commit\n\n   checkout main\n   merge develop tag:\"v0.2.0\"\n\n   checkout develop\n   commit\n   commit\n   checkout main\n   merge develop tag:\"v0.3.0\"\n\n   checkout develop\n   commit\n   commit\n\n\n\n\n\n\n\n\n\nAdd additional supporting branches\nWhen a critical bug in the stable version must be resolved immediately, a hotfix branch may be branched off from the corresponding tag on the main branch that marks this version. After fixing, hotfix is then merged with both main and develop.\n\n\n\n\n\n%%{init: {'theme': 'base', 'themeVariables': {\n              'git0': '#bfbf40',\n              'git1': '#4080bf',\n              'git2': '#7da97a'\n              }, 'gitGraph': {'showCommitLabel': false}}}%%\ngitGraph\n    \n   commit tag:\"v0.2.0\"\n   branch develop\n   commit\n   commit\n   commit\n   commit\n   checkout main\n   branch hotfix\n   commit\n   commit\n   checkout develop\n   merge hotfix\n   checkout main\n   merge hotfix tag:\"v0.2.1\"\n   checkout develop\n   commit\n   commit\n   checkout main\n   merge develop tag:\"v0.3.0\"\n   \n\n\n\n\n\n\n\n\nThe complete Gitflow model in action\nGitFlow‚Äôs structured approach with parallel production and integration branches, supplemented by feature/release/hotfix branches, was specifically designed for versioned software requiring maintenance of multiple production releases.\n\n\n\n\n\n%%{init: {'theme': 'base', 'themeVariables': {\n              'git0': '#bfbf40',\n              'git1': '#4080bf',\n              'git2': '#bf8040',\n              'git3': '#eae0b8',\n              'git4': '#7da97a'\n              }, 'gitGraph': {'showCommitLabel': false}}}%%\ngitGraph\n   commit\n   branch develop\n   commit\n   checkout develop\n   commit\n   branch feature\n   checkout feature\n   commit\n   commit\n   checkout develop\n   merge feature\n   commit\n   branch release\n   checkout release\n   commit\n   commit\n   checkout main\n   merge release\n   checkout develop\n   merge release\n   checkout main\n   branch hotfix/security\n   checkout hotfix/security\n   commit\n   checkout main\n   merge hotfix/security\n   checkout develop\n   merge hotfix/security\n\n\n\n\n\n\n\n\n\n\n\n\n Learn more\n\n\n\n\nCode Refinery - Branching models\nGitHub - Branch protection rules\nTag names following semantic versioning\nGitHub tags and releases",
    "crumbs": [
      "Guides",
      "<span style=\"filter:grayscale(100%);\">üíª</span> **Research Software**",
      "Development workflow",
      "Branch management"
    ]
  }
]